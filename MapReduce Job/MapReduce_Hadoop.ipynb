{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# MapReduce jobs\n",
    "\n",
    "In this notebook we list the two MapReduce jobs needed in our architecture."
   ],
   "id": "f452e226dc947013"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Title occurrences\n",
    "\n",
    "This MapReduce counts the occurrences of each title in the entire dataset."
   ],
   "id": "7f1dc8fa50e16148"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-31T10:04:10.877576Z",
     "start_time": "2025-08-31T10:03:58.654326Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mapper = '/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py'\n",
    "reducer = '/home/ubuntu/jupyter/MapReduce/reducer_title_occurrences.py'\n",
    "\n",
    "dataset = '/user/ubuntu/dataset_preprocessed/'\n",
    "\n",
    "out_dataset = '/user/ubuntu/map_reduce/title_occurrences/'\n",
    "\n",
    "streaming_jar = '/usr/local/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.10.0.jar'\n",
    "\n",
    "# Delete any old join MapReduce job output, if necessary\n",
    "!hadoop fs -rm -r $out_dataset\n",
    "\n",
    "# Execute the actual join MapReduce job\n",
    "!hadoop jar $streaming_jar -files $mapper,$reducer -mapper $mapper -reducer $reducer -input $dataset -output $out_dataset"
   ],
   "id": "25c45769f051fd2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted /user/ubuntu/map_reduce/title_occurrences\r\n",
      "25/08/31 12:04:00 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id\r\n",
      "25/08/31 12:04:00 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=\r\n",
      "25/08/31 12:04:00 INFO jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\r\n",
      "25/08/31 12:04:00 INFO mapred.FileInputFormat: Total input files to process : 348\r\n",
      "25/08/31 12:04:00 INFO mapreduce.JobSubmitter: number of splits:348\r\n",
      "25/08/31 12:04:00 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1968043658_0001\r\n",
      "25/08/31 12:04:01 INFO mapred.LocalDistributedCacheManager: Creating symlink: /app/hadoop/tmp/mapred/local/1756634641033/mapper_title_occurrences.py <- /home/ubuntu/mapper_title_occurrences.py\r\n",
      "25/08/31 12:04:01 INFO mapred.LocalDistributedCacheManager: Localized file:/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py as file:/app/hadoop/tmp/mapred/local/1756634641033/mapper_title_occurrences.py\r\n",
      "25/08/31 12:04:01 INFO mapred.LocalDistributedCacheManager: Creating symlink: /app/hadoop/tmp/mapred/local/1756634641034/reducer_title_occurrences.py <- /home/ubuntu/reducer_title_occurrences.py\r\n",
      "25/08/31 12:04:01 INFO mapred.LocalDistributedCacheManager: Localized file:/home/ubuntu/jupyter/MapReduce/reducer_title_occurrences.py as file:/app/hadoop/tmp/mapred/local/1756634641034/reducer_title_occurrences.py\r\n",
      "25/08/31 12:04:01 INFO mapreduce.Job: The url to track the job: http://localhost:8080/\r\n",
      "25/08/31 12:04:01 INFO mapred.LocalJobRunner: OutputCommitter set in config null\r\n",
      "25/08/31 12:04:01 INFO mapreduce.Job: Running job: job_local1968043658_0001\r\n",
      "25/08/31 12:04:01 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapred.FileOutputCommitter\r\n",
      "25/08/31 12:04:01 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:01 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:01 INFO mapred.LocalJobRunner: Waiting for map tasks\r\n",
      "25/08/31 12:04:01 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000000_0\r\n",
      "25/08/31 12:04:01 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:01 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:01 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00000-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+14454\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:01 INFO Configuration.deprecation: mapred.work.output.dir is deprecated. Instead, use mapreduce.task.output.dir\r\n",
      "25/08/31 12:04:01 INFO Configuration.deprecation: map.input.start is deprecated. Instead, use mapreduce.map.input.start\r\n",
      "25/08/31 12:04:01 INFO Configuration.deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap\r\n",
      "25/08/31 12:04:01 INFO Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id\r\n",
      "25/08/31 12:04:01 INFO Configuration.deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id\r\n",
      "25/08/31 12:04:01 INFO Configuration.deprecation: mapred.local.dir is deprecated. Instead, use mapreduce.cluster.local.dir\r\n",
      "25/08/31 12:04:01 INFO Configuration.deprecation: map.input.file is deprecated. Instead, use mapreduce.map.input.file\r\n",
      "25/08/31 12:04:01 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords\r\n",
      "25/08/31 12:04:01 INFO Configuration.deprecation: map.input.length is deprecated. Instead, use mapreduce.map.input.length\r\n",
      "25/08/31 12:04:01 INFO Configuration.deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id\r\n",
      "25/08/31 12:04:01 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name\r\n",
      "25/08/31 12:04:01 INFO Configuration.deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:01 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: bufstart = 0; bufend = 1843; bufvoid = 104857600\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:01 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000000_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:01 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:01 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000000_0' done.\r\n",
      "25/08/31 12:04:01 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000000_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=146007\r\n",
      "\t\tFILE: Number of bytes written=690581\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=14454\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=6\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1843\r\n",
      "\t\tMap output materialized bytes=1917\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=235405312\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=14454\r\n",
      "25/08/31 12:04:01 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000000_0\r\n",
      "25/08/31 12:04:01 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000001_0\r\n",
      "25/08/31 12:04:01 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:01 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:01 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00001-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+10199\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:01 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: bufstart = 0; bufend = 2103; bufvoid = 104857600\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:01 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000001_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:01 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:01 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000001_0' done.\r\n",
      "25/08/31 12:04:01 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000001_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=150559\r\n",
      "\t\tFILE: Number of bytes written=692789\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=24653\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=8\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=2103\r\n",
      "\t\tMap output materialized bytes=2176\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=340787200\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=10199\r\n",
      "25/08/31 12:04:01 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000001_0\r\n",
      "25/08/31 12:04:01 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000002_0\r\n",
      "25/08/31 12:04:01 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:01 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:01 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00002-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+8169\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:01 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: bufstart = 0; bufend = 2718; bufvoid = 104857600\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:01 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000002_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:01 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:01 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000002_0' done.\r\n",
      "25/08/31 12:04:01 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000002_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=155111\r\n",
      "\t\tFILE: Number of bytes written=695616\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=32822\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=10\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=2718\r\n",
      "\t\tMap output materialized bytes=2795\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=53\r\n",
      "\t\tTotal committed heap usage (bytes)=536346624\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=8169\r\n",
      "25/08/31 12:04:01 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000002_0\r\n",
      "25/08/31 12:04:01 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000003_0\r\n",
      "25/08/31 12:04:01 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:01 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:01 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00003-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+7090\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:01 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: bufstart = 0; bufend = 2994; bufvoid = 104857600\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:01 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000003_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:01 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:01 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000003_0' done.\r\n",
      "25/08/31 12:04:01 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000003_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=159663\r\n",
      "\t\tFILE: Number of bytes written=698720\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=39912\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=12\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=2994\r\n",
      "\t\tMap output materialized bytes=3072\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=536346624\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=7090\r\n",
      "25/08/31 12:04:01 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000003_0\r\n",
      "25/08/31 12:04:01 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000004_0\r\n",
      "25/08/31 12:04:01 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:01 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:01 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00004-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+6468\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:01 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: bufstart = 0; bufend = 3242; bufvoid = 104857600\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:01 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000004_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:01 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:01 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000004_0' done.\r\n",
      "25/08/31 12:04:01 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000004_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=164215\r\n",
      "\t\tFILE: Number of bytes written=702071\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=46380\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=14\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3242\r\n",
      "\t\tMap output materialized bytes=3319\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=536346624\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=6468\r\n",
      "25/08/31 12:04:01 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000004_0\r\n",
      "25/08/31 12:04:01 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000005_0\r\n",
      "25/08/31 12:04:01 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:01 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:01 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00005-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+6189\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:01 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: bufstart = 0; bufend = 3262; bufvoid = 104857600\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:01 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000005_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:01 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:01 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000005_0' done.\r\n",
      "25/08/31 12:04:01 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000005_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=168767\r\n",
      "\t\tFILE: Number of bytes written=705440\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=52569\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=16\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3262\r\n",
      "\t\tMap output materialized bytes=3337\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=1\r\n",
      "\t\tTotal committed heap usage (bytes)=536346624\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=6189\r\n",
      "25/08/31 12:04:01 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000005_0\r\n",
      "25/08/31 12:04:01 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000006_0\r\n",
      "25/08/31 12:04:01 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:01 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:01 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00006-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+6103\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:01 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: bufstart = 0; bufend = 3217; bufvoid = 104857600\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:01 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000006_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:01 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:01 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000006_0' done.\r\n",
      "25/08/31 12:04:01 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000006_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=173319\r\n",
      "\t\tFILE: Number of bytes written=708765\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=58672\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=18\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3217\r\n",
      "\t\tMap output materialized bytes=3293\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=3\r\n",
      "\t\tTotal committed heap usage (bytes)=592969728\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=6103\r\n",
      "25/08/31 12:04:01 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000006_0\r\n",
      "25/08/31 12:04:01 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000007_0\r\n",
      "25/08/31 12:04:01 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:01 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:01 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00007-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+6079\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:01 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: bufstart = 0; bufend = 2985; bufvoid = 104857600\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:01 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000007_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:01 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:01 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000007_0' done.\r\n",
      "25/08/31 12:04:01 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000007_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=177871\r\n",
      "\t\tFILE: Number of bytes written=711858\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=64751\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=20\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=2985\r\n",
      "\t\tMap output materialized bytes=3061\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=592969728\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=6079\r\n",
      "25/08/31 12:04:01 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000007_0\r\n",
      "25/08/31 12:04:01 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000008_0\r\n",
      "25/08/31 12:04:01 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:01 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:01 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00008-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+5759\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:01 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: bufstart = 0; bufend = 2836; bufvoid = 104857600\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:01 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000008_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:01 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:01 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000008_0' done.\r\n",
      "25/08/31 12:04:01 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000008_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=182423\r\n",
      "\t\tFILE: Number of bytes written=714799\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=70510\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=22\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=2836\r\n",
      "\t\tMap output materialized bytes=2909\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=698351616\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=5759\r\n",
      "25/08/31 12:04:01 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000008_0\r\n",
      "25/08/31 12:04:01 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000009_0\r\n",
      "25/08/31 12:04:01 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:01 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:01 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00009-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+5686\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:01 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: bufstart = 0; bufend = 3179; bufvoid = 104857600\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:01 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000009_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:01 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:01 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000009_0' done.\r\n",
      "25/08/31 12:04:01 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000009_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=186975\r\n",
      "\t\tFILE: Number of bytes written=718086\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=76196\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=24\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3179\r\n",
      "\t\tMap output materialized bytes=3255\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=803733504\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=5686\r\n",
      "25/08/31 12:04:01 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000009_0\r\n",
      "25/08/31 12:04:01 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000010_0\r\n",
      "25/08/31 12:04:01 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:01 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:01 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00010-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+5464\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:01 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: bufstart = 0; bufend = 2866; bufvoid = 104857600\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:01 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000010_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:01 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:01 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000010_0' done.\r\n",
      "25/08/31 12:04:01 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000010_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=191527\r\n",
      "\t\tFILE: Number of bytes written=721057\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=81660\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=26\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=2866\r\n",
      "\t\tMap output materialized bytes=2939\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=909115392\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=5464\r\n",
      "25/08/31 12:04:01 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000010_0\r\n",
      "25/08/31 12:04:01 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000011_0\r\n",
      "25/08/31 12:04:01 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:01 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:01 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00011-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+5338\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:01 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: bufstart = 0; bufend = 2722; bufvoid = 104857600\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:01 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000011_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:01 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:01 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000011_0' done.\r\n",
      "25/08/31 12:04:01 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000011_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=196079\r\n",
      "\t\tFILE: Number of bytes written=723882\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=86998\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=28\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=2722\r\n",
      "\t\tMap output materialized bytes=2793\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1014497280\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=5338\r\n",
      "25/08/31 12:04:01 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000011_0\r\n",
      "25/08/31 12:04:01 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000012_0\r\n",
      "25/08/31 12:04:01 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:01 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:01 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00013-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+5222\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:01 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: bufstart = 0; bufend = 2694; bufvoid = 104857600\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:01 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000012_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:01 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:01 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000012_0' done.\r\n",
      "25/08/31 12:04:01 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000012_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=200631\r\n",
      "\t\tFILE: Number of bytes written=726679\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=92220\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=30\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=2694\r\n",
      "\t\tMap output materialized bytes=2765\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1119879168\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=5222\r\n",
      "25/08/31 12:04:01 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000012_0\r\n",
      "25/08/31 12:04:01 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000013_0\r\n",
      "25/08/31 12:04:01 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:01 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:01 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00012-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+5169\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:01 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: bufstart = 0; bufend = 2585; bufvoid = 104857600\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:01 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000013_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:01 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:01 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000013_0' done.\r\n",
      "25/08/31 12:04:01 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000013_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=205183\r\n",
      "\t\tFILE: Number of bytes written=729368\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=97389\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=32\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=2585\r\n",
      "\t\tMap output materialized bytes=2657\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1225261056\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=5169\r\n",
      "25/08/31 12:04:01 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000013_0\r\n",
      "25/08/31 12:04:01 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000014_0\r\n",
      "25/08/31 12:04:01 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:01 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:01 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00014-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+5145\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:01 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: bufstart = 0; bufend = 2698; bufvoid = 104857600\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:01 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000014_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:01 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:01 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000014_0' done.\r\n",
      "25/08/31 12:04:01 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000014_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=209735\r\n",
      "\t\tFILE: Number of bytes written=732169\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=102534\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=34\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=2698\r\n",
      "\t\tMap output materialized bytes=2769\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1330642944\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=5145\r\n",
      "25/08/31 12:04:01 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000014_0\r\n",
      "25/08/31 12:04:01 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000015_0\r\n",
      "25/08/31 12:04:01 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:01 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:01 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00015-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+5121\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:01 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: bufstart = 0; bufend = 2462; bufvoid = 104857600\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:01 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000015_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:01 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:01 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000015_0' done.\r\n",
      "25/08/31 12:04:01 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000015_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=214287\r\n",
      "\t\tFILE: Number of bytes written=734734\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=107655\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=36\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=2462\r\n",
      "\t\tMap output materialized bytes=2533\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1436024832\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=5121\r\n",
      "25/08/31 12:04:01 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000015_0\r\n",
      "25/08/31 12:04:01 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000016_0\r\n",
      "25/08/31 12:04:01 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:01 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:01 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00017-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+5055\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:01 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: bufstart = 0; bufend = 2399; bufvoid = 104857600\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:01 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000016_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:01 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:01 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000016_0' done.\r\n",
      "25/08/31 12:04:01 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000016_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=218839\r\n",
      "\t\tFILE: Number of bytes written=737236\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=112710\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=38\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=2399\r\n",
      "\t\tMap output materialized bytes=2470\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=3\r\n",
      "\t\tTotal committed heap usage (bytes)=1540358144\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=5055\r\n",
      "25/08/31 12:04:01 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000016_0\r\n",
      "25/08/31 12:04:01 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000017_0\r\n",
      "25/08/31 12:04:01 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:01 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:01 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00025-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+4979\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:01 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:01 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: bufstart = 0; bufend = 2461; bufvoid = 104857600\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:01 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000017_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:01 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:01 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000017_0' done.\r\n",
      "25/08/31 12:04:01 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000017_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=223391\r\n",
      "\t\tFILE: Number of bytes written=739799\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=117689\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=40\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=2461\r\n",
      "\t\tMap output materialized bytes=2531\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1540358144\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4979\r\n",
      "25/08/31 12:04:01 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000017_0\r\n",
      "25/08/31 12:04:01 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000018_0\r\n",
      "25/08/31 12:04:01 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:01 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:01 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00018-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+4941\r\n",
      "25/08/31 12:04:01 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: bufstart = 0; bufend = 2473; bufvoid = 104857600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:02 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000018_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:02 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000018_0' done.\r\n",
      "25/08/31 12:04:02 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000018_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=227943\r\n",
      "\t\tFILE: Number of bytes written=742374\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=122630\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=42\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=2473\r\n",
      "\t\tMap output materialized bytes=2543\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1645740032\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4941\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000018_0\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000019_0\r\n",
      "25/08/31 12:04:02 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:02 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:02 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00016-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+4939\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: bufstart = 0; bufend = 2572; bufvoid = 104857600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:02 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000019_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:02 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000019_0' done.\r\n",
      "25/08/31 12:04:02 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000019_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=232495\r\n",
      "\t\tFILE: Number of bytes written=745049\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=127569\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=44\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=2572\r\n",
      "\t\tMap output materialized bytes=2643\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1751121920\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4939\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000019_0\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000020_0\r\n",
      "25/08/31 12:04:02 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:02 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:02 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00023-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+4875\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: bufstart = 0; bufend = 2206; bufvoid = 104857600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:02 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000020_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:02 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000020_0' done.\r\n",
      "25/08/31 12:04:02 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000020_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=237047\r\n",
      "\t\tFILE: Number of bytes written=747357\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=132444\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=46\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=2206\r\n",
      "\t\tMap output materialized bytes=2276\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1856503808\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4875\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000020_0\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000021_0\r\n",
      "25/08/31 12:04:02 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:02 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:02 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00019-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+4840\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: bufstart = 0; bufend = 2491; bufvoid = 104857600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:02 INFO mapreduce.Job: Job job_local1968043658_0001 running in uber mode : false\r\n",
      "25/08/31 12:04:02 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000021_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:02 INFO mapreduce.Job:  map 6% reduce 0%\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:02 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000021_0' done.\r\n",
      "25/08/31 12:04:02 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000021_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=241599\r\n",
      "\t\tFILE: Number of bytes written=749950\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=137284\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=48\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=2491\r\n",
      "\t\tMap output materialized bytes=2561\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1961885696\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4840\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000021_0\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000022_0\r\n",
      "25/08/31 12:04:02 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:02 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:02 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00028-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+4777\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: bufstart = 0; bufend = 2359; bufvoid = 104857600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:02 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000022_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:02 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000022_0' done.\r\n",
      "25/08/31 12:04:02 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000022_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=246151\r\n",
      "\t\tFILE: Number of bytes written=752411\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=142061\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=50\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=2359\r\n",
      "\t\tMap output materialized bytes=2429\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2067267584\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4777\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000022_0\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000023_0\r\n",
      "25/08/31 12:04:02 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:02 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:02 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00020-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+4775\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: bufstart = 0; bufend = 2190; bufvoid = 104857600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:02 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000023_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:02 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000023_0' done.\r\n",
      "25/08/31 12:04:02 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000023_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=250703\r\n",
      "\t\tFILE: Number of bytes written=754703\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=146836\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=52\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=2190\r\n",
      "\t\tMap output materialized bytes=2260\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2172649472\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4775\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000023_0\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000024_0\r\n",
      "25/08/31 12:04:02 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:02 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:02 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00024-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+4752\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: bufstart = 0; bufend = 2350; bufvoid = 104857600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:02 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000024_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:02 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000024_0' done.\r\n",
      "25/08/31 12:04:02 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000024_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=255255\r\n",
      "\t\tFILE: Number of bytes written=757155\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=151588\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=54\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=2350\r\n",
      "\t\tMap output materialized bytes=2420\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2278031360\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4752\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000024_0\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000025_0\r\n",
      "25/08/31 12:04:02 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:02 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:02 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00021-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+4677\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: bufstart = 0; bufend = 2302; bufvoid = 104857600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:02 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000025_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:02 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000025_0' done.\r\n",
      "25/08/31 12:04:02 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000025_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=259807\r\n",
      "\t\tFILE: Number of bytes written=759559\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=156265\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=56\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=2302\r\n",
      "\t\tMap output materialized bytes=2372\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=2\r\n",
      "\t\tTotal committed heap usage (bytes)=2312110080\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4677\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000025_0\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000026_0\r\n",
      "25/08/31 12:04:02 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:02 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:02 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00027-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+4637\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: bufstart = 0; bufend = 2244; bufvoid = 104857600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:02 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000026_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:02 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000026_0' done.\r\n",
      "25/08/31 12:04:02 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000026_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=264359\r\n",
      "\t\tFILE: Number of bytes written=761905\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=160902\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=58\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=2244\r\n",
      "\t\tMap output materialized bytes=2314\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2417491968\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4637\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000026_0\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000027_0\r\n",
      "25/08/31 12:04:02 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:02 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:02 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00022-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+4536\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: bufstart = 0; bufend = 2030; bufvoid = 104857600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:02 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000027_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:02 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000027_0' done.\r\n",
      "25/08/31 12:04:02 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000027_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=268911\r\n",
      "\t\tFILE: Number of bytes written=764037\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=165438\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=60\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=2030\r\n",
      "\t\tMap output materialized bytes=2100\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2522873856\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4536\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000027_0\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000028_0\r\n",
      "25/08/31 12:04:02 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:02 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:02 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00030-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+4533\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: bufstart = 0; bufend = 2111; bufvoid = 104857600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:02 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000028_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:02 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000028_0' done.\r\n",
      "25/08/31 12:04:02 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000028_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=273463\r\n",
      "\t\tFILE: Number of bytes written=766250\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=169971\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=62\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=2111\r\n",
      "\t\tMap output materialized bytes=2181\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2628255744\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4533\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000028_0\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000029_0\r\n",
      "25/08/31 12:04:02 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:02 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:02 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00036-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+4517\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: bufstart = 0; bufend = 2154; bufvoid = 104857600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:02 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000029_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:02 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000029_0' done.\r\n",
      "25/08/31 12:04:02 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000029_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=278015\r\n",
      "\t\tFILE: Number of bytes written=768506\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=174488\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=64\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=2154\r\n",
      "\t\tMap output materialized bytes=2224\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2733637632\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4517\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000029_0\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000030_0\r\n",
      "25/08/31 12:04:02 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:02 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:02 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00032-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+4459\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: bufstart = 0; bufend = 2089; bufvoid = 104857600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:02 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000030_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:02 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000030_0' done.\r\n",
      "25/08/31 12:04:02 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000030_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=282567\r\n",
      "\t\tFILE: Number of bytes written=770697\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=178947\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=66\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=2089\r\n",
      "\t\tMap output materialized bytes=2159\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2839019520\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4459\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000030_0\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000031_0\r\n",
      "25/08/31 12:04:02 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:02 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:02 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00034-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+4420\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: bufstart = 0; bufend = 2053; bufvoid = 104857600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:02 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000031_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:02 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000031_0' done.\r\n",
      "25/08/31 12:04:02 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000031_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=287119\r\n",
      "\t\tFILE: Number of bytes written=772852\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=183367\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=68\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=2053\r\n",
      "\t\tMap output materialized bytes=2123\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2944401408\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4420\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000031_0\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000032_0\r\n",
      "25/08/31 12:04:02 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:02 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:02 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00029-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+4415\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: bufstart = 0; bufend = 2009; bufvoid = 104857600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:02 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000032_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:02 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000032_0' done.\r\n",
      "25/08/31 12:04:02 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000032_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=291671\r\n",
      "\t\tFILE: Number of bytes written=774963\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=187782\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=70\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=2009\r\n",
      "\t\tMap output materialized bytes=2079\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=3049783296\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4415\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000032_0\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000033_0\r\n",
      "25/08/31 12:04:02 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:02 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:02 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00031-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+4405\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: bufstart = 0; bufend = 2024; bufvoid = 104857600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:02 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000033_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:02 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000033_0' done.\r\n",
      "25/08/31 12:04:02 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000033_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=296223\r\n",
      "\t\tFILE: Number of bytes written=777089\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=192187\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=72\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=2024\r\n",
      "\t\tMap output materialized bytes=2094\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=3155165184\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4405\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000033_0\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000034_0\r\n",
      "25/08/31 12:04:02 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:02 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:02 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00037-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+4395\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: bufstart = 0; bufend = 1873; bufvoid = 104857600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:02 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000034_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:02 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000034_0' done.\r\n",
      "25/08/31 12:04:02 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000034_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=300775\r\n",
      "\t\tFILE: Number of bytes written=779064\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=196582\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=74\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1873\r\n",
      "\t\tMap output materialized bytes=1943\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=3260547072\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4395\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000034_0\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000035_0\r\n",
      "25/08/31 12:04:02 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:02 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:02 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00026-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+4394\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: bufstart = 0; bufend = 2109; bufvoid = 104857600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:02 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000035_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:02 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000035_0' done.\r\n",
      "25/08/31 12:04:02 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000035_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=305327\r\n",
      "\t\tFILE: Number of bytes written=781275\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=200976\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=76\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=2109\r\n",
      "\t\tMap output materialized bytes=2179\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=3365928960\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4394\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000035_0\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000036_0\r\n",
      "25/08/31 12:04:02 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:02 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:02 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00033-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+4388\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: bufstart = 0; bufend = 1946; bufvoid = 104857600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:02 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000036_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:02 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000036_0' done.\r\n",
      "25/08/31 12:04:02 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000036_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=309879\r\n",
      "\t\tFILE: Number of bytes written=783323\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=205364\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=78\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1946\r\n",
      "\t\tMap output materialized bytes=2016\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=3471310848\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4388\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000036_0\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000037_0\r\n",
      "25/08/31 12:04:02 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:02 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:02 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00038-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+4357\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: bufstart = 0; bufend = 1984; bufvoid = 104857600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:02 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000037_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:02 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000037_0' done.\r\n",
      "25/08/31 12:04:02 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000037_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=314431\r\n",
      "\t\tFILE: Number of bytes written=785409\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=209721\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=80\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1984\r\n",
      "\t\tMap output materialized bytes=2054\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=3576692736\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4357\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000037_0\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000038_0\r\n",
      "25/08/31 12:04:02 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:02 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:02 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00052-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+4330\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: bufstart = 0; bufend = 2008; bufvoid = 104857600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:02 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000038_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:02 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000038_0' done.\r\n",
      "25/08/31 12:04:02 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000038_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=318983\r\n",
      "\t\tFILE: Number of bytes written=787519\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=214051\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=82\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=2008\r\n",
      "\t\tMap output materialized bytes=2078\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=3682074624\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4330\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000038_0\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000039_0\r\n",
      "25/08/31 12:04:02 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:02 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:02 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00035-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+4316\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: bufstart = 0; bufend = 2001; bufvoid = 104857600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:02 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000039_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:02 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000039_0' done.\r\n",
      "25/08/31 12:04:02 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000039_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=323535\r\n",
      "\t\tFILE: Number of bytes written=789622\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=218367\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=84\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=2001\r\n",
      "\t\tMap output materialized bytes=2071\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=3787456512\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4316\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000039_0\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000040_0\r\n",
      "25/08/31 12:04:02 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:02 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:02 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00044-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+4316\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: bufstart = 0; bufend = 1914; bufvoid = 104857600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:02 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000040_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:02 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000040_0' done.\r\n",
      "25/08/31 12:04:02 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000040_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=328087\r\n",
      "\t\tFILE: Number of bytes written=791638\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=222683\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=86\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1914\r\n",
      "\t\tMap output materialized bytes=1984\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=4\r\n",
      "\t\tTotal committed heap usage (bytes)=3899654144\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4316\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000040_0\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000041_0\r\n",
      "25/08/31 12:04:02 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:02 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:02 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00051-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+4292\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: bufstart = 0; bufend = 1906; bufvoid = 104857600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:02 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000041_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:02 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000041_0' done.\r\n",
      "25/08/31 12:04:02 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000041_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=332639\r\n",
      "\t\tFILE: Number of bytes written=793646\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=226975\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=88\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1906\r\n",
      "\t\tMap output materialized bytes=1976\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=3899654144\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4292\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000041_0\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000042_0\r\n",
      "25/08/31 12:04:02 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:02 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:02 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00048-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+4277\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: bufstart = 0; bufend = 1840; bufvoid = 104857600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:02 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000042_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:02 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000042_0' done.\r\n",
      "25/08/31 12:04:02 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000042_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=337191\r\n",
      "\t\tFILE: Number of bytes written=795588\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=231252\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=90\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1840\r\n",
      "\t\tMap output materialized bytes=1910\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=4005036032\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4277\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000042_0\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000043_0\r\n",
      "25/08/31 12:04:02 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:02 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:02 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00049-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+4257\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: bufstart = 0; bufend = 1907; bufvoid = 104857600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:02 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000043_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:02 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000043_0' done.\r\n",
      "25/08/31 12:04:02 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000043_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=341743\r\n",
      "\t\tFILE: Number of bytes written=797597\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=235509\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=92\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1907\r\n",
      "\t\tMap output materialized bytes=1977\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=4110417920\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4257\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000043_0\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000044_0\r\n",
      "25/08/31 12:04:02 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:02 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:02 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00039-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+4245\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:02 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: bufstart = 0; bufend = 1738; bufvoid = 104857600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:02 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000044_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:02 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000044_0' done.\r\n",
      "25/08/31 12:04:02 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000044_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=346295\r\n",
      "\t\tFILE: Number of bytes written=799437\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=239754\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=94\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1738\r\n",
      "\t\tMap output materialized bytes=1808\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=4215799808\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4245\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000044_0\r\n",
      "25/08/31 12:04:02 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000045_0\r\n",
      "25/08/31 12:04:02 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:02 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:02 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00042-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+4202\r\n",
      "25/08/31 12:04:02 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: bufstart = 0; bufend = 1820; bufvoid = 104857600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000045_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000045_0' done.\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000045_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=350847\r\n",
      "\t\tFILE: Number of bytes written=801359\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=243956\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=96\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1820\r\n",
      "\t\tMap output materialized bytes=1890\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=4321181696\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4202\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000045_0\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000046_0\r\n",
      "25/08/31 12:04:03 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:03 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:03 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00060-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+4186\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: bufstart = 0; bufend = 1983; bufvoid = 104857600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000046_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000046_0' done.\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000046_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=355399\r\n",
      "\t\tFILE: Number of bytes written=803444\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=248142\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=98\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1983\r\n",
      "\t\tMap output materialized bytes=2053\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=4426563584\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4186\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000046_0\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000047_0\r\n",
      "25/08/31 12:04:03 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:03 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:03 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00041-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+4179\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: bufstart = 0; bufend = 1721; bufvoid = 104857600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000047_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000047_0' done.\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000047_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=359951\r\n",
      "\t\tFILE: Number of bytes written=805267\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=252321\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=100\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1721\r\n",
      "\t\tMap output materialized bytes=1791\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=4531945472\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4179\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000047_0\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000048_0\r\n",
      "25/08/31 12:04:03 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:03 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:03 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00065-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+4179\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: bufstart = 0; bufend = 1789; bufvoid = 104857600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000048_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000048_0' done.\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000048_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=364503\r\n",
      "\t\tFILE: Number of bytes written=807158\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=256500\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=102\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1789\r\n",
      "\t\tMap output materialized bytes=1859\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=4637327360\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4179\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000048_0\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000049_0\r\n",
      "25/08/31 12:04:03 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:03 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:03 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00056-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+4151\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:03 INFO mapreduce.Job:  map 100% reduce 0%\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: bufstart = 0; bufend = 1783; bufvoid = 104857600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000049_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000049_0' done.\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000049_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=369055\r\n",
      "\t\tFILE: Number of bytes written=809043\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=260651\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=104\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1783\r\n",
      "\t\tMap output materialized bytes=1853\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=4742709248\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4151\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000049_0\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000050_0\r\n",
      "25/08/31 12:04:03 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:03 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:03 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00070-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+4150\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: bufstart = 0; bufend = 1914; bufvoid = 104857600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000050_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000050_0' done.\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000050_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=373607\r\n",
      "\t\tFILE: Number of bytes written=811059\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=264801\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=106\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1914\r\n",
      "\t\tMap output materialized bytes=1984\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=4848091136\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4150\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000050_0\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000051_0\r\n",
      "25/08/31 12:04:03 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:03 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:03 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00054-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+4146\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: bufstart = 0; bufend = 1842; bufvoid = 104857600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000051_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000051_0' done.\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000051_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=378159\r\n",
      "\t\tFILE: Number of bytes written=813003\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=268947\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=108\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1842\r\n",
      "\t\tMap output materialized bytes=1912\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=4953473024\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4146\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000051_0\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000052_0\r\n",
      "25/08/31 12:04:03 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:03 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:03 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00043-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+4132\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: bufstart = 0; bufend = 1898; bufvoid = 104857600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000052_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000052_0' done.\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000052_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=382711\r\n",
      "\t\tFILE: Number of bytes written=815003\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=273079\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=110\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1898\r\n",
      "\t\tMap output materialized bytes=1968\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=5058854912\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4132\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000052_0\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000053_0\r\n",
      "25/08/31 12:04:03 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:03 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:03 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00066-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+4132\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: bufstart = 0; bufend = 1717; bufvoid = 104857600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000053_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000053_0' done.\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000053_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=387263\r\n",
      "\t\tFILE: Number of bytes written=816822\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=277211\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=112\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1717\r\n",
      "\t\tMap output materialized bytes=1787\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=5164236800\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4132\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000053_0\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000054_0\r\n",
      "25/08/31 12:04:03 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:03 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:03 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00040-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+4112\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: bufstart = 0; bufend = 1925; bufvoid = 104857600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000054_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000054_0' done.\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000054_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=391815\r\n",
      "\t\tFILE: Number of bytes written=818849\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=281323\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=114\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1925\r\n",
      "\t\tMap output materialized bytes=1995\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=5269618688\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4112\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000054_0\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000055_0\r\n",
      "25/08/31 12:04:03 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:03 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:03 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00046-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+4103\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: bufstart = 0; bufend = 1821; bufvoid = 104857600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000055_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000055_0' done.\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000055_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=396367\r\n",
      "\t\tFILE: Number of bytes written=820772\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=285426\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=116\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1821\r\n",
      "\t\tMap output materialized bytes=1891\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=5375000576\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4103\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000055_0\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000056_0\r\n",
      "25/08/31 12:04:03 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:03 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:03 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00068-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+4099\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: bufstart = 0; bufend = 1691; bufvoid = 104857600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000056_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000056_0' done.\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000056_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=400919\r\n",
      "\t\tFILE: Number of bytes written=822565\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=289525\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=118\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1691\r\n",
      "\t\tMap output materialized bytes=1761\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=5480382464\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4099\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000056_0\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000057_0\r\n",
      "25/08/31 12:04:03 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:03 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:03 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00063-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+4084\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: bufstart = 0; bufend = 1952; bufvoid = 104857600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000057_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000057_0' done.\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000057_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=405471\r\n",
      "\t\tFILE: Number of bytes written=824619\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=293609\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=120\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1952\r\n",
      "\t\tMap output materialized bytes=2022\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=4\r\n",
      "\t\tTotal committed heap usage (bytes)=5500305408\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4084\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000057_0\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000058_0\r\n",
      "25/08/31 12:04:03 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:03 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:03 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00047-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+4068\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: bufstart = 0; bufend = 1792; bufvoid = 104857600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000058_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000058_0' done.\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000058_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=410023\r\n",
      "\t\tFILE: Number of bytes written=826513\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=297677\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=122\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1792\r\n",
      "\t\tMap output materialized bytes=1862\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=4\r\n",
      "\t\tTotal committed heap usage (bytes)=5504499712\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4068\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000058_0\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000059_0\r\n",
      "25/08/31 12:04:03 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:03 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:03 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00075-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+4053\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: bufstart = 0; bufend = 1735; bufvoid = 104857600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000059_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000059_0' done.\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000059_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=414575\r\n",
      "\t\tFILE: Number of bytes written=828350\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=301730\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=124\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1735\r\n",
      "\t\tMap output materialized bytes=1805\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=5\r\n",
      "\t\tTotal committed heap usage (bytes)=5577900032\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4053\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000059_0\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000060_0\r\n",
      "25/08/31 12:04:03 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:03 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:03 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00058-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+4036\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: bufstart = 0; bufend = 1837; bufvoid = 104857600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000060_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000060_0' done.\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000060_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=419127\r\n",
      "\t\tFILE: Number of bytes written=830289\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=305766\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=126\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1837\r\n",
      "\t\tMap output materialized bytes=1907\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=5577900032\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4036\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000060_0\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000061_0\r\n",
      "25/08/31 12:04:03 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:03 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:03 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00089-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+4024\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: bufstart = 0; bufend = 1756; bufvoid = 104857600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000061_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000061_0' done.\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000061_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=423679\r\n",
      "\t\tFILE: Number of bytes written=832147\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=309790\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=128\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1756\r\n",
      "\t\tMap output materialized bytes=1826\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=4\r\n",
      "\t\tTotal committed heap usage (bytes)=5576327168\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4024\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000061_0\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000062_0\r\n",
      "25/08/31 12:04:03 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:03 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:03 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00081-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+4020\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: bufstart = 0; bufend = 1829; bufvoid = 104857600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000062_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000062_0' done.\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000062_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=428231\r\n",
      "\t\tFILE: Number of bytes written=834078\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=313810\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=130\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1829\r\n",
      "\t\tMap output materialized bytes=1899\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=5576327168\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4020\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000062_0\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000063_0\r\n",
      "25/08/31 12:04:03 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:03 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:03 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00055-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+4008\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: bufstart = 0; bufend = 1811; bufvoid = 104857600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000063_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000063_0' done.\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000063_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=432783\r\n",
      "\t\tFILE: Number of bytes written=835991\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=317818\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=132\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1811\r\n",
      "\t\tMap output materialized bytes=1881\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=4\r\n",
      "\t\tTotal committed heap usage (bytes)=5689049088\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4008\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000063_0\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000064_0\r\n",
      "25/08/31 12:04:03 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:03 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:03 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00050-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+4007\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: bufstart = 0; bufend = 1670; bufvoid = 104857600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000064_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000064_0' done.\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000064_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=437335\r\n",
      "\t\tFILE: Number of bytes written=837763\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=321825\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=134\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1670\r\n",
      "\t\tMap output materialized bytes=1740\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=5689049088\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4007\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000064_0\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000065_0\r\n",
      "25/08/31 12:04:03 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:03 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:03 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00062-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+4004\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: bufstart = 0; bufend = 1741; bufvoid = 104857600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000065_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000065_0' done.\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000065_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=441887\r\n",
      "\t\tFILE: Number of bytes written=839606\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=325829\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=136\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1741\r\n",
      "\t\tMap output materialized bytes=1811\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=5689049088\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4004\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000065_0\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000066_0\r\n",
      "25/08/31 12:04:03 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:03 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:03 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00059-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+4001\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: bufstart = 0; bufend = 1829; bufvoid = 104857600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000066_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000066_0' done.\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000066_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=446439\r\n",
      "\t\tFILE: Number of bytes written=841537\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=329830\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=138\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1829\r\n",
      "\t\tMap output materialized bytes=1899\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=4\r\n",
      "\t\tTotal committed heap usage (bytes)=5689573376\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4001\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000066_0\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000067_0\r\n",
      "25/08/31 12:04:03 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:03 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:03 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00069-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3994\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: bufstart = 0; bufend = 1749; bufvoid = 104857600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000067_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000067_0' done.\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000067_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=450991\r\n",
      "\t\tFILE: Number of bytes written=843388\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=333824\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=140\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1749\r\n",
      "\t\tMap output materialized bytes=1819\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=5689573376\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3994\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000067_0\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000068_0\r\n",
      "25/08/31 12:04:03 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:03 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:03 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00045-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3992\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: bufstart = 0; bufend = 1694; bufvoid = 104857600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000068_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000068_0' done.\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000068_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=455543\r\n",
      "\t\tFILE: Number of bytes written=845184\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=337816\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=142\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1694\r\n",
      "\t\tMap output materialized bytes=1764\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=5689573376\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3992\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000068_0\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000069_0\r\n",
      "25/08/31 12:04:03 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:03 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:03 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00080-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3986\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: bufstart = 0; bufend = 1677; bufvoid = 104857600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000069_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000069_0' done.\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000069_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=460095\r\n",
      "\t\tFILE: Number of bytes written=846963\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=341802\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=144\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1677\r\n",
      "\t\tMap output materialized bytes=1747\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=4\r\n",
      "\t\tTotal committed heap usage (bytes)=5835849728\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3986\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000069_0\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000070_0\r\n",
      "25/08/31 12:04:03 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:03 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:03 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00064-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3979\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: bufstart = 0; bufend = 1690; bufvoid = 104857600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000070_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000070_0' done.\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000070_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=464647\r\n",
      "\t\tFILE: Number of bytes written=848755\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=345781\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=146\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1690\r\n",
      "\t\tMap output materialized bytes=1760\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=5835849728\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3979\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000070_0\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000071_0\r\n",
      "25/08/31 12:04:03 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:03 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:03 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00053-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3965\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: bufstart = 0; bufend = 1650; bufvoid = 104857600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000071_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000071_0' done.\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000071_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=469199\r\n",
      "\t\tFILE: Number of bytes written=850507\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=349746\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=148\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1650\r\n",
      "\t\tMap output materialized bytes=1720\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=5835849728\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3965\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000071_0\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000072_0\r\n",
      "25/08/31 12:04:03 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:03 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:03 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00086-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3958\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: bufstart = 0; bufend = 1570; bufvoid = 104857600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000072_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000072_0' done.\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000072_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=473751\r\n",
      "\t\tFILE: Number of bytes written=852179\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=353704\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=150\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1570\r\n",
      "\t\tMap output materialized bytes=1640\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=5835849728\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3958\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000072_0\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000073_0\r\n",
      "25/08/31 12:04:03 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:03 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:03 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00067-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3956\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: bufstart = 0; bufend = 1762; bufvoid = 104857600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000073_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000073_0' done.\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000073_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=478303\r\n",
      "\t\tFILE: Number of bytes written=854043\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=357660\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=152\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1762\r\n",
      "\t\tMap output materialized bytes=1832\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=4\r\n",
      "\t\tTotal committed heap usage (bytes)=5840044032\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3956\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000073_0\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000074_0\r\n",
      "25/08/31 12:04:03 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:03 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:03 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00057-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3954\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: bufstart = 0; bufend = 1750; bufvoid = 104857600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000074_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000074_0' done.\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000074_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=482855\r\n",
      "\t\tFILE: Number of bytes written=855895\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=361614\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=154\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1750\r\n",
      "\t\tMap output materialized bytes=1820\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=5840044032\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3954\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000074_0\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000075_0\r\n",
      "25/08/31 12:04:03 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:03 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:03 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00079-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3954\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: bufstart = 0; bufend = 1570; bufvoid = 104857600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000075_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000075_0' done.\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000075_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=487407\r\n",
      "\t\tFILE: Number of bytes written=857567\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=365568\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=156\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1570\r\n",
      "\t\tMap output materialized bytes=1640\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=5840044032\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3954\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000075_0\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000076_0\r\n",
      "25/08/31 12:04:03 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:03 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:03 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00077-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3944\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: bufstart = 0; bufend = 1714; bufvoid = 104857600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000076_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000076_0' done.\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000076_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=491959\r\n",
      "\t\tFILE: Number of bytes written=859383\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=369512\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=158\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1714\r\n",
      "\t\tMap output materialized bytes=1784\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=5840044032\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3944\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000076_0\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000077_0\r\n",
      "25/08/31 12:04:03 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:03 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:03 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00083-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3943\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: bufstart = 0; bufend = 1644; bufvoid = 104857600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000077_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000077_0' done.\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000077_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=496511\r\n",
      "\t\tFILE: Number of bytes written=861129\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=373455\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=160\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1644\r\n",
      "\t\tMap output materialized bytes=1714\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=4\r\n",
      "\t\tTotal committed heap usage (bytes)=5964824576\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3943\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000077_0\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000078_0\r\n",
      "25/08/31 12:04:03 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:03 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:03 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00094-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3927\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: bufstart = 0; bufend = 1606; bufvoid = 104857600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000078_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000078_0' done.\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000078_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=501063\r\n",
      "\t\tFILE: Number of bytes written=862837\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=377382\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=162\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1606\r\n",
      "\t\tMap output materialized bytes=1676\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=5964824576\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3927\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000078_0\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000079_0\r\n",
      "25/08/31 12:04:03 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:03 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:03 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00061-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3925\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: bufstart = 0; bufend = 1677; bufvoid = 104857600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000079_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000079_0' done.\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000079_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=505615\r\n",
      "\t\tFILE: Number of bytes written=864616\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=381307\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=164\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1677\r\n",
      "\t\tMap output materialized bytes=1747\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=5964824576\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3925\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000079_0\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000080_0\r\n",
      "25/08/31 12:04:03 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:03 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:03 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00073-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3921\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: bufstart = 0; bufend = 1813; bufvoid = 104857600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000080_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000080_0' done.\r\n",
      "25/08/31 12:04:03 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000080_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=510167\r\n",
      "\t\tFILE: Number of bytes written=866531\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=385228\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=166\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1813\r\n",
      "\t\tMap output materialized bytes=1883\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=5964824576\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3921\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000080_0\r\n",
      "25/08/31 12:04:03 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000081_0\r\n",
      "25/08/31 12:04:03 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:03 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:03 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00087-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3917\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:03 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:03 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: bufstart = 0; bufend = 1657; bufvoid = 104857600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000081_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000081_0' done.\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000081_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=514719\r\n",
      "\t\tFILE: Number of bytes written=868290\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=389145\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=168\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1657\r\n",
      "\t\tMap output materialized bytes=1727\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=5964824576\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3917\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000081_0\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000082_0\r\n",
      "25/08/31 12:04:04 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:04 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:04 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00090-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3917\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: bufstart = 0; bufend = 1759; bufvoid = 104857600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:04 INFO mapreduce.Job:  map 24% reduce 0%\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000082_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000082_0' done.\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000082_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=519271\r\n",
      "\t\tFILE: Number of bytes written=870151\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=393062\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=170\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1759\r\n",
      "\t\tMap output materialized bytes=1829\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=247\r\n",
      "\t\tTotal committed heap usage (bytes)=1222639616\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3917\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000082_0\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000083_0\r\n",
      "25/08/31 12:04:04 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:04 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:04 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00092-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3914\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: bufstart = 0; bufend = 1661; bufvoid = 104857600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000083_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000083_0' done.\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000083_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=523823\r\n",
      "\t\tFILE: Number of bytes written=871914\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=396976\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=172\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1661\r\n",
      "\t\tMap output materialized bytes=1731\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1222639616\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3914\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000083_0\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000084_0\r\n",
      "25/08/31 12:04:04 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:04 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:04 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00076-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3903\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: bufstart = 0; bufend = 1652; bufvoid = 104857600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000084_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000084_0' done.\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000084_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=528375\r\n",
      "\t\tFILE: Number of bytes written=873668\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=400879\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=174\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1652\r\n",
      "\t\tMap output materialized bytes=1722\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1222639616\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3903\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000084_0\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000085_0\r\n",
      "25/08/31 12:04:04 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:04 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:04 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00074-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3898\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: bufstart = 0; bufend = 1784; bufvoid = 104857600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000085_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000085_0' done.\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000085_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=532927\r\n",
      "\t\tFILE: Number of bytes written=875554\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=404777\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=176\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1784\r\n",
      "\t\tMap output materialized bytes=1854\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1222639616\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3898\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000085_0\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000086_0\r\n",
      "25/08/31 12:04:04 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:04 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:04 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00078-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3878\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: bufstart = 0; bufend = 1727; bufvoid = 104857600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000086_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000086_0' done.\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000086_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=537479\r\n",
      "\t\tFILE: Number of bytes written=877383\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=408655\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=178\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1727\r\n",
      "\t\tMap output materialized bytes=1797\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1222639616\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3878\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000086_0\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000087_0\r\n",
      "25/08/31 12:04:04 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:04 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:04 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00088-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3876\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: bufstart = 0; bufend = 1635; bufvoid = 104857600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000087_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000087_0' done.\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000087_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=542031\r\n",
      "\t\tFILE: Number of bytes written=879120\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=412531\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=180\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1635\r\n",
      "\t\tMap output materialized bytes=1705\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1222639616\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3876\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000087_0\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000088_0\r\n",
      "25/08/31 12:04:04 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:04 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:04 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00112-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3868\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: bufstart = 0; bufend = 1545; bufvoid = 104857600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000088_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000088_0' done.\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000088_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=546583\r\n",
      "\t\tFILE: Number of bytes written=880767\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=416399\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=182\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1545\r\n",
      "\t\tMap output materialized bytes=1615\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=1\r\n",
      "\t\tTotal committed heap usage (bytes)=1387266048\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3868\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000088_0\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000089_0\r\n",
      "25/08/31 12:04:04 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:04 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:04 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00085-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3864\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: bufstart = 0; bufend = 1525; bufvoid = 104857600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000089_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000089_0' done.\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000089_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=551135\r\n",
      "\t\tFILE: Number of bytes written=882394\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=420263\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=184\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1525\r\n",
      "\t\tMap output materialized bytes=1595\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1387266048\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3864\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000089_0\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000090_0\r\n",
      "25/08/31 12:04:04 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:04 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:04 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00071-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3849\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: bufstart = 0; bufend = 1555; bufvoid = 104857600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000090_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000090_0' done.\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000090_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=555687\r\n",
      "\t\tFILE: Number of bytes written=884051\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=424112\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=186\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1555\r\n",
      "\t\tMap output materialized bytes=1625\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1387266048\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3849\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000090_0\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000091_0\r\n",
      "25/08/31 12:04:04 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:04 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:04 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00084-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3849\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: bufstart = 0; bufend = 1660; bufvoid = 104857600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000091_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000091_0' done.\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000091_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=560239\r\n",
      "\t\tFILE: Number of bytes written=885813\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=427961\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=188\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1660\r\n",
      "\t\tMap output materialized bytes=1730\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1387266048\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3849\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000091_0\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000092_0\r\n",
      "25/08/31 12:04:04 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:04 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:04 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00105-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3830\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: bufstart = 0; bufend = 1439; bufvoid = 104857600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000092_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000092_0' done.\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000092_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=564791\r\n",
      "\t\tFILE: Number of bytes written=887354\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=431791\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=190\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1439\r\n",
      "\t\tMap output materialized bytes=1509\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1387266048\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3830\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000092_0\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000093_0\r\n",
      "25/08/31 12:04:04 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:04 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:04 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00102-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3820\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: bufstart = 0; bufend = 1532; bufvoid = 104857600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000093_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000093_0' done.\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000093_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=569343\r\n",
      "\t\tFILE: Number of bytes written=888988\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=435611\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=192\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1532\r\n",
      "\t\tMap output materialized bytes=1602\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1387266048\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3820\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000093_0\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000094_0\r\n",
      "25/08/31 12:04:04 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:04 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:04 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00082-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3815\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: bufstart = 0; bufend = 1546; bufvoid = 104857600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000094_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000094_0' done.\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000094_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=573895\r\n",
      "\t\tFILE: Number of bytes written=890636\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=439426\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=194\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1546\r\n",
      "\t\tMap output materialized bytes=1616\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1387266048\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3815\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000094_0\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000095_0\r\n",
      "25/08/31 12:04:04 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:04 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:04 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00091-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3814\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: bufstart = 0; bufend = 1649; bufvoid = 104857600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000095_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000095_0' done.\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000095_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=578447\r\n",
      "\t\tFILE: Number of bytes written=892387\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=443240\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=196\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1649\r\n",
      "\t\tMap output materialized bytes=1719\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=1\r\n",
      "\t\tTotal committed heap usage (bytes)=1400373248\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3814\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000095_0\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000096_0\r\n",
      "25/08/31 12:04:04 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:04 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:04 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00096-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3801\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: bufstart = 0; bufend = 1537; bufvoid = 104857600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000096_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000096_0' done.\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000096_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=582999\r\n",
      "\t\tFILE: Number of bytes written=894026\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=447041\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=198\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1537\r\n",
      "\t\tMap output materialized bytes=1607\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1400373248\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3801\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000096_0\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000097_0\r\n",
      "25/08/31 12:04:04 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:04 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:04 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00101-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3791\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: bufstart = 0; bufend = 1554; bufvoid = 104857600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000097_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000097_0' done.\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000097_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=587551\r\n",
      "\t\tFILE: Number of bytes written=895682\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=450832\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=200\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1554\r\n",
      "\t\tMap output materialized bytes=1624\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1400373248\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3791\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000097_0\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000098_0\r\n",
      "25/08/31 12:04:04 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:04 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:04 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00098-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3786\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: bufstart = 0; bufend = 1624; bufvoid = 104857600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000098_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000098_0' done.\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000098_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=592103\r\n",
      "\t\tFILE: Number of bytes written=897408\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=454618\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=202\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1624\r\n",
      "\t\tMap output materialized bytes=1694\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1400373248\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3786\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000098_0\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000099_0\r\n",
      "25/08/31 12:04:04 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:04 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:04 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00095-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3777\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: bufstart = 0; bufend = 1517; bufvoid = 104857600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000099_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000099_0' done.\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000099_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=596655\r\n",
      "\t\tFILE: Number of bytes written=899027\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=458395\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=204\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1517\r\n",
      "\t\tMap output materialized bytes=1587\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1400373248\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3777\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000099_0\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000100_0\r\n",
      "25/08/31 12:04:04 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:04 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:04 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00099-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3774\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: bufstart = 0; bufend = 1646; bufvoid = 104857600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000100_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000100_0' done.\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000100_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=601207\r\n",
      "\t\tFILE: Number of bytes written=900775\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=462169\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=206\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1646\r\n",
      "\t\tMap output materialized bytes=1716\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1400373248\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3774\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000100_0\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000101_0\r\n",
      "25/08/31 12:04:04 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:04 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:04 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00109-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3772\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: bufstart = 0; bufend = 1542; bufvoid = 104857600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000101_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000101_0' done.\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000101_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=605759\r\n",
      "\t\tFILE: Number of bytes written=902419\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=465941\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=208\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1542\r\n",
      "\t\tMap output materialized bytes=1612\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1400373248\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3772\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000101_0\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000102_0\r\n",
      "25/08/31 12:04:04 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:04 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:04 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00111-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3771\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: bufstart = 0; bufend = 1566; bufvoid = 104857600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000102_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000102_0' done.\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000102_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=610311\r\n",
      "\t\tFILE: Number of bytes written=904087\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=469712\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=210\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1566\r\n",
      "\t\tMap output materialized bytes=1636\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=1\r\n",
      "\t\tTotal committed heap usage (bytes)=1568145408\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3771\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000102_0\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000103_0\r\n",
      "25/08/31 12:04:04 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:04 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:04 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00107-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3767\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: bufstart = 0; bufend = 1558; bufvoid = 104857600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000103_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000103_0' done.\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000103_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=614863\r\n",
      "\t\tFILE: Number of bytes written=905747\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=473479\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=212\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1558\r\n",
      "\t\tMap output materialized bytes=1628\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1568145408\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3767\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000103_0\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000104_0\r\n",
      "25/08/31 12:04:04 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:04 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:04 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00093-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3764\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: bufstart = 0; bufend = 1578; bufvoid = 104857600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000104_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000104_0' done.\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000104_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=619415\r\n",
      "\t\tFILE: Number of bytes written=907427\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=477243\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=214\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1578\r\n",
      "\t\tMap output materialized bytes=1648\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1568145408\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3764\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000104_0\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000105_0\r\n",
      "25/08/31 12:04:04 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:04 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:04 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00116-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3716\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: bufstart = 0; bufend = 1442; bufvoid = 104857600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000105_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000105_0' done.\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000105_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=623967\r\n",
      "\t\tFILE: Number of bytes written=908971\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=480959\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=216\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1442\r\n",
      "\t\tMap output materialized bytes=1512\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1568145408\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3716\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000105_0\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000106_0\r\n",
      "25/08/31 12:04:04 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:04 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:04 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00104-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3701\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: bufstart = 0; bufend = 1595; bufvoid = 104857600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000106_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000106_0' done.\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000106_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=628519\r\n",
      "\t\tFILE: Number of bytes written=910668\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=484660\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=218\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1595\r\n",
      "\t\tMap output materialized bytes=1665\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1568145408\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3701\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000106_0\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000107_0\r\n",
      "25/08/31 12:04:04 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:04 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:04 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00119-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3681\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: bufstart = 0; bufend = 1444; bufvoid = 104857600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000107_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000107_0' done.\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000107_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=633071\r\n",
      "\t\tFILE: Number of bytes written=912214\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=488341\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=220\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1444\r\n",
      "\t\tMap output materialized bytes=1514\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1568145408\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3681\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000107_0\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000108_0\r\n",
      "25/08/31 12:04:04 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:04 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:04 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00114-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3675\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: bufstart = 0; bufend = 1570; bufvoid = 104857600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000108_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000108_0' done.\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000108_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=637623\r\n",
      "\t\tFILE: Number of bytes written=913886\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=492016\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=222\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1570\r\n",
      "\t\tMap output materialized bytes=1640\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1568145408\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3675\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000108_0\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000109_0\r\n",
      "25/08/31 12:04:04 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:04 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:04 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00128-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3672\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: bufstart = 0; bufend = 1541; bufvoid = 104857600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000109_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000109_0' done.\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000109_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=642175\r\n",
      "\t\tFILE: Number of bytes written=915529\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=495688\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=224\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1541\r\n",
      "\t\tMap output materialized bytes=1611\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1568145408\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3672\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000109_0\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000110_0\r\n",
      "25/08/31 12:04:04 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:04 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:04 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00100-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3670\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: bufstart = 0; bufend = 1542; bufvoid = 104857600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000110_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000110_0' done.\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000110_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=646727\r\n",
      "\t\tFILE: Number of bytes written=917173\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=499358\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=226\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1542\r\n",
      "\t\tMap output materialized bytes=1612\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=2\r\n",
      "\t\tTotal committed heap usage (bytes)=1589116928\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3670\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000110_0\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000111_0\r\n",
      "25/08/31 12:04:04 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:04 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:04 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00124-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3655\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: bufstart = 0; bufend = 1592; bufvoid = 104857600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000111_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000111_0' done.\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000111_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=651279\r\n",
      "\t\tFILE: Number of bytes written=918867\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=503013\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=228\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1592\r\n",
      "\t\tMap output materialized bytes=1662\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1589116928\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3655\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000111_0\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000112_0\r\n",
      "25/08/31 12:04:04 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:04 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:04 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00120-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3639\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: bufstart = 0; bufend = 1498; bufvoid = 104857600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000112_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000112_0' done.\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000112_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=655831\r\n",
      "\t\tFILE: Number of bytes written=920467\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=506652\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=230\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1498\r\n",
      "\t\tMap output materialized bytes=1568\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1589116928\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3639\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000112_0\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000113_0\r\n",
      "25/08/31 12:04:04 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:04 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:04 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00106-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3635\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: bufstart = 0; bufend = 1463; bufvoid = 104857600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000113_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000113_0' done.\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000113_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=660383\r\n",
      "\t\tFILE: Number of bytes written=922032\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=510287\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=232\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1463\r\n",
      "\t\tMap output materialized bytes=1533\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1589116928\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3635\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000113_0\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000114_0\r\n",
      "25/08/31 12:04:04 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:04 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:04 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00108-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3626\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: bufstart = 0; bufend = 1419; bufvoid = 104857600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000114_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000114_0' done.\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000114_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=664935\r\n",
      "\t\tFILE: Number of bytes written=923553\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=513913\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=234\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1419\r\n",
      "\t\tMap output materialized bytes=1489\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1589116928\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3626\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000114_0\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000115_0\r\n",
      "25/08/31 12:04:04 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:04 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:04 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00072-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3623\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: bufstart = 0; bufend = 1472; bufvoid = 104857600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000115_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000115_0' done.\r\n",
      "25/08/31 12:04:04 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000115_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=669487\r\n",
      "\t\tFILE: Number of bytes written=925127\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=517536\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=236\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1472\r\n",
      "\t\tMap output materialized bytes=1542\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1589116928\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3623\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000115_0\r\n",
      "25/08/31 12:04:04 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000116_0\r\n",
      "25/08/31 12:04:04 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:04 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:04 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00123-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3617\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:04 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:04 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufend = 1356; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000116_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000116_0' done.\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000116_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=674039\r\n",
      "\t\tFILE: Number of bytes written=926585\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=521153\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=238\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1356\r\n",
      "\t\tMap output materialized bytes=1426\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1589116928\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3617\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000116_0\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000117_0\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:05 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00097-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3614\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufend = 1514; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000117_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000117_0' done.\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000117_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=678591\r\n",
      "\t\tFILE: Number of bytes written=928201\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=524767\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=240\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1514\r\n",
      "\t\tMap output materialized bytes=1584\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1589116928\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3614\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000117_0\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000118_0\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:05 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00115-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3614\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufend = 1459; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000118_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000118_0' done.\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000118_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=683143\r\n",
      "\t\tFILE: Number of bytes written=929762\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=528381\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=242\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1459\r\n",
      "\t\tMap output materialized bytes=1529\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=1\r\n",
      "\t\tTotal committed heap usage (bytes)=1751646208\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3614\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000118_0\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000119_0\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:05 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00129-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3594\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufend = 1354; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000119_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000119_0' done.\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000119_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=687695\r\n",
      "\t\tFILE: Number of bytes written=931218\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=531975\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=244\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1354\r\n",
      "\t\tMap output materialized bytes=1424\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1751646208\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3594\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000119_0\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000120_0\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:05 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00130-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3593\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufend = 1414; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000120_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000120_0' done.\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000120_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=692247\r\n",
      "\t\tFILE: Number of bytes written=932734\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=535568\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=246\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1414\r\n",
      "\t\tMap output materialized bytes=1484\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1751646208\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3593\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000120_0\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000121_0\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:05 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00127-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3580\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufend = 1357; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000121_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000121_0' done.\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000121_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=696799\r\n",
      "\t\tFILE: Number of bytes written=934193\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=539148\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=248\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1357\r\n",
      "\t\tMap output materialized bytes=1427\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1751646208\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3580\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000121_0\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000122_0\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:05 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00126-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3574\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufend = 1343; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000122_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000122_0' done.\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000122_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=701351\r\n",
      "\t\tFILE: Number of bytes written=935638\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=542722\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=250\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1343\r\n",
      "\t\tMap output materialized bytes=1413\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1751646208\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3574\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000122_0\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000123_0\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:05 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00121-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3566\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufend = 1370; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000123_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000123_0' done.\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000123_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=705903\r\n",
      "\t\tFILE: Number of bytes written=937110\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=546288\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=252\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1370\r\n",
      "\t\tMap output materialized bytes=1440\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1751646208\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3566\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000123_0\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000124_0\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:05 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00113-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3563\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufend = 1398; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000124_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000124_0' done.\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000124_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=710455\r\n",
      "\t\tFILE: Number of bytes written=938610\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=549851\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=254\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1398\r\n",
      "\t\tMap output materialized bytes=1468\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1751646208\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3563\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000124_0\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000125_0\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:05 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00103-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3553\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufend = 1519; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000125_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000125_0' done.\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000125_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=715007\r\n",
      "\t\tFILE: Number of bytes written=940231\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=553404\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=256\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1519\r\n",
      "\t\tMap output materialized bytes=1589\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1751646208\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3553\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000125_0\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000126_0\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:05 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00131-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3553\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufend = 1386; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000126_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000126_0' done.\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000126_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=719559\r\n",
      "\t\tFILE: Number of bytes written=941719\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=556957\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=258\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1386\r\n",
      "\t\tMap output materialized bytes=1456\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1751646208\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3553\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000126_0\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000127_0\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:05 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00110-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3548\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufend = 1421; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000127_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000127_0' done.\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000127_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=724111\r\n",
      "\t\tFILE: Number of bytes written=943242\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=560505\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=260\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1421\r\n",
      "\t\tMap output materialized bytes=1491\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1751646208\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3548\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000127_0\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000128_0\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:05 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00147-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3541\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufend = 1361; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000128_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000128_0' done.\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000128_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=728663\r\n",
      "\t\tFILE: Number of bytes written=944705\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=564046\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=262\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1361\r\n",
      "\t\tMap output materialized bytes=1431\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=1\r\n",
      "\t\tTotal committed heap usage (bytes)=1769996288\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3541\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000128_0\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000129_0\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:05 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00137-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3540\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufend = 1435; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000129_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:05 INFO mapreduce.Job:  map 37% reduce 0%\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000129_0' done.\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000129_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=733215\r\n",
      "\t\tFILE: Number of bytes written=946242\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=567586\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=264\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1435\r\n",
      "\t\tMap output materialized bytes=1505\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1769996288\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3540\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000129_0\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000130_0\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:05 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00139-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3540\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufend = 1415; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000130_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000130_0' done.\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000130_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=737767\r\n",
      "\t\tFILE: Number of bytes written=947759\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=571126\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=266\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1415\r\n",
      "\t\tMap output materialized bytes=1485\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1769996288\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3540\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000130_0\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000131_0\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:05 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00146-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3520\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufend = 1547; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000131_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000131_0' done.\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000131_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=742319\r\n",
      "\t\tFILE: Number of bytes written=949408\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=574646\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=268\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1547\r\n",
      "\t\tMap output materialized bytes=1617\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1769996288\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3520\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000131_0\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000132_0\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:05 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00142-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3519\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufend = 1340; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000132_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000132_0' done.\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000132_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=746871\r\n",
      "\t\tFILE: Number of bytes written=950850\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=578165\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=270\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1340\r\n",
      "\t\tMap output materialized bytes=1410\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1769996288\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3519\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000132_0\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000133_0\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:05 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00133-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3513\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufend = 1213; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000133_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000133_0' done.\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000133_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=751423\r\n",
      "\t\tFILE: Number of bytes written=952165\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=581678\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=272\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1213\r\n",
      "\t\tMap output materialized bytes=1283\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1769996288\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3513\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000133_0\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000134_0\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:05 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00140-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3511\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufend = 1275; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000134_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000134_0' done.\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000134_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=755975\r\n",
      "\t\tFILE: Number of bytes written=953542\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=585189\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=274\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1275\r\n",
      "\t\tMap output materialized bytes=1345\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1769996288\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3511\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000134_0\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000135_0\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:05 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00143-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3510\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufend = 1464; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000135_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000135_0' done.\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000135_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=760527\r\n",
      "\t\tFILE: Number of bytes written=955108\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=588699\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=276\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1464\r\n",
      "\t\tMap output materialized bytes=1534\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1769996288\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3510\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000135_0\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000136_0\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:05 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00118-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3502\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufend = 1370; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000136_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000136_0' done.\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000136_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=765079\r\n",
      "\t\tFILE: Number of bytes written=956580\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=592201\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=278\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1370\r\n",
      "\t\tMap output materialized bytes=1440\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1769996288\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3502\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000136_0\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000137_0\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:05 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00122-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3500\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufend = 1349; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000137_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000137_0' done.\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000137_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=769631\r\n",
      "\t\tFILE: Number of bytes written=958031\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=595701\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=280\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1349\r\n",
      "\t\tMap output materialized bytes=1419\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1769996288\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3500\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000137_0\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000138_0\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:05 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00144-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3499\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufend = 1308; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000138_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000138_0' done.\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000138_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=774183\r\n",
      "\t\tFILE: Number of bytes written=959441\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=599200\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=282\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1308\r\n",
      "\t\tMap output materialized bytes=1378\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=1\r\n",
      "\t\tTotal committed heap usage (bytes)=1876426752\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3499\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000138_0\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000139_0\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:05 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00141-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3498\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufend = 1305; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000139_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000139_0' done.\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000139_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=778735\r\n",
      "\t\tFILE: Number of bytes written=960848\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=602698\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=284\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1305\r\n",
      "\t\tMap output materialized bytes=1375\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1876426752\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3498\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000139_0\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000140_0\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:05 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00150-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3489\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufend = 1448; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000140_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000140_0' done.\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000140_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=783287\r\n",
      "\t\tFILE: Number of bytes written=962398\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=606187\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=286\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1448\r\n",
      "\t\tMap output materialized bytes=1518\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1876426752\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3489\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000140_0\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000141_0\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:05 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00153-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3485\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufend = 1309; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000141_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000141_0' done.\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000141_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=787839\r\n",
      "\t\tFILE: Number of bytes written=963809\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=609672\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=288\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1309\r\n",
      "\t\tMap output materialized bytes=1379\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1876426752\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3485\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000141_0\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000142_0\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:05 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00145-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3484\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufend = 1477; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000142_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000142_0' done.\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000142_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=792391\r\n",
      "\t\tFILE: Number of bytes written=965388\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=613156\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=290\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1477\r\n",
      "\t\tMap output materialized bytes=1547\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1876426752\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3484\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000142_0\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000143_0\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:05 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00148-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3464\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufend = 1252; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000143_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000143_0' done.\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000143_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=796943\r\n",
      "\t\tFILE: Number of bytes written=966742\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=616620\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=292\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1252\r\n",
      "\t\tMap output materialized bytes=1322\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1876426752\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3464\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000143_0\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000144_0\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:05 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00155-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3462\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufend = 1375; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000144_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000144_0' done.\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000144_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=801495\r\n",
      "\t\tFILE: Number of bytes written=968219\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=620082\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=294\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1375\r\n",
      "\t\tMap output materialized bytes=1445\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1876426752\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3462\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000144_0\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000145_0\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:05 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00156-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3454\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufend = 1295; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000145_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000145_0' done.\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000145_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=806047\r\n",
      "\t\tFILE: Number of bytes written=969616\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=623536\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=296\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1295\r\n",
      "\t\tMap output materialized bytes=1365\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1876426752\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3454\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000145_0\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000146_0\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:05 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00152-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3450\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufend = 1235; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000146_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000146_0' done.\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000146_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=810599\r\n",
      "\t\tFILE: Number of bytes written=970953\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=626986\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=298\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1235\r\n",
      "\t\tMap output materialized bytes=1305\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1876426752\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3450\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000146_0\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000147_0\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:05 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00138-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3449\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufend = 1284; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000147_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000147_0' done.\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000147_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=815151\r\n",
      "\t\tFILE: Number of bytes written=972339\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=630435\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=300\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1284\r\n",
      "\t\tMap output materialized bytes=1354\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1876426752\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3449\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000147_0\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000148_0\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:05 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00160-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3435\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufend = 1174; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000148_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000148_0' done.\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000148_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=819703\r\n",
      "\t\tFILE: Number of bytes written=973615\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=633870\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=302\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1174\r\n",
      "\t\tMap output materialized bytes=1244\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=7\r\n",
      "\t\tTotal committed heap usage (bytes)=1889533952\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3435\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000148_0\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000149_0\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:05 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00149-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3433\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufend = 1398; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000149_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000149_0' done.\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000149_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=824255\r\n",
      "\t\tFILE: Number of bytes written=975115\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=637303\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=304\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1398\r\n",
      "\t\tMap output materialized bytes=1468\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1889533952\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3433\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000149_0\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000150_0\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:05 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00117-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3429\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufend = 1426; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000150_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000150_0' done.\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000150_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=828807\r\n",
      "\t\tFILE: Number of bytes written=976643\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=640732\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=306\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1426\r\n",
      "\t\tMap output materialized bytes=1496\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1889533952\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3429\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000150_0\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000151_0\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:05 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00125-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3427\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufend = 1248; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000151_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000151_0' done.\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000151_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=833359\r\n",
      "\t\tFILE: Number of bytes written=977993\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=644159\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=308\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1248\r\n",
      "\t\tMap output materialized bytes=1318\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1889533952\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3427\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000151_0\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000152_0\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:05 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00134-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3424\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufend = 1245; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000152_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000152_0' done.\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000152_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=837911\r\n",
      "\t\tFILE: Number of bytes written=979340\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=647583\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=310\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1245\r\n",
      "\t\tMap output materialized bytes=1315\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1889533952\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3424\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000152_0\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000153_0\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:05 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00135-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3423\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufend = 1451; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000153_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000153_0' done.\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000153_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=842463\r\n",
      "\t\tFILE: Number of bytes written=980893\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=651006\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=312\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1451\r\n",
      "\t\tMap output materialized bytes=1521\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1889533952\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3423\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000153_0\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000154_0\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:05 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00154-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3423\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufend = 1290; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000154_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000154_0' done.\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000154_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=847015\r\n",
      "\t\tFILE: Number of bytes written=982285\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=654429\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=314\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1290\r\n",
      "\t\tMap output materialized bytes=1360\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1889533952\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3423\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000154_0\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000155_0\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:05 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00132-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3412\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufend = 1441; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000155_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000155_0' done.\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000155_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=851567\r\n",
      "\t\tFILE: Number of bytes written=983828\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=657841\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=316\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1441\r\n",
      "\t\tMap output materialized bytes=1511\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1889533952\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3412\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000155_0\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000156_0\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:05 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00157-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3412\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufend = 1318; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000156_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000156_0' done.\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000156_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=856119\r\n",
      "\t\tFILE: Number of bytes written=985248\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=661253\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=318\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1318\r\n",
      "\t\tMap output materialized bytes=1388\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1889533952\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3412\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000156_0\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000157_0\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:05 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00151-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3403\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufend = 1173; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000157_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000157_0' done.\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000157_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=860671\r\n",
      "\t\tFILE: Number of bytes written=986523\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=664656\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=320\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1173\r\n",
      "\t\tMap output materialized bytes=1243\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1889533952\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3403\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000157_0\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000158_0\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:05 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00162-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3402\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufend = 1239; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000158_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000158_0' done.\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000158_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=865223\r\n",
      "\t\tFILE: Number of bytes written=987864\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=668058\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=322\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1239\r\n",
      "\t\tMap output materialized bytes=1309\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1889533952\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3402\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000158_0\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000159_0\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:05 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00163-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3401\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufend = 1245; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000159_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000159_0' done.\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000159_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=869775\r\n",
      "\t\tFILE: Number of bytes written=989211\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=671459\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=324\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1245\r\n",
      "\t\tMap output materialized bytes=1315\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1889533952\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3401\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000159_0\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000160_0\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:05 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00161-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3399\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufend = 1315; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000160_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000160_0' done.\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000160_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=874327\r\n",
      "\t\tFILE: Number of bytes written=990628\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=674858\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=326\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1315\r\n",
      "\t\tMap output materialized bytes=1385\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=1\r\n",
      "\t\tTotal committed heap usage (bytes)=2003304448\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3399\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000160_0\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000161_0\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:05 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00164-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3391\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufend = 1282; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000161_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000161_0' done.\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000161_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=878879\r\n",
      "\t\tFILE: Number of bytes written=992012\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=678249\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=328\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1282\r\n",
      "\t\tMap output materialized bytes=1352\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2003304448\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3391\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000161_0\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000162_0\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:05 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00165-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3375\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufend = 1217; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000162_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000162_0' done.\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000162_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=883431\r\n",
      "\t\tFILE: Number of bytes written=993331\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=681624\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=330\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1217\r\n",
      "\t\tMap output materialized bytes=1287\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2003304448\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3375\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000162_0\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000163_0\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:05 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00167-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3361\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufend = 1247; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000163_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000163_0' done.\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000163_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=887983\r\n",
      "\t\tFILE: Number of bytes written=994680\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=684985\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=332\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1247\r\n",
      "\t\tMap output materialized bytes=1317\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2003304448\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3361\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000163_0\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000164_0\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:05 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00168-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3361\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufend = 1296; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000164_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000164_0' done.\r\n",
      "25/08/31 12:04:05 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000164_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=892535\r\n",
      "\t\tFILE: Number of bytes written=996078\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=688346\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=334\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1296\r\n",
      "\t\tMap output materialized bytes=1366\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2003304448\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3361\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000164_0\r\n",
      "25/08/31 12:04:05 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000165_0\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:05 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:05 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00136-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3349\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:05 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:05 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufend = 1368; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000165_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000165_0' done.\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000165_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=897087\r\n",
      "\t\tFILE: Number of bytes written=997548\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=691695\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=336\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1368\r\n",
      "\t\tMap output materialized bytes=1438\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2003304448\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3349\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000165_0\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000166_0\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:06 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00159-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3341\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufend = 1307; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000166_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000166_0' done.\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000166_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=901639\r\n",
      "\t\tFILE: Number of bytes written=998957\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=695036\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=338\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1307\r\n",
      "\t\tMap output materialized bytes=1377\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2003304448\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3341\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000166_0\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000167_0\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:06 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00171-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3341\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufend = 1201; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000167_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000167_0' done.\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000167_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=906191\r\n",
      "\t\tFILE: Number of bytes written=1000260\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=698377\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=340\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1201\r\n",
      "\t\tMap output materialized bytes=1271\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2003304448\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3341\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000167_0\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000168_0\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:06 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00158-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3333\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufend = 1426; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000168_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000168_0' done.\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000168_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=910743\r\n",
      "\t\tFILE: Number of bytes written=1001788\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=701710\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=342\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1426\r\n",
      "\t\tMap output materialized bytes=1496\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2003304448\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3333\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000168_0\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000169_0\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:06 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00166-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3313\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufend = 1163; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000169_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000169_0' done.\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000169_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=915295\r\n",
      "\t\tFILE: Number of bytes written=1003053\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=705023\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=344\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1163\r\n",
      "\t\tMap output materialized bytes=1233\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2003304448\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3313\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000169_0\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000170_0\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:06 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00169-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3305\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufend = 985; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000170_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000170_0' done.\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000170_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=919847\r\n",
      "\t\tFILE: Number of bytes written=1004140\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=708328\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=346\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=985\r\n",
      "\t\tMap output materialized bytes=1055\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2003304448\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3305\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000170_0\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000171_0\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:06 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00173-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3305\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufend = 1226; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000171_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000171_0' done.\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000171_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=924399\r\n",
      "\t\tFILE: Number of bytes written=1005468\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=711633\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=348\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1226\r\n",
      "\t\tMap output materialized bytes=1296\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=50\r\n",
      "\t\tTotal committed heap usage (bytes)=2198863872\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3305\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000171_0\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000172_0\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:06 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00175-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3305\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufend = 1226; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000172_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000172_0' done.\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000172_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=928951\r\n",
      "\t\tFILE: Number of bytes written=1006796\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=714938\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=350\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1226\r\n",
      "\t\tMap output materialized bytes=1296\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2198863872\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3305\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000172_0\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000173_0\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:06 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00174-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3294\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufend = 1190; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000173_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000173_0' done.\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000173_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=933503\r\n",
      "\t\tFILE: Number of bytes written=1008088\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=718232\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=352\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1190\r\n",
      "\t\tMap output materialized bytes=1260\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2198863872\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3294\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000173_0\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000174_0\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:06 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00176-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3293\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufend = 1315; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000174_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000174_0' done.\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000174_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=938055\r\n",
      "\t\tFILE: Number of bytes written=1009505\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=721525\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=354\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1315\r\n",
      "\t\tMap output materialized bytes=1385\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2198863872\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3293\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000174_0\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000175_0\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:06 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00170-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3281\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufend = 1230; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000175_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000175_0' done.\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000175_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=942607\r\n",
      "\t\tFILE: Number of bytes written=1010837\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=724806\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=356\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1230\r\n",
      "\t\tMap output materialized bytes=1300\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2198863872\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3281\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000175_0\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000176_0\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:06 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00180-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3271\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufend = 1138; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000176_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000176_0' done.\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000176_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=947159\r\n",
      "\t\tFILE: Number of bytes written=1012077\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=728077\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=358\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1138\r\n",
      "\t\tMap output materialized bytes=1208\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2198863872\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3271\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000176_0\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000177_0\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:06 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00178-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3267\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufend = 1167; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:06 INFO mapreduce.Job:  map 51% reduce 0%\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000177_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000177_0' done.\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000177_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=951711\r\n",
      "\t\tFILE: Number of bytes written=1013346\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=731344\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=360\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1167\r\n",
      "\t\tMap output materialized bytes=1237\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2198863872\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3267\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000177_0\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000178_0\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:06 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00177-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3263\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufend = 1230; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000178_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000178_0' done.\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000178_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=956263\r\n",
      "\t\tFILE: Number of bytes written=1014678\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=734607\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=362\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1230\r\n",
      "\t\tMap output materialized bytes=1300\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2198863872\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3263\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000178_0\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000179_0\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:06 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00179-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3250\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufend = 1233; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000179_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000179_0' done.\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000179_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=960815\r\n",
      "\t\tFILE: Number of bytes written=1016013\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=737857\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=364\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1233\r\n",
      "\t\tMap output materialized bytes=1303\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2198863872\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3250\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000179_0\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000180_0\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:06 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00181-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3242\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufend = 1090; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000180_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000180_0' done.\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000180_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=965367\r\n",
      "\t\tFILE: Number of bytes written=1017205\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=741099\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=366\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1090\r\n",
      "\t\tMap output materialized bytes=1160\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2198863872\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3242\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000180_0\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000181_0\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:06 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00182-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3240\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufend = 1215; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000181_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000181_0' done.\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000181_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=969919\r\n",
      "\t\tFILE: Number of bytes written=1018522\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=744339\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=368\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1215\r\n",
      "\t\tMap output materialized bytes=1285\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2198863872\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3240\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000181_0\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000182_0\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:06 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00172-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3239\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufend = 1247; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000182_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000182_0' done.\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000182_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=974471\r\n",
      "\t\tFILE: Number of bytes written=1019871\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=747578\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=370\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1247\r\n",
      "\t\tMap output materialized bytes=1317\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2198863872\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3239\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000182_0\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000183_0\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:06 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00184-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3235\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufend = 1169; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000183_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000183_0' done.\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000183_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=979023\r\n",
      "\t\tFILE: Number of bytes written=1021142\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=750813\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=372\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1169\r\n",
      "\t\tMap output materialized bytes=1239\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=2\r\n",
      "\t\tTotal committed heap usage (bytes)=2400714752\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3235\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000183_0\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000184_0\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:06 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00183-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3225\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufend = 1200; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000184_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000184_0' done.\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000184_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=983575\r\n",
      "\t\tFILE: Number of bytes written=1022444\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=754038\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=374\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1200\r\n",
      "\t\tMap output materialized bytes=1270\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2400714752\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3225\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000184_0\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000185_0\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:06 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00185-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3224\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufend = 1151; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000185_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000185_0' done.\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000185_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=988127\r\n",
      "\t\tFILE: Number of bytes written=1023697\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=757262\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=376\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1151\r\n",
      "\t\tMap output materialized bytes=1221\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2400714752\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3224\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000185_0\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000186_0\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:06 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00188-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3212\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufend = 1071; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000186_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000186_0' done.\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000186_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=992679\r\n",
      "\t\tFILE: Number of bytes written=1024870\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=760474\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=378\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1071\r\n",
      "\t\tMap output materialized bytes=1141\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2400714752\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3212\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000186_0\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000187_0\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:06 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00186-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3208\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufend = 1259; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000187_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000187_0' done.\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000187_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=997231\r\n",
      "\t\tFILE: Number of bytes written=1026231\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=763682\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=380\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1259\r\n",
      "\t\tMap output materialized bytes=1329\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2400714752\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3208\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000187_0\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000188_0\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:06 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00187-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3205\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufend = 1269; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000188_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000188_0' done.\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000188_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1001783\r\n",
      "\t\tFILE: Number of bytes written=1027602\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=766887\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=382\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1269\r\n",
      "\t\tMap output materialized bytes=1339\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2400714752\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3205\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000188_0\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000189_0\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:06 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00189-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3200\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufend = 1120; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000189_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000189_0' done.\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000189_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1006335\r\n",
      "\t\tFILE: Number of bytes written=1028824\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=770087\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=384\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1120\r\n",
      "\t\tMap output materialized bytes=1190\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2400714752\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3200\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000189_0\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000190_0\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:06 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00191-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3182\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufend = 1178; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000190_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000190_0' done.\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000190_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1010887\r\n",
      "\t\tFILE: Number of bytes written=1030104\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=773269\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=386\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1178\r\n",
      "\t\tMap output materialized bytes=1248\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2400714752\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3182\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000190_0\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000191_0\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:06 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00192-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3182\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufend = 1142; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000191_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000191_0' done.\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000191_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1015439\r\n",
      "\t\tFILE: Number of bytes written=1031348\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=776451\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=388\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1142\r\n",
      "\t\tMap output materialized bytes=1212\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2400714752\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3182\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000191_0\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000192_0\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:06 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00190-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3176\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufend = 1167; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000192_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000192_0' done.\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000192_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1019991\r\n",
      "\t\tFILE: Number of bytes written=1032617\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=779627\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=390\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1167\r\n",
      "\t\tMap output materialized bytes=1237\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2400714752\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3176\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000192_0\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000193_0\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:06 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00193-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3175\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufend = 1221; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000193_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000193_0' done.\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000193_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1024543\r\n",
      "\t\tFILE: Number of bytes written=1033940\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=782802\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=392\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1221\r\n",
      "\t\tMap output materialized bytes=1291\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2400714752\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3175\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000193_0\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000194_0\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:06 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00194-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3157\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufend = 1092; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000194_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000194_0' done.\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000194_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1029095\r\n",
      "\t\tFILE: Number of bytes written=1035134\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=785959\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=394\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1092\r\n",
      "\t\tMap output materialized bytes=1162\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2400714752\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3157\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000194_0\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000195_0\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:06 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00196-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3147\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufend = 1170; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000195_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000195_0' done.\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000195_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1033647\r\n",
      "\t\tFILE: Number of bytes written=1036406\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=789106\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=396\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1170\r\n",
      "\t\tMap output materialized bytes=1240\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2400714752\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3147\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000195_0\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000196_0\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:06 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00198-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3143\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufend = 1115; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000196_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000196_0' done.\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000196_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1038199\r\n",
      "\t\tFILE: Number of bytes written=1037623\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=792249\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=398\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1115\r\n",
      "\t\tMap output materialized bytes=1185\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2400714752\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3143\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000196_0\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000197_0\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:06 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00195-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3142\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufend = 1219; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000197_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000197_0' done.\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000197_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1042751\r\n",
      "\t\tFILE: Number of bytes written=1038944\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=795391\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=400\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1219\r\n",
      "\t\tMap output materialized bytes=1289\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=1\r\n",
      "\t\tTotal committed heap usage (bytes)=2400190464\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3142\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000197_0\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000198_0\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:06 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00197-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3141\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufend = 1223; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000198_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000198_0' done.\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000198_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1047303\r\n",
      "\t\tFILE: Number of bytes written=1040269\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=798532\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=402\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1223\r\n",
      "\t\tMap output materialized bytes=1293\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2400190464\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3141\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000198_0\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000199_0\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:06 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00199-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3125\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufend = 946; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000199_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000199_0' done.\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000199_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1051855\r\n",
      "\t\tFILE: Number of bytes written=1041317\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=801657\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=404\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=946\r\n",
      "\t\tMap output materialized bytes=1016\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2400190464\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3125\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000199_0\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000200_0\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:06 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00203-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3115\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufend = 1229; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000200_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000200_0' done.\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000200_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1056407\r\n",
      "\t\tFILE: Number of bytes written=1042648\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=804772\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=406\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1229\r\n",
      "\t\tMap output materialized bytes=1299\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2400190464\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3115\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000200_0\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000201_0\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:06 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00204-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3111\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufend = 1027; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000201_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000201_0' done.\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000201_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1060959\r\n",
      "\t\tFILE: Number of bytes written=1043777\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=807883\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=408\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1027\r\n",
      "\t\tMap output materialized bytes=1097\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2400190464\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3111\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000201_0\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000202_0\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:06 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00200-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3108\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufend = 1098; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000202_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000202_0' done.\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000202_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1065511\r\n",
      "\t\tFILE: Number of bytes written=1044977\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=810991\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=410\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1098\r\n",
      "\t\tMap output materialized bytes=1168\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2400190464\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3108\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000202_0\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000203_0\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:06 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00202-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3106\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufend = 1138; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000203_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000203_0' done.\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000203_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1070063\r\n",
      "\t\tFILE: Number of bytes written=1046217\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=814097\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=412\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1138\r\n",
      "\t\tMap output materialized bytes=1208\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2400190464\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3106\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000203_0\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000204_0\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:06 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00201-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3102\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufend = 1066; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000204_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000204_0' done.\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000204_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1074615\r\n",
      "\t\tFILE: Number of bytes written=1047385\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=817199\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=414\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1066\r\n",
      "\t\tMap output materialized bytes=1136\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2400190464\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3102\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000204_0\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000205_0\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:06 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00209-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3084\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufend = 1139; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000205_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000205_0' done.\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000205_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1079167\r\n",
      "\t\tFILE: Number of bytes written=1048626\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=820283\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=416\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1139\r\n",
      "\t\tMap output materialized bytes=1209\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2400190464\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3084\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000205_0\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000206_0\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:06 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00205-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3080\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufend = 1067; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000206_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000206_0' done.\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000206_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1083719\r\n",
      "\t\tFILE: Number of bytes written=1049795\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=823363\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=418\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1067\r\n",
      "\t\tMap output materialized bytes=1137\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2400190464\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3080\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000206_0\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000207_0\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:06 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00207-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3080\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufend = 1104; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000207_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000207_0' done.\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000207_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1088271\r\n",
      "\t\tFILE: Number of bytes written=1051001\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=826443\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=420\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1104\r\n",
      "\t\tMap output materialized bytes=1174\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2400190464\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3080\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000207_0\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000208_0\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:06 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00208-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3074\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufend = 1169; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000208_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000208_0' done.\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000208_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1092823\r\n",
      "\t\tFILE: Number of bytes written=1052272\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=829517\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=422\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1169\r\n",
      "\t\tMap output materialized bytes=1239\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2400190464\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3074\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000208_0\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000209_0\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:06 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00206-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3065\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufend = 1170; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000209_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000209_0' done.\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000209_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1097375\r\n",
      "\t\tFILE: Number of bytes written=1053544\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=832582\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=424\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1170\r\n",
      "\t\tMap output materialized bytes=1240\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2400190464\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3065\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000209_0\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000210_0\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:06 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00210-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3059\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufend = 1155; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000210_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000210_0' done.\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000210_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1101927\r\n",
      "\t\tFILE: Number of bytes written=1054801\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=835641\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=426\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1155\r\n",
      "\t\tMap output materialized bytes=1225\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=1\r\n",
      "\t\tTotal committed heap usage (bytes)=2568486912\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3059\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000210_0\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000211_0\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:06 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00213-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3048\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufend = 1139; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000211_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000211_0' done.\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000211_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1106479\r\n",
      "\t\tFILE: Number of bytes written=1056042\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=838689\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=428\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1139\r\n",
      "\t\tMap output materialized bytes=1209\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2568486912\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3048\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000211_0\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000212_0\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:06 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00214-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3048\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufend = 1146; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000212_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000212_0' done.\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000212_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1111031\r\n",
      "\t\tFILE: Number of bytes written=1057290\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=841737\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=430\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1146\r\n",
      "\t\tMap output materialized bytes=1216\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2568486912\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3048\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000212_0\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000213_0\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:06 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00212-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3047\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufend = 1104; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000213_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000213_0' done.\r\n",
      "25/08/31 12:04:06 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000213_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1115583\r\n",
      "\t\tFILE: Number of bytes written=1058496\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=844784\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=432\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1104\r\n",
      "\t\tMap output materialized bytes=1174\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2568486912\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3047\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000213_0\r\n",
      "25/08/31 12:04:06 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000214_0\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:06 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:06 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00211-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3040\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:06 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:06 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufend = 1087; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000214_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000214_0' done.\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000214_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1120135\r\n",
      "\t\tFILE: Number of bytes written=1059685\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=847824\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=434\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1087\r\n",
      "\t\tMap output materialized bytes=1157\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2568486912\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3040\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000214_0\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000215_0\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:07 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00215-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3029\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufend = 1096; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000215_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000215_0' done.\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000215_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1124687\r\n",
      "\t\tFILE: Number of bytes written=1060883\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=850853\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=436\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1096\r\n",
      "\t\tMap output materialized bytes=1166\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2568486912\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3029\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000215_0\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000216_0\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:07 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00216-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3018\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufend = 1070; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000216_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000216_0' done.\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000216_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1129239\r\n",
      "\t\tFILE: Number of bytes written=1062055\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=853871\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=438\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1070\r\n",
      "\t\tMap output materialized bytes=1140\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2568486912\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3018\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000216_0\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000217_0\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:07 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00217-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3014\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufend = 1045; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000217_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000217_0' done.\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000217_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1133791\r\n",
      "\t\tFILE: Number of bytes written=1063202\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=856885\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=440\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1045\r\n",
      "\t\tMap output materialized bytes=1115\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2568486912\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3014\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000217_0\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000218_0\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:07 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00219-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3013\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufend = 1045; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000218_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000218_0' done.\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000218_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1138343\r\n",
      "\t\tFILE: Number of bytes written=1064349\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=859898\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=442\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1045\r\n",
      "\t\tMap output materialized bytes=1115\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2568486912\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3013\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000218_0\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000219_0\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:07 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00218-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+3012\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufend = 991; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000219_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000219_0' done.\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000219_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1142895\r\n",
      "\t\tFILE: Number of bytes written=1065442\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=862910\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=444\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=991\r\n",
      "\t\tMap output materialized bytes=1061\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2568486912\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3012\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000219_0\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000220_0\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:07 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00223-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2987\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufend = 1123; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000220_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000220_0' done.\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000220_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1147447\r\n",
      "\t\tFILE: Number of bytes written=1066667\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=865897\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=446\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1123\r\n",
      "\t\tMap output materialized bytes=1193\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2568486912\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2987\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000220_0\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000221_0\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:07 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00220-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2986\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufend = 1010; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000221_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000221_0' done.\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000221_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1151999\r\n",
      "\t\tFILE: Number of bytes written=1067779\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=868883\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=448\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1010\r\n",
      "\t\tMap output materialized bytes=1080\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2568486912\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2986\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000221_0\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000222_0\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:07 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00222-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2984\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufend = 1055; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000222_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000222_0' done.\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000222_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1156551\r\n",
      "\t\tFILE: Number of bytes written=1068936\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=871867\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=450\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1055\r\n",
      "\t\tMap output materialized bytes=1125\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2568486912\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2984\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000222_0\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000223_0\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:07 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00224-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2967\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufend = 1122; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000223_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000223_0' done.\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000223_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1161103\r\n",
      "\t\tFILE: Number of bytes written=1070160\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=874834\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=452\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1122\r\n",
      "\t\tMap output materialized bytes=1192\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2568486912\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2967\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000223_0\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000224_0\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:07 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00221-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2963\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufend = 1123; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000224_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000224_0' done.\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000224_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1165655\r\n",
      "\t\tFILE: Number of bytes written=1071385\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=877797\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=454\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1123\r\n",
      "\t\tMap output materialized bytes=1193\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=2\r\n",
      "\t\tTotal committed heap usage (bytes)=2593652736\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2963\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000224_0\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000225_0\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:07 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00227-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2957\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufend = 1097; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000225_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000225_0' done.\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000225_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1170207\r\n",
      "\t\tFILE: Number of bytes written=1072584\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=880754\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=456\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1097\r\n",
      "\t\tMap output materialized bytes=1167\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2593652736\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2957\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000225_0\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000226_0\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:07 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00228-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2953\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufend = 1126; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000226_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000226_0' done.\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000226_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1174759\r\n",
      "\t\tFILE: Number of bytes written=1073812\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=883707\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=458\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1126\r\n",
      "\t\tMap output materialized bytes=1196\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2593652736\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2953\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000226_0\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000227_0\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:07 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00225-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2946\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufend = 1026; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000227_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000227_0' done.\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000227_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1179311\r\n",
      "\t\tFILE: Number of bytes written=1074940\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=886653\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=460\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1026\r\n",
      "\t\tMap output materialized bytes=1096\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2593652736\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2946\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000227_0\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000228_0\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:07 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00226-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2934\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO mapreduce.Job:  map 100% reduce 0%\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufend = 1048; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000228_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000228_0' done.\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000228_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1183863\r\n",
      "\t\tFILE: Number of bytes written=1076090\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=889587\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=462\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1048\r\n",
      "\t\tMap output materialized bytes=1118\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2593652736\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2934\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000228_0\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000229_0\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:07 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00231-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2932\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufend = 982; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000229_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000229_0' done.\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000229_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1188415\r\n",
      "\t\tFILE: Number of bytes written=1077174\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=892519\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=464\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=982\r\n",
      "\t\tMap output materialized bytes=1052\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2593652736\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2932\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000229_0\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000230_0\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:07 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00229-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2930\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufend = 1001; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000230_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000230_0' done.\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000230_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1192967\r\n",
      "\t\tFILE: Number of bytes written=1078277\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=895449\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=466\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1001\r\n",
      "\t\tMap output materialized bytes=1071\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2593652736\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2930\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000230_0\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000231_0\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:07 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00230-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2918\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufend = 1081; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000231_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000231_0' done.\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000231_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1197519\r\n",
      "\t\tFILE: Number of bytes written=1079460\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=898367\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=468\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1081\r\n",
      "\t\tMap output materialized bytes=1151\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2593652736\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2918\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000231_0\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000232_0\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:07 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00233-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2918\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufend = 996; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000232_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000232_0' done.\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000232_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1202071\r\n",
      "\t\tFILE: Number of bytes written=1080558\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=901285\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=470\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=996\r\n",
      "\t\tMap output materialized bytes=1066\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2593652736\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2918\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000232_0\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000233_0\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:07 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00232-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2914\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufend = 1049; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000233_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000233_0' done.\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000233_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1206623\r\n",
      "\t\tFILE: Number of bytes written=1081709\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=904199\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=472\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1049\r\n",
      "\t\tMap output materialized bytes=1119\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2593652736\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2914\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000233_0\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000234_0\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:07 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00234-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2909\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufend = 1096; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000234_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000234_0' done.\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000234_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1211175\r\n",
      "\t\tFILE: Number of bytes written=1082907\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=907108\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=474\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1096\r\n",
      "\t\tMap output materialized bytes=1166\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2593652736\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2909\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000234_0\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000235_0\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:07 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00238-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2893\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufend = 978; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000235_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000235_0' done.\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000235_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1215727\r\n",
      "\t\tFILE: Number of bytes written=1083987\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=910001\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=476\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=978\r\n",
      "\t\tMap output materialized bytes=1048\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2593652736\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2893\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000235_0\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000236_0\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:07 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00237-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2889\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufend = 1053; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000236_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000236_0' done.\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000236_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1220279\r\n",
      "\t\tFILE: Number of bytes written=1085142\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=912890\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=478\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1053\r\n",
      "\t\tMap output materialized bytes=1123\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2593652736\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2889\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000236_0\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000237_0\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:07 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00235-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2883\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufend = 1052; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000237_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000237_0' done.\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000237_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1224831\r\n",
      "\t\tFILE: Number of bytes written=1086296\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=915773\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=480\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1052\r\n",
      "\t\tMap output materialized bytes=1122\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2593652736\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2883\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000237_0\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000238_0\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:07 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00236-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2879\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufend = 977; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000238_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000238_0' done.\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000238_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1229383\r\n",
      "\t\tFILE: Number of bytes written=1087375\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=918652\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=482\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=977\r\n",
      "\t\tMap output materialized bytes=1047\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=1\r\n",
      "\t\tTotal committed heap usage (bytes)=2718433280\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2879\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000238_0\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000239_0\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:07 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00239-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2867\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufend = 902; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000239_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000239_0' done.\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000239_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1233935\r\n",
      "\t\tFILE: Number of bytes written=1088379\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=921519\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=484\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=902\r\n",
      "\t\tMap output materialized bytes=972\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2718433280\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2867\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000239_0\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000240_0\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:07 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00242-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2850\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufend = 929; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000240_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000240_0' done.\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000240_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1238487\r\n",
      "\t\tFILE: Number of bytes written=1089410\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=924369\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=486\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=929\r\n",
      "\t\tMap output materialized bytes=999\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2718433280\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2850\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000240_0\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000241_0\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:07 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00240-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2849\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufend = 935; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000241_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000241_0' done.\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000241_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1243039\r\n",
      "\t\tFILE: Number of bytes written=1090447\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=927218\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=488\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=935\r\n",
      "\t\tMap output materialized bytes=1005\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2718433280\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2849\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000241_0\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000242_0\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:07 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00241-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2849\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufend = 908; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000242_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000242_0' done.\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000242_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1247591\r\n",
      "\t\tFILE: Number of bytes written=1091457\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=930067\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=490\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=908\r\n",
      "\t\tMap output materialized bytes=978\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2718433280\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2849\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000242_0\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000243_0\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:07 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00243-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2847\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufend = 1092; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000243_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000243_0' done.\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000243_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1252143\r\n",
      "\t\tFILE: Number of bytes written=1092651\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=932914\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=492\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1092\r\n",
      "\t\tMap output materialized bytes=1162\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2718433280\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2847\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000243_0\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000244_0\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:07 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00247-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2827\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufend = 1025; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000244_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000244_0' done.\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000244_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1256695\r\n",
      "\t\tFILE: Number of bytes written=1093778\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=935741\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=494\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1025\r\n",
      "\t\tMap output materialized bytes=1095\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2718433280\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2827\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000244_0\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000245_0\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:07 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00246-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2823\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufend = 939; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000245_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000245_0' done.\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000245_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1261247\r\n",
      "\t\tFILE: Number of bytes written=1094819\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=938564\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=496\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=939\r\n",
      "\t\tMap output materialized bytes=1009\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2718433280\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2823\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000245_0\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000246_0\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:07 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00244-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2821\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufend = 911; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000246_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000246_0' done.\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000246_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1265799\r\n",
      "\t\tFILE: Number of bytes written=1095832\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=941385\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=498\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=911\r\n",
      "\t\tMap output materialized bytes=981\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2718433280\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2821\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000246_0\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000247_0\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:07 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00245-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2811\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufend = 883; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000247_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000247_0' done.\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000247_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1270351\r\n",
      "\t\tFILE: Number of bytes written=1096817\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=944196\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=500\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=883\r\n",
      "\t\tMap output materialized bytes=953\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2718433280\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2811\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000247_0\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000248_0\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:07 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00248-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2808\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufend = 935; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000248_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000248_0' done.\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000248_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1274903\r\n",
      "\t\tFILE: Number of bytes written=1097854\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=947004\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=502\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=935\r\n",
      "\t\tMap output materialized bytes=1005\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2718433280\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2808\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000248_0\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000249_0\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:07 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00250-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2800\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufend = 1002; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000249_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000249_0' done.\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000249_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1279455\r\n",
      "\t\tFILE: Number of bytes written=1098958\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=949804\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=504\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1002\r\n",
      "\t\tMap output materialized bytes=1072\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2718433280\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2800\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000249_0\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000250_0\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:07 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00249-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2797\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufend = 914; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000250_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000250_0' done.\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000250_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1284007\r\n",
      "\t\tFILE: Number of bytes written=1099974\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=952601\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=506\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=914\r\n",
      "\t\tMap output materialized bytes=984\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2718433280\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2797\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000250_0\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000251_0\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:07 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00252-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2791\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufend = 1025; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000251_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000251_0' done.\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000251_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1288559\r\n",
      "\t\tFILE: Number of bytes written=1101101\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=955392\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=508\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=1025\r\n",
      "\t\tMap output materialized bytes=1095\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2718433280\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2791\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000251_0\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000252_0\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:07 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00251-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2783\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufend = 863; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000252_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000252_0' done.\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000252_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1293111\r\n",
      "\t\tFILE: Number of bytes written=1102066\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=958175\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=510\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=863\r\n",
      "\t\tMap output materialized bytes=933\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2718433280\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2783\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000252_0\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000253_0\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:07 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00254-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2760\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufend = 897; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000253_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000253_0' done.\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000253_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1297663\r\n",
      "\t\tFILE: Number of bytes written=1103065\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=960935\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=512\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=897\r\n",
      "\t\tMap output materialized bytes=967\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=2\r\n",
      "\t\tTotal committed heap usage (bytes)=2717908992\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2760\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000253_0\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000254_0\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:07 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00253-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2758\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufend = 857; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000254_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000254_0' done.\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000254_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1302215\r\n",
      "\t\tFILE: Number of bytes written=1104024\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=963693\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=514\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=857\r\n",
      "\t\tMap output materialized bytes=927\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2717908992\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2758\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000254_0\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000255_0\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:07 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00255-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2758\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufend = 889; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000255_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000255_0' done.\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000255_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1306767\r\n",
      "\t\tFILE: Number of bytes written=1105015\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=966451\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=516\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=889\r\n",
      "\t\tMap output materialized bytes=959\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2717908992\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2758\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000255_0\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000256_0\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:07 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00256-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2756\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufend = 847; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000256_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000256_0' done.\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000256_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1311319\r\n",
      "\t\tFILE: Number of bytes written=1105964\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=969207\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=518\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=847\r\n",
      "\t\tMap output materialized bytes=917\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2717908992\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2756\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000256_0\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000257_0\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:07 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00259-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2731\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufend = 945; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000257_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000257_0' done.\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000257_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1315871\r\n",
      "\t\tFILE: Number of bytes written=1107011\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=971938\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=520\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=945\r\n",
      "\t\tMap output materialized bytes=1015\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2717908992\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2731\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000257_0\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000258_0\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:07 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00258-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2729\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufend = 903; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000258_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000258_0' done.\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000258_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1320423\r\n",
      "\t\tFILE: Number of bytes written=1108016\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=974667\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=522\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=903\r\n",
      "\t\tMap output materialized bytes=973\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2717908992\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2729\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000258_0\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000259_0\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:07 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00257-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2727\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufend = 921; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000259_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000259_0' done.\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000259_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1324975\r\n",
      "\t\tFILE: Number of bytes written=1109039\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=977394\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=524\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=921\r\n",
      "\t\tMap output materialized bytes=991\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2717908992\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2727\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000259_0\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000260_0\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:07 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00260-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2722\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufend = 944; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000260_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000260_0' done.\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000260_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1329527\r\n",
      "\t\tFILE: Number of bytes written=1110085\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=980116\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=526\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=944\r\n",
      "\t\tMap output materialized bytes=1014\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2717908992\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2722\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000260_0\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000261_0\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:07 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00261-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2704\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufend = 914; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000261_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000261_0' done.\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000261_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1334079\r\n",
      "\t\tFILE: Number of bytes written=1111101\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=982820\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=528\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=914\r\n",
      "\t\tMap output materialized bytes=984\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2717908992\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2704\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000261_0\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000262_0\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:07 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00262-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2698\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufend = 963; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000262_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000262_0' done.\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000262_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1338631\r\n",
      "\t\tFILE: Number of bytes written=1112166\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=985518\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=530\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=963\r\n",
      "\t\tMap output materialized bytes=1033\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2717908992\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2698\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000262_0\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000263_0\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:07 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00263-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2695\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufend = 819; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000263_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000263_0' done.\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000263_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1343183\r\n",
      "\t\tFILE: Number of bytes written=1113087\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=988213\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=532\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=819\r\n",
      "\t\tMap output materialized bytes=889\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2717908992\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2695\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000263_0\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000264_0\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:07 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00264-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2694\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufend = 840; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000264_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000264_0' done.\r\n",
      "25/08/31 12:04:07 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000264_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1347735\r\n",
      "\t\tFILE: Number of bytes written=1114029\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=990907\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=534\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=840\r\n",
      "\t\tMap output materialized bytes=910\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2717908992\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2694\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000264_0\r\n",
      "25/08/31 12:04:07 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000265_0\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:07 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:07 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00265-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2684\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:07 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:07 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufend = 848; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000265_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000265_0' done.\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000265_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1352287\r\n",
      "\t\tFILE: Number of bytes written=1114979\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=993591\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=536\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=848\r\n",
      "\t\tMap output materialized bytes=918\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2717908992\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2684\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000265_0\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000266_0\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:08 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00267-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2668\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufend = 797; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000266_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000266_0' done.\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000266_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1356839\r\n",
      "\t\tFILE: Number of bytes written=1115878\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=996259\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=538\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=797\r\n",
      "\t\tMap output materialized bytes=867\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2717908992\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2668\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000266_0\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000267_0\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:08 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00266-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2666\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufend = 894; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000267_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000267_0' done.\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000267_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1361391\r\n",
      "\t\tFILE: Number of bytes written=1116874\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=998925\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=540\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=894\r\n",
      "\t\tMap output materialized bytes=964\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2717908992\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2666\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000267_0\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000268_0\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:08 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00269-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2665\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufend = 842; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000268_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000268_0' done.\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000268_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1365943\r\n",
      "\t\tFILE: Number of bytes written=1117818\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1001590\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=542\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=842\r\n",
      "\t\tMap output materialized bytes=912\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=1\r\n",
      "\t\tTotal committed heap usage (bytes)=2818572288\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2665\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000268_0\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000269_0\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:08 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00268-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2651\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufend = 811; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000269_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000269_0' done.\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000269_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1370495\r\n",
      "\t\tFILE: Number of bytes written=1118731\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1004241\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=544\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=811\r\n",
      "\t\tMap output materialized bytes=881\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2818572288\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2651\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000269_0\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000270_0\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:08 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00270-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2647\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufend = 866; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000270_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000270_0' done.\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000270_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1375047\r\n",
      "\t\tFILE: Number of bytes written=1119699\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1006888\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=546\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=866\r\n",
      "\t\tMap output materialized bytes=936\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2818572288\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2647\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000270_0\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000271_0\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:08 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00271-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2638\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufend = 875; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000271_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000271_0' done.\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000271_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1379599\r\n",
      "\t\tFILE: Number of bytes written=1120676\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1009526\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=548\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=875\r\n",
      "\t\tMap output materialized bytes=945\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2818572288\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2638\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000271_0\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000272_0\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:08 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00272-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2635\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufend = 761; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000272_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000272_0' done.\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000272_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1384151\r\n",
      "\t\tFILE: Number of bytes written=1121539\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1012161\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=550\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=761\r\n",
      "\t\tMap output materialized bytes=831\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2818572288\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2635\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000272_0\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000273_0\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:08 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00273-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2629\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufend = 801; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000273_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000273_0' done.\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000273_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1388703\r\n",
      "\t\tFILE: Number of bytes written=1122442\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1014790\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=552\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=801\r\n",
      "\t\tMap output materialized bytes=871\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2818572288\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2629\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000273_0\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000274_0\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:08 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00274-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2612\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufend = 794; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000274_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000274_0' done.\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000274_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1393255\r\n",
      "\t\tFILE: Number of bytes written=1123338\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1017402\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=554\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=794\r\n",
      "\t\tMap output materialized bytes=864\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2818572288\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2612\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000274_0\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000275_0\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:08 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00278-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2606\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufend = 856; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000275_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000275_0' done.\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000275_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1397807\r\n",
      "\t\tFILE: Number of bytes written=1124296\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1020008\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=556\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=856\r\n",
      "\t\tMap output materialized bytes=926\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2818572288\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2606\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000275_0\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000276_0\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:08 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00275-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2599\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufend = 804; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000276_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000276_0' done.\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000276_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1402359\r\n",
      "\t\tFILE: Number of bytes written=1125202\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1022607\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=558\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=804\r\n",
      "\t\tMap output materialized bytes=874\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2818572288\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2599\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000276_0\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000277_0\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:08 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00276-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2598\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufend = 832; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000277_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000277_0' done.\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000277_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1406911\r\n",
      "\t\tFILE: Number of bytes written=1126136\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1025205\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=560\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=832\r\n",
      "\t\tMap output materialized bytes=902\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2818572288\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2598\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000277_0\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000278_0\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:08 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00277-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2597\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufend = 926; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000278_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000278_0' done.\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000278_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1411463\r\n",
      "\t\tFILE: Number of bytes written=1127164\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1027802\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=562\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=926\r\n",
      "\t\tMap output materialized bytes=996\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2818572288\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2597\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000278_0\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000279_0\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:08 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00279-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2574\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufend = 853; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000279_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000279_0' done.\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000279_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1416015\r\n",
      "\t\tFILE: Number of bytes written=1128119\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1030376\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=564\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=853\r\n",
      "\t\tMap output materialized bytes=923\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2818572288\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2574\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000279_0\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000280_0\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:08 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00281-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2572\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufend = 793; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000280_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000280_0' done.\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000280_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1420567\r\n",
      "\t\tFILE: Number of bytes written=1129014\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1032948\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=566\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=793\r\n",
      "\t\tMap output materialized bytes=863\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2818572288\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2572\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000280_0\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000281_0\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:08 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00282-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2571\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufend = 809; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000281_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000281_0' done.\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000281_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1425119\r\n",
      "\t\tFILE: Number of bytes written=1129925\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1035519\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=568\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=809\r\n",
      "\t\tMap output materialized bytes=879\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2818572288\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2571\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000281_0\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000282_0\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:08 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00280-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2565\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufend = 782; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000282_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000282_0' done.\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000282_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1429671\r\n",
      "\t\tFILE: Number of bytes written=1130809\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1038084\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=570\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=782\r\n",
      "\t\tMap output materialized bytes=852\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2818572288\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2565\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000282_0\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000283_0\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:08 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00283-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2555\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufend = 753; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000283_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000283_0' done.\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000283_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1434223\r\n",
      "\t\tFILE: Number of bytes written=1131664\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1040639\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=572\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=753\r\n",
      "\t\tMap output materialized bytes=823\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=2\r\n",
      "\t\tTotal committed heap usage (bytes)=2832203776\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2555\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000283_0\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000284_0\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:08 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00285-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2537\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufend = 792; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000284_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000284_0' done.\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000284_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1438775\r\n",
      "\t\tFILE: Number of bytes written=1132558\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1043176\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=574\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=792\r\n",
      "\t\tMap output materialized bytes=862\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2832203776\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2537\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000284_0\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000285_0\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:08 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00286-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2537\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufend = 782; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000285_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000285_0' done.\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000285_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1443327\r\n",
      "\t\tFILE: Number of bytes written=1133442\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1045713\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=576\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=782\r\n",
      "\t\tMap output materialized bytes=852\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2832203776\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2537\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000285_0\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000286_0\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:08 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00284-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2532\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufend = 797; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000286_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000286_0' done.\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000286_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1447879\r\n",
      "\t\tFILE: Number of bytes written=1134341\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1048245\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=578\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=797\r\n",
      "\t\tMap output materialized bytes=867\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2832203776\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2532\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000286_0\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000287_0\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:08 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00287-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2526\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufend = 718; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000287_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000287_0' done.\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000287_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1452431\r\n",
      "\t\tFILE: Number of bytes written=1135161\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1050771\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=580\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=718\r\n",
      "\t\tMap output materialized bytes=788\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2832203776\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2526\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000287_0\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000288_0\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:08 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00290-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2497\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufend = 776; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000288_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000288_0' done.\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000288_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1456983\r\n",
      "\t\tFILE: Number of bytes written=1136039\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1053268\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=582\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=776\r\n",
      "\t\tMap output materialized bytes=846\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2832203776\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2497\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000288_0\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000289_0\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:08 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00288-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2494\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufend = 738; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000289_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000289_0' done.\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000289_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1461535\r\n",
      "\t\tFILE: Number of bytes written=1136879\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1055762\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=584\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=738\r\n",
      "\t\tMap output materialized bytes=808\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2832203776\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2494\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000289_0\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000290_0\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:08 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00289-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2490\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufend = 809; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000290_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000290_0' done.\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000290_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1466087\r\n",
      "\t\tFILE: Number of bytes written=1137790\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1058252\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=586\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=809\r\n",
      "\t\tMap output materialized bytes=879\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2832203776\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2490\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000290_0\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000291_0\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:08 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00291-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2486\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufend = 767; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000291_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000291_0' done.\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000291_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1470639\r\n",
      "\t\tFILE: Number of bytes written=1138659\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1060738\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=588\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=767\r\n",
      "\t\tMap output materialized bytes=837\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2832203776\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2486\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000291_0\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000292_0\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:08 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00293-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2476\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufend = 691; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000292_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000292_0' done.\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000292_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1475191\r\n",
      "\t\tFILE: Number of bytes written=1139452\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1063214\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=590\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=691\r\n",
      "\t\tMap output materialized bytes=761\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2832203776\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2476\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000292_0\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000293_0\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:08 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00292-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2475\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufend = 749; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000293_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000293_0' done.\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000293_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1479743\r\n",
      "\t\tFILE: Number of bytes written=1140303\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1065689\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=592\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=749\r\n",
      "\t\tMap output materialized bytes=819\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2832203776\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2475\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000293_0\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000294_0\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:08 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00294-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2462\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufend = 752; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000294_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000294_0' done.\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000294_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1484295\r\n",
      "\t\tFILE: Number of bytes written=1141157\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1068151\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=594\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=752\r\n",
      "\t\tMap output materialized bytes=822\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2832203776\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2462\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000294_0\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000295_0\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:08 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00298-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2450\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufend = 658; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000295_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000295_0' done.\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000295_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1488847\r\n",
      "\t\tFILE: Number of bytes written=1141917\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1070601\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=596\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=658\r\n",
      "\t\tMap output materialized bytes=728\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2832203776\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2450\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000295_0\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000296_0\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:08 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00297-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2442\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufend = 713; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000296_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000296_0' done.\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000296_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1493399\r\n",
      "\t\tFILE: Number of bytes written=1142732\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1073043\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=598\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=713\r\n",
      "\t\tMap output materialized bytes=783\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2832203776\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2442\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000296_0\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000297_0\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:08 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00296-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2435\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufend = 771; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000297_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000297_0' done.\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000297_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1497951\r\n",
      "\t\tFILE: Number of bytes written=1143605\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1075478\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=600\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=771\r\n",
      "\t\tMap output materialized bytes=841\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2832203776\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2435\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000297_0\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000298_0\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:08 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00295-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2429\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufend = 771; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000298_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000298_0' done.\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000298_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1502503\r\n",
      "\t\tFILE: Number of bytes written=1144478\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1077907\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=602\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=771\r\n",
      "\t\tMap output materialized bytes=841\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=1\r\n",
      "\t\tTotal committed heap usage (bytes)=2927624192\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2429\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000298_0\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000299_0\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:08 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00302-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2413\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufend = 748; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000299_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000299_0' done.\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000299_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1507055\r\n",
      "\t\tFILE: Number of bytes written=1145328\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1080320\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=604\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=748\r\n",
      "\t\tMap output materialized bytes=818\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2927624192\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2413\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000299_0\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000300_0\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:08 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00299-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2409\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufend = 753; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000300_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000300_0' done.\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000300_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1511607\r\n",
      "\t\tFILE: Number of bytes written=1146183\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1082729\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=606\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=753\r\n",
      "\t\tMap output materialized bytes=823\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2927624192\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2409\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000300_0\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000301_0\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:08 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00301-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2407\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufend = 736; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000301_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000301_0' done.\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000301_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1516159\r\n",
      "\t\tFILE: Number of bytes written=1147021\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1085136\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=608\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=736\r\n",
      "\t\tMap output materialized bytes=806\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2927624192\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2407\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000301_0\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000302_0\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:08 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00300-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2402\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufend = 720; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000302_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000302_0' done.\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000302_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1520711\r\n",
      "\t\tFILE: Number of bytes written=1147843\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1087538\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=610\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=720\r\n",
      "\t\tMap output materialized bytes=790\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2927624192\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2402\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000302_0\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000303_0\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:08 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00303-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2389\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufend = 690; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000303_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000303_0' done.\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000303_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1525263\r\n",
      "\t\tFILE: Number of bytes written=1148635\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1089927\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=612\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=690\r\n",
      "\t\tMap output materialized bytes=760\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2927624192\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2389\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000303_0\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000304_0\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:08 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00306-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2375\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufend = 741; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000304_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000304_0' done.\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000304_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1529815\r\n",
      "\t\tFILE: Number of bytes written=1149478\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1092302\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=614\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=741\r\n",
      "\t\tMap output materialized bytes=811\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2927624192\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2375\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000304_0\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000305_0\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:08 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00305-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2372\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufend = 755; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000305_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000305_0' done.\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000305_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1534367\r\n",
      "\t\tFILE: Number of bytes written=1150335\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1094674\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=616\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=755\r\n",
      "\t\tMap output materialized bytes=825\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2927624192\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2372\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000305_0\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000306_0\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:08 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00304-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2370\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufend = 717; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000306_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000306_0' done.\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000306_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1538919\r\n",
      "\t\tFILE: Number of bytes written=1151154\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1097044\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=618\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=717\r\n",
      "\t\tMap output materialized bytes=787\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2927624192\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2370\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000306_0\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000307_0\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:08 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00308-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2349\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufend = 637; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000307_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000307_0' done.\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000307_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1543471\r\n",
      "\t\tFILE: Number of bytes written=1151893\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1099393\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=620\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=637\r\n",
      "\t\tMap output materialized bytes=707\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2927624192\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2349\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000307_0\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000308_0\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:08 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00309-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2348\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufend = 745; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000308_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000308_0' done.\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000308_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1548023\r\n",
      "\t\tFILE: Number of bytes written=1152740\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1101741\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=622\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=745\r\n",
      "\t\tMap output materialized bytes=815\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2927624192\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2348\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000308_0\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000309_0\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:08 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00307-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2345\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufend = 676; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000309_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000309_0' done.\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000309_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1552575\r\n",
      "\t\tFILE: Number of bytes written=1153518\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1104086\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=624\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=676\r\n",
      "\t\tMap output materialized bytes=746\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2927624192\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2345\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000309_0\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000310_0\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:08 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00310-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2335\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufend = 686; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000310_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000310_0' done.\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000310_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1557127\r\n",
      "\t\tFILE: Number of bytes written=1154306\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1106421\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=626\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=686\r\n",
      "\t\tMap output materialized bytes=756\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2927624192\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2335\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000310_0\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000311_0\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:08 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00312-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2318\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufend = 649; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000311_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000311_0' done.\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000311_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1561679\r\n",
      "\t\tFILE: Number of bytes written=1155057\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1108739\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=628\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=649\r\n",
      "\t\tMap output materialized bytes=719\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2927624192\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2318\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000311_0\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000312_0\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:08 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00311-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2312\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufend = 697; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000312_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000312_0' done.\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000312_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1566231\r\n",
      "\t\tFILE: Number of bytes written=1155856\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1111051\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=630\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=697\r\n",
      "\t\tMap output materialized bytes=767\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2927624192\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2312\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000312_0\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000313_0\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:08 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00313-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2301\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufend = 669; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000313_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000313_0' done.\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000313_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1570783\r\n",
      "\t\tFILE: Number of bytes written=1156627\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1113352\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=632\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=669\r\n",
      "\t\tMap output materialized bytes=739\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2927624192\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2301\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000313_0\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000314_0\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:08 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00314-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2293\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufend = 623; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000314_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000314_0' done.\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000314_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1575335\r\n",
      "\t\tFILE: Number of bytes written=1157352\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1115645\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=634\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=623\r\n",
      "\t\tMap output materialized bytes=693\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=2\r\n",
      "\t\tTotal committed heap usage (bytes)=2927099904\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2293\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000314_0\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000315_0\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:08 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00315-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2279\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufend = 618; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000315_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000315_0' done.\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000315_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1579887\r\n",
      "\t\tFILE: Number of bytes written=1158072\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1117924\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=636\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=618\r\n",
      "\t\tMap output materialized bytes=688\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2927099904\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2279\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000315_0\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000316_0\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:08 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00317-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2275\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufend = 603; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000316_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000316_0' done.\r\n",
      "25/08/31 12:04:08 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000316_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1584439\r\n",
      "\t\tFILE: Number of bytes written=1158777\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1120199\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=638\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=603\r\n",
      "\t\tMap output materialized bytes=673\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2927099904\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2275\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000316_0\r\n",
      "25/08/31 12:04:08 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000317_0\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:08 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:08 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00316-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2273\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:08 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:08 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: bufstart = 0; bufend = 682; bufvoid = 104857600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000317_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000317_0' done.\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000317_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1588991\r\n",
      "\t\tFILE: Number of bytes written=1159561\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1122472\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=640\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=682\r\n",
      "\t\tMap output materialized bytes=752\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2927099904\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2273\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000317_0\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000318_0\r\n",
      "25/08/31 12:04:09 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:09 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:09 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00318-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2249\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: bufstart = 0; bufend = 590; bufvoid = 104857600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000318_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000318_0' done.\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000318_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1593543\r\n",
      "\t\tFILE: Number of bytes written=1160253\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1124721\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=642\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=590\r\n",
      "\t\tMap output materialized bytes=660\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2927099904\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2249\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000318_0\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000319_0\r\n",
      "25/08/31 12:04:09 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:09 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:09 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00319-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2249\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: bufstart = 0; bufend = 658; bufvoid = 104857600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000319_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000319_0' done.\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000319_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1598095\r\n",
      "\t\tFILE: Number of bytes written=1161013\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1126970\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=644\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=658\r\n",
      "\t\tMap output materialized bytes=728\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2927099904\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2249\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000319_0\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000320_0\r\n",
      "25/08/31 12:04:09 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:09 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:09 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00320-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2239\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: bufstart = 0; bufend = 648; bufvoid = 104857600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000320_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000320_0' done.\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000320_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1602647\r\n",
      "\t\tFILE: Number of bytes written=1161763\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1129209\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=646\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=648\r\n",
      "\t\tMap output materialized bytes=718\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2927099904\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2239\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000320_0\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000321_0\r\n",
      "25/08/31 12:04:09 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:09 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:09 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00322-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2221\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: bufstart = 0; bufend = 593; bufvoid = 104857600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000321_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000321_0' done.\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000321_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1607199\r\n",
      "\t\tFILE: Number of bytes written=1162458\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1131430\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=648\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=593\r\n",
      "\t\tMap output materialized bytes=663\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2927099904\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2221\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000321_0\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000322_0\r\n",
      "25/08/31 12:04:09 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:09 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:09 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00321-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2218\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: bufstart = 0; bufend = 619; bufvoid = 104857600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000322_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000322_0' done.\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000322_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1611751\r\n",
      "\t\tFILE: Number of bytes written=1163179\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1133648\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=650\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=619\r\n",
      "\t\tMap output materialized bytes=689\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2927099904\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2218\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000322_0\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000323_0\r\n",
      "25/08/31 12:04:09 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:09 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:09 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00323-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2204\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: bufstart = 0; bufend = 596; bufvoid = 104857600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000323_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000323_0' done.\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000323_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1616303\r\n",
      "\t\tFILE: Number of bytes written=1163877\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1135852\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=652\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=596\r\n",
      "\t\tMap output materialized bytes=666\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2927099904\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2204\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000323_0\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000324_0\r\n",
      "25/08/31 12:04:09 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:09 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:09 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00324-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2191\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: bufstart = 0; bufend = 594; bufvoid = 104857600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000324_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000324_0' done.\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000324_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1620855\r\n",
      "\t\tFILE: Number of bytes written=1164573\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1138043\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=654\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=594\r\n",
      "\t\tMap output materialized bytes=664\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2927099904\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2191\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000324_0\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000325_0\r\n",
      "25/08/31 12:04:09 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:09 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:09 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00325-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2183\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: bufstart = 0; bufend = 631; bufvoid = 104857600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000325_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000325_0' done.\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000325_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1625142\r\n",
      "\t\tFILE: Number of bytes written=1165306\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1140226\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=656\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=631\r\n",
      "\t\tMap output materialized bytes=701\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2927099904\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2183\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000325_0\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000326_0\r\n",
      "25/08/31 12:04:09 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:09 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:09 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00326-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2165\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: bufstart = 0; bufend = 589; bufvoid = 104857600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000326_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000326_0' done.\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000326_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1629429\r\n",
      "\t\tFILE: Number of bytes written=1165997\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1142391\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=658\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=589\r\n",
      "\t\tMap output materialized bytes=659\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2927099904\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2165\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000326_0\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000327_0\r\n",
      "25/08/31 12:04:09 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:09 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:09 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00327-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2148\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: bufstart = 0; bufend = 612; bufvoid = 104857600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000327_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000327_0' done.\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000327_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1633716\r\n",
      "\t\tFILE: Number of bytes written=1166711\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1144539\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=660\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=612\r\n",
      "\t\tMap output materialized bytes=682\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2927099904\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2148\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000327_0\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000328_0\r\n",
      "25/08/31 12:04:09 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:09 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:09 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00328-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2132\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: bufstart = 0; bufend = 593; bufvoid = 104857600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000328_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000328_0' done.\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000328_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1637491\r\n",
      "\t\tFILE: Number of bytes written=1167406\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1146671\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=662\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=593\r\n",
      "\t\tMap output materialized bytes=663\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2927099904\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2132\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000328_0\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000329_0\r\n",
      "25/08/31 12:04:09 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:09 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:09 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00329-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2123\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: bufstart = 0; bufend = 570; bufvoid = 104857600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000329_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000329_0' done.\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000329_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1641266\r\n",
      "\t\tFILE: Number of bytes written=1168078\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1148794\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=664\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=570\r\n",
      "\t\tMap output materialized bytes=640\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2927099904\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2123\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000329_0\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000330_0\r\n",
      "25/08/31 12:04:09 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:09 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:09 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00330-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2120\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: bufstart = 0; bufend = 542; bufvoid = 104857600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000330_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000330_0' done.\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000330_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1645041\r\n",
      "\t\tFILE: Number of bytes written=1168722\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1150914\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=666\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=542\r\n",
      "\t\tMap output materialized bytes=612\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=1\r\n",
      "\t\tTotal committed heap usage (bytes)=3012034560\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2120\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000330_0\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000331_0\r\n",
      "25/08/31 12:04:09 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:09 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:09 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00331-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2118\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: bufstart = 0; bufend = 587; bufvoid = 104857600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000331_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000331_0' done.\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000331_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1648304\r\n",
      "\t\tFILE: Number of bytes written=1169411\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1153032\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=668\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=587\r\n",
      "\t\tMap output materialized bytes=657\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=3012034560\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2118\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000331_0\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000332_0\r\n",
      "25/08/31 12:04:09 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:09 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:09 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00333-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2090\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: bufstart = 0; bufend = 552; bufvoid = 104857600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000332_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000332_0' done.\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000332_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1651567\r\n",
      "\t\tFILE: Number of bytes written=1170065\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1155122\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=670\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=552\r\n",
      "\t\tMap output materialized bytes=622\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=3012034560\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2090\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000332_0\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000333_0\r\n",
      "25/08/31 12:04:09 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:09 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:09 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00332-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2083\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: bufstart = 0; bufend = 581; bufvoid = 104857600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000333_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000333_0' done.\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000333_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1654830\r\n",
      "\t\tFILE: Number of bytes written=1170748\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1157205\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=672\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=581\r\n",
      "\t\tMap output materialized bytes=651\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=3012034560\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2083\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000333_0\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000334_0\r\n",
      "25/08/31 12:04:09 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:09 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:09 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00334-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2083\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: bufstart = 0; bufend = 531; bufvoid = 104857600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000334_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000334_0' done.\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000334_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1658093\r\n",
      "\t\tFILE: Number of bytes written=1171381\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1159288\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=674\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=531\r\n",
      "\t\tMap output materialized bytes=601\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=3012034560\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2083\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000334_0\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000335_0\r\n",
      "25/08/31 12:04:09 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:09 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:09 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00335-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2069\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: bufstart = 0; bufend = 536; bufvoid = 104857600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000335_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000335_0' done.\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000335_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1660844\r\n",
      "\t\tFILE: Number of bytes written=1172019\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1161357\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=676\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=536\r\n",
      "\t\tMap output materialized bytes=606\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=3012034560\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2069\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000335_0\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000336_0\r\n",
      "25/08/31 12:04:09 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:09 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:09 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00336-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2048\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: bufstart = 0; bufend = 508; bufvoid = 104857600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000336_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000336_0' done.\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000336_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1663595\r\n",
      "\t\tFILE: Number of bytes written=1172629\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1163405\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=678\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=508\r\n",
      "\t\tMap output materialized bytes=578\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=3012034560\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2048\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000336_0\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000337_0\r\n",
      "25/08/31 12:04:09 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:09 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:09 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00337-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2031\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: bufstart = 0; bufend = 543; bufvoid = 104857600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000337_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000337_0' done.\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000337_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1666346\r\n",
      "\t\tFILE: Number of bytes written=1173274\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1165436\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=680\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=543\r\n",
      "\t\tMap output materialized bytes=613\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=3012034560\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2031\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000337_0\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000338_0\r\n",
      "25/08/31 12:04:09 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:09 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:09 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00338-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+2009\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: bufstart = 0; bufend = 532; bufvoid = 104857600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000338_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000338_0' done.\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000338_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1668585\r\n",
      "\t\tFILE: Number of bytes written=1173908\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1167445\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=682\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=532\r\n",
      "\t\tMap output materialized bytes=602\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=3012034560\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2009\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000338_0\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000339_0\r\n",
      "25/08/31 12:04:09 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:09 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:09 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00339-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+1981\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: bufstart = 0; bufend = 495; bufvoid = 104857600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000339_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000339_0' done.\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000339_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1670824\r\n",
      "\t\tFILE: Number of bytes written=1174505\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1169426\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=684\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=495\r\n",
      "\t\tMap output materialized bytes=565\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=3012034560\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=1981\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000339_0\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000340_0\r\n",
      "25/08/31 12:04:09 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:09 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:09 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00340-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+1972\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: bufstart = 0; bufend = 507; bufvoid = 104857600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000340_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000340_0' done.\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000340_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1673063\r\n",
      "\t\tFILE: Number of bytes written=1175114\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1171398\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=686\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=507\r\n",
      "\t\tMap output materialized bytes=577\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=3012034560\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=1972\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000340_0\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000341_0\r\n",
      "25/08/31 12:04:09 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:09 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:09 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00341-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+1948\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: bufstart = 0; bufend = 468; bufvoid = 104857600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000341_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000341_0' done.\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000341_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1674790\r\n",
      "\t\tFILE: Number of bytes written=1175684\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1173346\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=688\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=468\r\n",
      "\t\tMap output materialized bytes=538\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=3012034560\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=1948\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000341_0\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000342_0\r\n",
      "25/08/31 12:04:09 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:09 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:09 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00342-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+1938\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: bufstart = 0; bufend = 454; bufvoid = 104857600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000342_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000342_0' done.\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000342_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1676517\r\n",
      "\t\tFILE: Number of bytes written=1176240\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1175284\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=690\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=454\r\n",
      "\t\tMap output materialized bytes=524\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=3012034560\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=1938\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000342_0\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000343_0\r\n",
      "25/08/31 12:04:09 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:09 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:09 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00343-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+1895\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: bufstart = 0; bufend = 478; bufvoid = 104857600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000343_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000343_0' done.\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000343_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1678244\r\n",
      "\t\tFILE: Number of bytes written=1176820\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1177179\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=692\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=478\r\n",
      "\t\tMap output materialized bytes=548\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=3012034560\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=1895\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000343_0\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000344_0\r\n",
      "25/08/31 12:04:09 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:09 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:09 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00344-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+1868\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: bufstart = 0; bufend = 445; bufvoid = 104857600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000344_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000344_0' done.\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000344_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1679459\r\n",
      "\t\tFILE: Number of bytes written=1177367\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1179047\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=694\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=445\r\n",
      "\t\tMap output materialized bytes=515\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=3012034560\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=1868\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000344_0\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000345_0\r\n",
      "25/08/31 12:04:09 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:09 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:09 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00345-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+1828\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: bufstart = 0; bufend = 443; bufvoid = 104857600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000345_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000345_0' done.\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000345_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1680674\r\n",
      "\t\tFILE: Number of bytes written=1177912\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1180875\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=696\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=443\r\n",
      "\t\tMap output materialized bytes=513\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=3012034560\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=1828\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000345_0\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000346_0\r\n",
      "25/08/31 12:04:09 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:09 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:09 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00346-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+1774\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: bufstart = 0; bufend = 420; bufvoid = 104857600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000346_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000346_0' done.\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000346_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1681889\r\n",
      "\t\tFILE: Number of bytes written=1178434\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1182649\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=698\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=420\r\n",
      "\t\tMap output materialized bytes=490\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=7\r\n",
      "\t\tTotal committed heap usage (bytes)=3016753152\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=1774\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000346_0\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_m_000347_0\r\n",
      "25/08/31 12:04:09 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:09 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:09 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00347-ecea9d9d-3f07-44c3-ac00-c730049679e1-c000.csv:0+1221\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_title_occurrences.py]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: Records R/W=23/1\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: \r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: bufstart = 0; bufend = 258; bufvoid = 104857600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214308(104857232); length = 89/6553600\r\n",
      "25/08/31 12:04:09 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Task:attempt_local1968043658_0001_m_000347_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Records R/W=23/1\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Task 'attempt_local1968043658_0001_m_000347_0' done.\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_m_000347_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1682592\r\n",
      "\t\tFILE: Number of bytes written=1178776\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1183870\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=700\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=23\r\n",
      "\t\tMap output records=23\r\n",
      "\t\tMap output bytes=258\r\n",
      "\t\tMap output materialized bytes=310\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=23\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=3016753152\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=1221\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_m_000347_0\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: map task executor complete.\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Waiting for reduce tasks\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Starting task: attempt_local1968043658_0001_r_000000_0\r\n",
      "25/08/31 12:04:09 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/31 12:04:09 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/31 12:04:09 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/31 12:04:09 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@131e0fe5\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: The max number of bytes for a single in-memory shuffle cannot be larger than Integer.MAX_VALUE. Setting it to Integer.MAX_VALUE\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=10690022400, maxSingleShuffleLimit=2147483647, mergeThreshold=7055415296, ioSortFactor=10, memToMemMergeOutputsThreshold=10\r\n",
      "25/08/31 12:04:09 INFO reduce.EventFetcher: attempt_local1968043658_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000110_0 decomp: 1608 len: 1612 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1608 bytes from map-output for attempt_local1968043658_0001_m_000110_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1608, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1608\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000212_0 decomp: 1212 len: 1216 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1212 bytes from map-output for attempt_local1968043658_0001_m_000212_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1212, inMemoryMapOutputs.size() -> 2, commitMemory -> 1608, usedMemory ->2820\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000007_0 decomp: 3057 len: 3061 to MEMORY\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 3057 bytes from map-output for attempt_local1968043658_0001_m_000007_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3057, inMemoryMapOutputs.size() -> 3, commitMemory -> 2820, usedMemory ->5877\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000213_0 decomp: 1170 len: 1174 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1170 bytes from map-output for attempt_local1968043658_0001_m_000213_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1170, inMemoryMapOutputs.size() -> 4, commitMemory -> 5877, usedMemory ->7047\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000008_0 decomp: 2905 len: 2909 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 2905 bytes from map-output for attempt_local1968043658_0001_m_000008_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2905, inMemoryMapOutputs.size() -> 5, commitMemory -> 7047, usedMemory ->9952\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000315_0 decomp: 684 len: 688 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 684 bytes from map-output for attempt_local1968043658_0001_m_000315_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 684, inMemoryMapOutputs.size() -> 6, commitMemory -> 9952, usedMemory ->10636\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000006_0 decomp: 3289 len: 3293 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 3289 bytes from map-output for attempt_local1968043658_0001_m_000006_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3289, inMemoryMapOutputs.size() -> 7, commitMemory -> 10636, usedMemory ->13925\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000313_0 decomp: 735 len: 739 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 735 bytes from map-output for attempt_local1968043658_0001_m_000313_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 735, inMemoryMapOutputs.size() -> 8, commitMemory -> 13925, usedMemory ->14660\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000108_0 decomp: 1636 len: 1640 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1636 bytes from map-output for attempt_local1968043658_0001_m_000108_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1636, inMemoryMapOutputs.size() -> 9, commitMemory -> 14660, usedMemory ->16296\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000314_0 decomp: 689 len: 693 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 689 bytes from map-output for attempt_local1968043658_0001_m_000314_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 689, inMemoryMapOutputs.size() -> 10, commitMemory -> 16296, usedMemory ->16985\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000109_0 decomp: 1607 len: 1611 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1607 bytes from map-output for attempt_local1968043658_0001_m_000109_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1607, inMemoryMapOutputs.size() -> 11, commitMemory -> 16985, usedMemory ->18592\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000211_0 decomp: 1205 len: 1209 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1205 bytes from map-output for attempt_local1968043658_0001_m_000211_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1205, inMemoryMapOutputs.size() -> 12, commitMemory -> 18592, usedMemory ->19797\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000318_0 decomp: 656 len: 660 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 656 bytes from map-output for attempt_local1968043658_0001_m_000318_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 656, inMemoryMapOutputs.size() -> 13, commitMemory -> 19797, usedMemory ->20453\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000113_0 decomp: 1529 len: 1533 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1529 bytes from map-output for attempt_local1968043658_0001_m_000113_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1529, inMemoryMapOutputs.size() -> 14, commitMemory -> 20453, usedMemory ->21982\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000215_0 decomp: 1162 len: 1166 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1162 bytes from map-output for attempt_local1968043658_0001_m_000215_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1162, inMemoryMapOutputs.size() -> 15, commitMemory -> 21982, usedMemory ->23144\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000114_0 decomp: 1485 len: 1489 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1485 bytes from map-output for attempt_local1968043658_0001_m_000114_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1485, inMemoryMapOutputs.size() -> 16, commitMemory -> 23144, usedMemory ->24629\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000216_0 decomp: 1136 len: 1140 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1136 bytes from map-output for attempt_local1968043658_0001_m_000216_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1136, inMemoryMapOutputs.size() -> 17, commitMemory -> 24629, usedMemory ->25765\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000011_0 decomp: 2789 len: 2793 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 2789 bytes from map-output for attempt_local1968043658_0001_m_000011_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2789, inMemoryMapOutputs.size() -> 18, commitMemory -> 25765, usedMemory ->28554\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000214_0 decomp: 1153 len: 1157 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1153 bytes from map-output for attempt_local1968043658_0001_m_000214_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1153, inMemoryMapOutputs.size() -> 19, commitMemory -> 28554, usedMemory ->29707\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000009_0 decomp: 3251 len: 3255 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 3251 bytes from map-output for attempt_local1968043658_0001_m_000009_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3251, inMemoryMapOutputs.size() -> 20, commitMemory -> 29707, usedMemory ->32958\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000316_0 decomp: 669 len: 673 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 669 bytes from map-output for attempt_local1968043658_0001_m_000316_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 669, inMemoryMapOutputs.size() -> 21, commitMemory -> 32958, usedMemory ->33627\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000111_0 decomp: 1658 len: 1662 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1658 bytes from map-output for attempt_local1968043658_0001_m_000111_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1658, inMemoryMapOutputs.size() -> 22, commitMemory -> 33627, usedMemory ->35285\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000010_0 decomp: 2935 len: 2939 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 2935 bytes from map-output for attempt_local1968043658_0001_m_000010_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2935, inMemoryMapOutputs.size() -> 23, commitMemory -> 35285, usedMemory ->38220\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000317_0 decomp: 748 len: 752 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 748 bytes from map-output for attempt_local1968043658_0001_m_000317_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 748, inMemoryMapOutputs.size() -> 24, commitMemory -> 38220, usedMemory ->38968\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000112_0 decomp: 1564 len: 1568 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1564 bytes from map-output for attempt_local1968043658_0001_m_000112_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1564, inMemoryMapOutputs.size() -> 25, commitMemory -> 38968, usedMemory ->40532\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000206_0 decomp: 1133 len: 1137 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1133 bytes from map-output for attempt_local1968043658_0001_m_000206_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1133, inMemoryMapOutputs.size() -> 26, commitMemory -> 40532, usedMemory ->41665\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000001_0 decomp: 2172 len: 2176 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 2172 bytes from map-output for attempt_local1968043658_0001_m_000001_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2172, inMemoryMapOutputs.size() -> 27, commitMemory -> 41665, usedMemory ->43837\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000308_0 decomp: 811 len: 815 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 811 bytes from map-output for attempt_local1968043658_0001_m_000308_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 811, inMemoryMapOutputs.size() -> 28, commitMemory -> 43837, usedMemory ->44648\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000103_0 decomp: 1624 len: 1628 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1624 bytes from map-output for attempt_local1968043658_0001_m_000103_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1624, inMemoryMapOutputs.size() -> 29, commitMemory -> 44648, usedMemory ->46272\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000002_0 decomp: 2791 len: 2795 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 2791 bytes from map-output for attempt_local1968043658_0001_m_000002_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2791, inMemoryMapOutputs.size() -> 30, commitMemory -> 46272, usedMemory ->49063\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000309_0 decomp: 742 len: 746 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 742 bytes from map-output for attempt_local1968043658_0001_m_000309_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 742, inMemoryMapOutputs.size() -> 31, commitMemory -> 49063, usedMemory ->49805\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000104_0 decomp: 1644 len: 1648 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1644 bytes from map-output for attempt_local1968043658_0001_m_000104_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1644, inMemoryMapOutputs.size() -> 32, commitMemory -> 49805, usedMemory ->51449\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000102_0 decomp: 1632 len: 1636 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1632 bytes from map-output for attempt_local1968043658_0001_m_000102_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1632, inMemoryMapOutputs.size() -> 33, commitMemory -> 51449, usedMemory ->53081\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000204_0 decomp: 1132 len: 1136 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1132 bytes from map-output for attempt_local1968043658_0001_m_000204_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1132, inMemoryMapOutputs.size() -> 34, commitMemory -> 53081, usedMemory ->54213\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000205_0 decomp: 1205 len: 1209 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1205 bytes from map-output for attempt_local1968043658_0001_m_000205_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1205, inMemoryMapOutputs.size() -> 35, commitMemory -> 54213, usedMemory ->55418\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000000_0 decomp: 1913 len: 1917 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1913 bytes from map-output for attempt_local1968043658_0001_m_000000_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1913, inMemoryMapOutputs.size() -> 36, commitMemory -> 55418, usedMemory ->57331\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000307_0 decomp: 703 len: 707 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 703 bytes from map-output for attempt_local1968043658_0001_m_000307_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 703, inMemoryMapOutputs.size() -> 37, commitMemory -> 57331, usedMemory ->58034\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000209_0 decomp: 1236 len: 1240 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1236 bytes from map-output for attempt_local1968043658_0001_m_000209_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1236, inMemoryMapOutputs.size() -> 38, commitMemory -> 58034, usedMemory ->59270\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000004_0 decomp: 3315 len: 3319 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 3315 bytes from map-output for attempt_local1968043658_0001_m_000004_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3315, inMemoryMapOutputs.size() -> 39, commitMemory -> 59270, usedMemory ->62585\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000311_0 decomp: 715 len: 719 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 715 bytes from map-output for attempt_local1968043658_0001_m_000311_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 715, inMemoryMapOutputs.size() -> 40, commitMemory -> 62585, usedMemory ->63300\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000210_0 decomp: 1221 len: 1225 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1221 bytes from map-output for attempt_local1968043658_0001_m_000210_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1221, inMemoryMapOutputs.size() -> 41, commitMemory -> 63300, usedMemory ->64521\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000005_0 decomp: 3333 len: 3337 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 3333 bytes from map-output for attempt_local1968043658_0001_m_000005_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3333, inMemoryMapOutputs.size() -> 42, commitMemory -> 64521, usedMemory ->67854\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000312_0 decomp: 763 len: 767 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 763 bytes from map-output for attempt_local1968043658_0001_m_000312_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 763, inMemoryMapOutputs.size() -> 43, commitMemory -> 67854, usedMemory ->68617\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000107_0 decomp: 1510 len: 1514 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1510 bytes from map-output for attempt_local1968043658_0001_m_000107_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1510, inMemoryMapOutputs.size() -> 44, commitMemory -> 68617, usedMemory ->70127\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000310_0 decomp: 752 len: 756 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 752 bytes from map-output for attempt_local1968043658_0001_m_000310_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 752, inMemoryMapOutputs.size() -> 45, commitMemory -> 70127, usedMemory ->70879\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000105_0 decomp: 1508 len: 1512 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1508 bytes from map-output for attempt_local1968043658_0001_m_000105_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1508, inMemoryMapOutputs.size() -> 46, commitMemory -> 70879, usedMemory ->72387\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000207_0 decomp: 1170 len: 1174 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1170 bytes from map-output for attempt_local1968043658_0001_m_000207_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1170, inMemoryMapOutputs.size() -> 47, commitMemory -> 72387, usedMemory ->73557\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000106_0 decomp: 1661 len: 1665 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1661 bytes from map-output for attempt_local1968043658_0001_m_000106_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1661, inMemoryMapOutputs.size() -> 48, commitMemory -> 73557, usedMemory ->75218\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000208_0 decomp: 1235 len: 1239 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1235 bytes from map-output for attempt_local1968043658_0001_m_000208_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1235, inMemoryMapOutputs.size() -> 49, commitMemory -> 75218, usedMemory ->76453\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000003_0 decomp: 3068 len: 3072 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 3068 bytes from map-output for attempt_local1968043658_0001_m_000003_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3068, inMemoryMapOutputs.size() -> 50, commitMemory -> 76453, usedMemory ->79521\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000302_0 decomp: 786 len: 790 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 786 bytes from map-output for attempt_local1968043658_0001_m_000302_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 786, inMemoryMapOutputs.size() -> 51, commitMemory -> 79521, usedMemory ->80307\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000097_0 decomp: 1620 len: 1624 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1620 bytes from map-output for attempt_local1968043658_0001_m_000097_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1620, inMemoryMapOutputs.size() -> 52, commitMemory -> 80307, usedMemory ->81927\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000199_0 decomp: 1012 len: 1016 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1012 bytes from map-output for attempt_local1968043658_0001_m_000199_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1012, inMemoryMapOutputs.size() -> 53, commitMemory -> 81927, usedMemory ->82939\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000098_0 decomp: 1690 len: 1694 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1690 bytes from map-output for attempt_local1968043658_0001_m_000098_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1690, inMemoryMapOutputs.size() -> 54, commitMemory -> 82939, usedMemory ->84629\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000200_0 decomp: 1295 len: 1299 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1295 bytes from map-output for attempt_local1968043658_0001_m_000200_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1295, inMemoryMapOutputs.size() -> 55, commitMemory -> 84629, usedMemory ->85924\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000198_0 decomp: 1289 len: 1293 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1289 bytes from map-output for attempt_local1968043658_0001_m_000198_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1289, inMemoryMapOutputs.size() -> 56, commitMemory -> 85924, usedMemory ->87213\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000300_0 decomp: 819 len: 823 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 819 bytes from map-output for attempt_local1968043658_0001_m_000300_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 819, inMemoryMapOutputs.size() -> 57, commitMemory -> 87213, usedMemory ->88032\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000095_0 decomp: 1715 len: 1719 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1715 bytes from map-output for attempt_local1968043658_0001_m_000095_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1715, inMemoryMapOutputs.size() -> 58, commitMemory -> 88032, usedMemory ->89747\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000301_0 decomp: 802 len: 806 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 802 bytes from map-output for attempt_local1968043658_0001_m_000301_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 802, inMemoryMapOutputs.size() -> 59, commitMemory -> 89747, usedMemory ->90549\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000096_0 decomp: 1603 len: 1607 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1603 bytes from map-output for attempt_local1968043658_0001_m_000096_0\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1603, inMemoryMapOutputs.size() -> 60, commitMemory -> 90549, usedMemory ->92152\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000305_0 decomp: 821 len: 825 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 821 bytes from map-output for attempt_local1968043658_0001_m_000305_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 821, inMemoryMapOutputs.size() -> 61, commitMemory -> 92152, usedMemory ->92973\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000100_0 decomp: 1712 len: 1716 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1712 bytes from map-output for attempt_local1968043658_0001_m_000100_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1712, inMemoryMapOutputs.size() -> 62, commitMemory -> 92973, usedMemory ->94685\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000306_0 decomp: 783 len: 787 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 783 bytes from map-output for attempt_local1968043658_0001_m_000306_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 783, inMemoryMapOutputs.size() -> 63, commitMemory -> 94685, usedMemory ->95468\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000101_0 decomp: 1608 len: 1612 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1608 bytes from map-output for attempt_local1968043658_0001_m_000101_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1608, inMemoryMapOutputs.size() -> 64, commitMemory -> 95468, usedMemory ->97076\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000203_0 decomp: 1204 len: 1208 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1204 bytes from map-output for attempt_local1968043658_0001_m_000203_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1204, inMemoryMapOutputs.size() -> 65, commitMemory -> 97076, usedMemory ->98280\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000201_0 decomp: 1093 len: 1097 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1093 bytes from map-output for attempt_local1968043658_0001_m_000201_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1093, inMemoryMapOutputs.size() -> 66, commitMemory -> 98280, usedMemory ->99373\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000303_0 decomp: 756 len: 760 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 756 bytes from map-output for attempt_local1968043658_0001_m_000303_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 756, inMemoryMapOutputs.size() -> 67, commitMemory -> 99373, usedMemory ->100129\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000202_0 decomp: 1164 len: 1168 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1164 bytes from map-output for attempt_local1968043658_0001_m_000202_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1164, inMemoryMapOutputs.size() -> 68, commitMemory -> 100129, usedMemory ->101293\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000304_0 decomp: 807 len: 811 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 807 bytes from map-output for attempt_local1968043658_0001_m_000304_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 807, inMemoryMapOutputs.size() -> 69, commitMemory -> 101293, usedMemory ->102100\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000099_0 decomp: 1583 len: 1587 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1583 bytes from map-output for attempt_local1968043658_0001_m_000099_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1583, inMemoryMapOutputs.size() -> 70, commitMemory -> 102100, usedMemory ->103683\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000193_0 decomp: 1287 len: 1291 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1287 bytes from map-output for attempt_local1968043658_0001_m_000193_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1287, inMemoryMapOutputs.size() -> 71, commitMemory -> 103683, usedMemory ->104970\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000295_0 decomp: 724 len: 728 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 724 bytes from map-output for attempt_local1968043658_0001_m_000295_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 724, inMemoryMapOutputs.size() -> 72, commitMemory -> 104970, usedMemory ->105694\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000194_0 decomp: 1158 len: 1162 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1158 bytes from map-output for attempt_local1968043658_0001_m_000194_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1158, inMemoryMapOutputs.size() -> 73, commitMemory -> 105694, usedMemory ->106852\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000296_0 decomp: 779 len: 783 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 779 bytes from map-output for attempt_local1968043658_0001_m_000296_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 779, inMemoryMapOutputs.size() -> 74, commitMemory -> 106852, usedMemory ->107631\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000091_0 decomp: 1726 len: 1730 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1726 bytes from map-output for attempt_local1968043658_0001_m_000091_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1726, inMemoryMapOutputs.size() -> 75, commitMemory -> 107631, usedMemory ->109357\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000294_0 decomp: 818 len: 822 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 818 bytes from map-output for attempt_local1968043658_0001_m_000294_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 818, inMemoryMapOutputs.size() -> 76, commitMemory -> 109357, usedMemory ->110175\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000089_0 decomp: 1591 len: 1595 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1591 bytes from map-output for attempt_local1968043658_0001_m_000089_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1591, inMemoryMapOutputs.size() -> 77, commitMemory -> 110175, usedMemory ->111766\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000191_0 decomp: 1208 len: 1212 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1208 bytes from map-output for attempt_local1968043658_0001_m_000191_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1208, inMemoryMapOutputs.size() -> 78, commitMemory -> 111766, usedMemory ->112974\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000090_0 decomp: 1621 len: 1625 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1621 bytes from map-output for attempt_local1968043658_0001_m_000090_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1621, inMemoryMapOutputs.size() -> 79, commitMemory -> 112974, usedMemory ->114595\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000192_0 decomp: 1233 len: 1237 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1233 bytes from map-output for attempt_local1968043658_0001_m_000192_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1233, inMemoryMapOutputs.size() -> 80, commitMemory -> 114595, usedMemory ->115828\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000094_0 decomp: 1612 len: 1616 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1612 bytes from map-output for attempt_local1968043658_0001_m_000094_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1612, inMemoryMapOutputs.size() -> 81, commitMemory -> 115828, usedMemory ->117440\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000196_0 decomp: 1181 len: 1185 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1181 bytes from map-output for attempt_local1968043658_0001_m_000196_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1181, inMemoryMapOutputs.size() -> 82, commitMemory -> 117440, usedMemory ->118621\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000197_0 decomp: 1285 len: 1289 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1285 bytes from map-output for attempt_local1968043658_0001_m_000197_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1285, inMemoryMapOutputs.size() -> 83, commitMemory -> 118621, usedMemory ->119906\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000299_0 decomp: 814 len: 818 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 814 bytes from map-output for attempt_local1968043658_0001_m_000299_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 814, inMemoryMapOutputs.size() -> 84, commitMemory -> 119906, usedMemory ->120720\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000297_0 decomp: 837 len: 841 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 837 bytes from map-output for attempt_local1968043658_0001_m_000297_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 837, inMemoryMapOutputs.size() -> 85, commitMemory -> 120720, usedMemory ->121557\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000092_0 decomp: 1505 len: 1509 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1505 bytes from map-output for attempt_local1968043658_0001_m_000092_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1505, inMemoryMapOutputs.size() -> 86, commitMemory -> 121557, usedMemory ->123062\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000298_0 decomp: 837 len: 841 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 837 bytes from map-output for attempt_local1968043658_0001_m_000298_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 837, inMemoryMapOutputs.size() -> 87, commitMemory -> 123062, usedMemory ->123899\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000093_0 decomp: 1598 len: 1602 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1598 bytes from map-output for attempt_local1968043658_0001_m_000093_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1598, inMemoryMapOutputs.size() -> 88, commitMemory -> 123899, usedMemory ->125497\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000195_0 decomp: 1236 len: 1240 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1236 bytes from map-output for attempt_local1968043658_0001_m_000195_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1236, inMemoryMapOutputs.size() -> 89, commitMemory -> 125497, usedMemory ->126733\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000289_0 decomp: 804 len: 808 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 804 bytes from map-output for attempt_local1968043658_0001_m_000289_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 804, inMemoryMapOutputs.size() -> 90, commitMemory -> 126733, usedMemory ->127537\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000084_0 decomp: 1718 len: 1722 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1718 bytes from map-output for attempt_local1968043658_0001_m_000084_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1718, inMemoryMapOutputs.size() -> 91, commitMemory -> 127537, usedMemory ->129255\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000290_0 decomp: 875 len: 879 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 875 bytes from map-output for attempt_local1968043658_0001_m_000290_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 875, inMemoryMapOutputs.size() -> 92, commitMemory -> 129255, usedMemory ->130130\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000085_0 decomp: 1850 len: 1854 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1850 bytes from map-output for attempt_local1968043658_0001_m_000085_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1850, inMemoryMapOutputs.size() -> 93, commitMemory -> 130130, usedMemory ->131980\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000187_0 decomp: 1325 len: 1329 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1325 bytes from map-output for attempt_local1968043658_0001_m_000187_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1325, inMemoryMapOutputs.size() -> 94, commitMemory -> 131980, usedMemory ->133305\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000185_0 decomp: 1217 len: 1221 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1217 bytes from map-output for attempt_local1968043658_0001_m_000185_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1217, inMemoryMapOutputs.size() -> 95, commitMemory -> 133305, usedMemory ->134522\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000287_0 decomp: 784 len: 788 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 784 bytes from map-output for attempt_local1968043658_0001_m_000287_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 784, inMemoryMapOutputs.size() -> 96, commitMemory -> 134522, usedMemory ->135306\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000186_0 decomp: 1137 len: 1141 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1137 bytes from map-output for attempt_local1968043658_0001_m_000186_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1137, inMemoryMapOutputs.size() -> 97, commitMemory -> 135306, usedMemory ->136443\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000288_0 decomp: 842 len: 846 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 842 bytes from map-output for attempt_local1968043658_0001_m_000288_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 842, inMemoryMapOutputs.size() -> 98, commitMemory -> 136443, usedMemory ->137285\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000083_0 decomp: 1727 len: 1731 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1727 bytes from map-output for attempt_local1968043658_0001_m_000083_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1727, inMemoryMapOutputs.size() -> 99, commitMemory -> 137285, usedMemory ->139012\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000190_0 decomp: 1244 len: 1248 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1244 bytes from map-output for attempt_local1968043658_0001_m_000190_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1244, inMemoryMapOutputs.size() -> 100, commitMemory -> 139012, usedMemory ->140256\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000292_0 decomp: 757 len: 761 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 757 bytes from map-output for attempt_local1968043658_0001_m_000292_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 757, inMemoryMapOutputs.size() -> 101, commitMemory -> 140256, usedMemory ->141013\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000087_0 decomp: 1701 len: 1705 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1701 bytes from map-output for attempt_local1968043658_0001_m_000087_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1701, inMemoryMapOutputs.size() -> 102, commitMemory -> 141013, usedMemory ->142714\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000293_0 decomp: 815 len: 819 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 815 bytes from map-output for attempt_local1968043658_0001_m_000293_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 815, inMemoryMapOutputs.size() -> 103, commitMemory -> 142714, usedMemory ->143529\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000088_0 decomp: 1611 len: 1615 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1611 bytes from map-output for attempt_local1968043658_0001_m_000088_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1611, inMemoryMapOutputs.size() -> 104, commitMemory -> 143529, usedMemory ->145140\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000086_0 decomp: 1793 len: 1797 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1793 bytes from map-output for attempt_local1968043658_0001_m_000086_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1793, inMemoryMapOutputs.size() -> 105, commitMemory -> 145140, usedMemory ->146933\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000188_0 decomp: 1335 len: 1339 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1335 bytes from map-output for attempt_local1968043658_0001_m_000188_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1335, inMemoryMapOutputs.size() -> 106, commitMemory -> 146933, usedMemory ->148268\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000189_0 decomp: 1186 len: 1190 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1186 bytes from map-output for attempt_local1968043658_0001_m_000189_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1186, inMemoryMapOutputs.size() -> 107, commitMemory -> 148268, usedMemory ->149454\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000291_0 decomp: 833 len: 837 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 833 bytes from map-output for attempt_local1968043658_0001_m_000291_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 833, inMemoryMapOutputs.size() -> 108, commitMemory -> 149454, usedMemory ->150287\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000078_0 decomp: 1672 len: 1676 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1672 bytes from map-output for attempt_local1968043658_0001_m_000078_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1672, inMemoryMapOutputs.size() -> 109, commitMemory -> 150287, usedMemory ->151959\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000180_0 decomp: 1156 len: 1160 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1156 bytes from map-output for attempt_local1968043658_0001_m_000180_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1156, inMemoryMapOutputs.size() -> 110, commitMemory -> 151959, usedMemory ->153115\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000181_0 decomp: 1281 len: 1285 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1281 bytes from map-output for attempt_local1968043658_0001_m_000181_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1281, inMemoryMapOutputs.size() -> 111, commitMemory -> 153115, usedMemory ->154396\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000283_0 decomp: 819 len: 823 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 819 bytes from map-output for attempt_local1968043658_0001_m_000283_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 819, inMemoryMapOutputs.size() -> 112, commitMemory -> 154396, usedMemory ->155215\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000281_0 decomp: 875 len: 879 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 875 bytes from map-output for attempt_local1968043658_0001_m_000281_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 875, inMemoryMapOutputs.size() -> 113, commitMemory -> 155215, usedMemory ->156090\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000076_0 decomp: 1780 len: 1784 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1780 bytes from map-output for attempt_local1968043658_0001_m_000076_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1780, inMemoryMapOutputs.size() -> 114, commitMemory -> 156090, usedMemory ->157870\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000282_0 decomp: 848 len: 852 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 848 bytes from map-output for attempt_local1968043658_0001_m_000282_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 848, inMemoryMapOutputs.size() -> 115, commitMemory -> 157870, usedMemory ->158718\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000077_0 decomp: 1710 len: 1714 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1710 bytes from map-output for attempt_local1968043658_0001_m_000077_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1710, inMemoryMapOutputs.size() -> 116, commitMemory -> 158718, usedMemory ->160428\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000179_0 decomp: 1299 len: 1303 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1299 bytes from map-output for attempt_local1968043658_0001_m_000179_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1299, inMemoryMapOutputs.size() -> 117, commitMemory -> 160428, usedMemory ->161727\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000286_0 decomp: 863 len: 867 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 863 bytes from map-output for attempt_local1968043658_0001_m_000286_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 863, inMemoryMapOutputs.size() -> 118, commitMemory -> 161727, usedMemory ->162590\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000081_0 decomp: 1723 len: 1727 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1723 bytes from map-output for attempt_local1968043658_0001_m_000081_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1723, inMemoryMapOutputs.size() -> 119, commitMemory -> 162590, usedMemory ->164313\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000183_0 decomp: 1235 len: 1239 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1235 bytes from map-output for attempt_local1968043658_0001_m_000183_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1235, inMemoryMapOutputs.size() -> 120, commitMemory -> 164313, usedMemory ->165548\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000082_0 decomp: 1825 len: 1829 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1825 bytes from map-output for attempt_local1968043658_0001_m_000082_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1825, inMemoryMapOutputs.size() -> 121, commitMemory -> 165548, usedMemory ->167373\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000184_0 decomp: 1266 len: 1270 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1266 bytes from map-output for attempt_local1968043658_0001_m_000184_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1266, inMemoryMapOutputs.size() -> 122, commitMemory -> 167373, usedMemory ->168639\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000182_0 decomp: 1313 len: 1317 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1313 bytes from map-output for attempt_local1968043658_0001_m_000182_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1313, inMemoryMapOutputs.size() -> 123, commitMemory -> 168639, usedMemory ->169952\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000284_0 decomp: 858 len: 862 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 858 bytes from map-output for attempt_local1968043658_0001_m_000284_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 858, inMemoryMapOutputs.size() -> 124, commitMemory -> 169952, usedMemory ->170810\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000079_0 decomp: 1743 len: 1747 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1743 bytes from map-output for attempt_local1968043658_0001_m_000079_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1743, inMemoryMapOutputs.size() -> 125, commitMemory -> 170810, usedMemory ->172553\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000285_0 decomp: 848 len: 852 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 848 bytes from map-output for attempt_local1968043658_0001_m_000285_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 848, inMemoryMapOutputs.size() -> 126, commitMemory -> 172553, usedMemory ->173401\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000080_0 decomp: 1879 len: 1883 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1879 bytes from map-output for attempt_local1968043658_0001_m_000080_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1879, inMemoryMapOutputs.size() -> 127, commitMemory -> 173401, usedMemory ->175280\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000174_0 decomp: 1381 len: 1385 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1381 bytes from map-output for attempt_local1968043658_0001_m_000174_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1381, inMemoryMapOutputs.size() -> 128, commitMemory -> 175280, usedMemory ->176661\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000276_0 decomp: 870 len: 874 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 870 bytes from map-output for attempt_local1968043658_0001_m_000276_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 870, inMemoryMapOutputs.size() -> 129, commitMemory -> 176661, usedMemory ->177531\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000071_0 decomp: 1716 len: 1720 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1716 bytes from map-output for attempt_local1968043658_0001_m_000071_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1716, inMemoryMapOutputs.size() -> 130, commitMemory -> 177531, usedMemory ->179247\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000277_0 decomp: 898 len: 902 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 898 bytes from map-output for attempt_local1968043658_0001_m_000277_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 898, inMemoryMapOutputs.size() -> 131, commitMemory -> 179247, usedMemory ->180145\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000072_0 decomp: 1636 len: 1640 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1636 bytes from map-output for attempt_local1968043658_0001_m_000072_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1636, inMemoryMapOutputs.size() -> 132, commitMemory -> 180145, usedMemory ->181781\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000070_0 decomp: 1756 len: 1760 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1756 bytes from map-output for attempt_local1968043658_0001_m_000070_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1756, inMemoryMapOutputs.size() -> 133, commitMemory -> 181781, usedMemory ->183537\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000172_0 decomp: 1292 len: 1296 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1292 bytes from map-output for attempt_local1968043658_0001_m_000172_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1292, inMemoryMapOutputs.size() -> 134, commitMemory -> 183537, usedMemory ->184829\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000173_0 decomp: 1256 len: 1260 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1256 bytes from map-output for attempt_local1968043658_0001_m_000173_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1256, inMemoryMapOutputs.size() -> 135, commitMemory -> 184829, usedMemory ->186085\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000275_0 decomp: 922 len: 926 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 922 bytes from map-output for attempt_local1968043658_0001_m_000275_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 922, inMemoryMapOutputs.size() -> 136, commitMemory -> 186085, usedMemory ->187007\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000177_0 decomp: 1233 len: 1237 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1233 bytes from map-output for attempt_local1968043658_0001_m_000177_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1233, inMemoryMapOutputs.size() -> 137, commitMemory -> 187007, usedMemory ->188240\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000279_0 decomp: 919 len: 923 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 919 bytes from map-output for attempt_local1968043658_0001_m_000279_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 919, inMemoryMapOutputs.size() -> 138, commitMemory -> 188240, usedMemory ->189159\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000178_0 decomp: 1296 len: 1300 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1296 bytes from map-output for attempt_local1968043658_0001_m_000178_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1296, inMemoryMapOutputs.size() -> 139, commitMemory -> 189159, usedMemory ->190455\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000280_0 decomp: 859 len: 863 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 859 bytes from map-output for attempt_local1968043658_0001_m_000280_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 859, inMemoryMapOutputs.size() -> 140, commitMemory -> 190455, usedMemory ->191314\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000075_0 decomp: 1636 len: 1640 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1636 bytes from map-output for attempt_local1968043658_0001_m_000075_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1636, inMemoryMapOutputs.size() -> 141, commitMemory -> 191314, usedMemory ->192950\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000278_0 decomp: 992 len: 996 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 992 bytes from map-output for attempt_local1968043658_0001_m_000278_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 992, inMemoryMapOutputs.size() -> 142, commitMemory -> 192950, usedMemory ->193942\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000073_0 decomp: 1828 len: 1832 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1828 bytes from map-output for attempt_local1968043658_0001_m_000073_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1828, inMemoryMapOutputs.size() -> 143, commitMemory -> 193942, usedMemory ->195770\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000175_0 decomp: 1296 len: 1300 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1296 bytes from map-output for attempt_local1968043658_0001_m_000175_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1296, inMemoryMapOutputs.size() -> 144, commitMemory -> 195770, usedMemory ->197066\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000074_0 decomp: 1816 len: 1820 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1816 bytes from map-output for attempt_local1968043658_0001_m_000074_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1816, inMemoryMapOutputs.size() -> 145, commitMemory -> 197066, usedMemory ->198882\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000176_0 decomp: 1204 len: 1208 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1204 bytes from map-output for attempt_local1968043658_0001_m_000176_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1204, inMemoryMapOutputs.size() -> 146, commitMemory -> 198882, usedMemory ->200086\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000270_0 decomp: 932 len: 936 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 932 bytes from map-output for attempt_local1968043658_0001_m_000270_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 932, inMemoryMapOutputs.size() -> 147, commitMemory -> 200086, usedMemory ->201018\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000065_0 decomp: 1807 len: 1811 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1807 bytes from map-output for attempt_local1968043658_0001_m_000065_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1807, inMemoryMapOutputs.size() -> 148, commitMemory -> 201018, usedMemory ->202825\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000167_0 decomp: 1267 len: 1271 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1267 bytes from map-output for attempt_local1968043658_0001_m_000167_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1267, inMemoryMapOutputs.size() -> 149, commitMemory -> 202825, usedMemory ->204092\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000066_0 decomp: 1895 len: 1899 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1895 bytes from map-output for attempt_local1968043658_0001_m_000066_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1895, inMemoryMapOutputs.size() -> 150, commitMemory -> 204092, usedMemory ->205987\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000168_0 decomp: 1492 len: 1496 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1492 bytes from map-output for attempt_local1968043658_0001_m_000168_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1492, inMemoryMapOutputs.size() -> 151, commitMemory -> 205987, usedMemory ->207479\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000166_0 decomp: 1373 len: 1377 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1373 bytes from map-output for attempt_local1968043658_0001_m_000166_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1373, inMemoryMapOutputs.size() -> 152, commitMemory -> 207479, usedMemory ->208852\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000268_0 decomp: 908 len: 912 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 908 bytes from map-output for attempt_local1968043658_0001_m_000268_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 908, inMemoryMapOutputs.size() -> 153, commitMemory -> 208852, usedMemory ->209760\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000063_0 decomp: 1877 len: 1881 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1877 bytes from map-output for attempt_local1968043658_0001_m_000063_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1877, inMemoryMapOutputs.size() -> 154, commitMemory -> 209760, usedMemory ->211637\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000269_0 decomp: 877 len: 881 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 877 bytes from map-output for attempt_local1968043658_0001_m_000269_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 877, inMemoryMapOutputs.size() -> 155, commitMemory -> 211637, usedMemory ->212514\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000064_0 decomp: 1736 len: 1740 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1736 bytes from map-output for attempt_local1968043658_0001_m_000064_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1736, inMemoryMapOutputs.size() -> 156, commitMemory -> 212514, usedMemory ->214250\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000273_0 decomp: 867 len: 871 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 867 bytes from map-output for attempt_local1968043658_0001_m_000273_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 867, inMemoryMapOutputs.size() -> 157, commitMemory -> 214250, usedMemory ->215117\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000068_0 decomp: 1760 len: 1764 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1760 bytes from map-output for attempt_local1968043658_0001_m_000068_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1760, inMemoryMapOutputs.size() -> 158, commitMemory -> 215117, usedMemory ->216877\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000274_0 decomp: 860 len: 864 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 860 bytes from map-output for attempt_local1968043658_0001_m_000274_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 860, inMemoryMapOutputs.size() -> 159, commitMemory -> 216877, usedMemory ->217737\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000069_0 decomp: 1743 len: 1747 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1743 bytes from map-output for attempt_local1968043658_0001_m_000069_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1743, inMemoryMapOutputs.size() -> 160, commitMemory -> 217737, usedMemory ->219480\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000171_0 decomp: 1292 len: 1296 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1292 bytes from map-output for attempt_local1968043658_0001_m_000171_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1292, inMemoryMapOutputs.size() -> 161, commitMemory -> 219480, usedMemory ->220772\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000169_0 decomp: 1229 len: 1233 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1229 bytes from map-output for attempt_local1968043658_0001_m_000169_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1229, inMemoryMapOutputs.size() -> 162, commitMemory -> 220772, usedMemory ->222001\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000271_0 decomp: 941 len: 945 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 941 bytes from map-output for attempt_local1968043658_0001_m_000271_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 941, inMemoryMapOutputs.size() -> 163, commitMemory -> 222001, usedMemory ->222942\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000170_0 decomp: 1051 len: 1055 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1051 bytes from map-output for attempt_local1968043658_0001_m_000170_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1051, inMemoryMapOutputs.size() -> 164, commitMemory -> 222942, usedMemory ->223993\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000272_0 decomp: 827 len: 831 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 827 bytes from map-output for attempt_local1968043658_0001_m_000272_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 827, inMemoryMapOutputs.size() -> 165, commitMemory -> 223993, usedMemory ->224820\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000067_0 decomp: 1815 len: 1819 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1815 bytes from map-output for attempt_local1968043658_0001_m_000067_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1815, inMemoryMapOutputs.size() -> 166, commitMemory -> 224820, usedMemory ->226635\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000161_0 decomp: 1348 len: 1352 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1348 bytes from map-output for attempt_local1968043658_0001_m_000161_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1348, inMemoryMapOutputs.size() -> 167, commitMemory -> 226635, usedMemory ->227983\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000263_0 decomp: 885 len: 889 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 885 bytes from map-output for attempt_local1968043658_0001_m_000263_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 885, inMemoryMapOutputs.size() -> 168, commitMemory -> 227983, usedMemory ->228868\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000162_0 decomp: 1283 len: 1287 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1283 bytes from map-output for attempt_local1968043658_0001_m_000162_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1283, inMemoryMapOutputs.size() -> 169, commitMemory -> 228868, usedMemory ->230151\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000264_0 decomp: 906 len: 910 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 906 bytes from map-output for attempt_local1968043658_0001_m_000264_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 906, inMemoryMapOutputs.size() -> 170, commitMemory -> 230151, usedMemory ->231057\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000059_0 decomp: 1801 len: 1805 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1801 bytes from map-output for attempt_local1968043658_0001_m_000059_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1801, inMemoryMapOutputs.size() -> 171, commitMemory -> 231057, usedMemory ->232858\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000262_0 decomp: 1029 len: 1033 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1029 bytes from map-output for attempt_local1968043658_0001_m_000262_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1029, inMemoryMapOutputs.size() -> 172, commitMemory -> 232858, usedMemory ->233887\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000057_0 decomp: 2018 len: 2022 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 2018 bytes from map-output for attempt_local1968043658_0001_m_000057_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2018, inMemoryMapOutputs.size() -> 173, commitMemory -> 233887, usedMemory ->235905\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000159_0 decomp: 1311 len: 1315 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1311 bytes from map-output for attempt_local1968043658_0001_m_000159_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1311, inMemoryMapOutputs.size() -> 174, commitMemory -> 235905, usedMemory ->237216\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000058_0 decomp: 1858 len: 1862 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1858 bytes from map-output for attempt_local1968043658_0001_m_000058_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1858, inMemoryMapOutputs.size() -> 175, commitMemory -> 237216, usedMemory ->239074\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000160_0 decomp: 1381 len: 1385 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1381 bytes from map-output for attempt_local1968043658_0001_m_000160_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1381, inMemoryMapOutputs.size() -> 176, commitMemory -> 239074, usedMemory ->240455\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000062_0 decomp: 1895 len: 1899 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1895 bytes from map-output for attempt_local1968043658_0001_m_000062_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1895, inMemoryMapOutputs.size() -> 177, commitMemory -> 240455, usedMemory ->242350\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000164_0 decomp: 1362 len: 1366 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1362 bytes from map-output for attempt_local1968043658_0001_m_000164_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1362, inMemoryMapOutputs.size() -> 178, commitMemory -> 242350, usedMemory ->243712\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000165_0 decomp: 1434 len: 1438 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1434 bytes from map-output for attempt_local1968043658_0001_m_000165_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1434, inMemoryMapOutputs.size() -> 179, commitMemory -> 243712, usedMemory ->245146\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000267_0 decomp: 960 len: 964 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 960 bytes from map-output for attempt_local1968043658_0001_m_000267_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 960, inMemoryMapOutputs.size() -> 180, commitMemory -> 245146, usedMemory ->246106\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000265_0 decomp: 914 len: 918 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 914 bytes from map-output for attempt_local1968043658_0001_m_000265_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 914, inMemoryMapOutputs.size() -> 181, commitMemory -> 246106, usedMemory ->247020\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000060_0 decomp: 1903 len: 1907 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1903 bytes from map-output for attempt_local1968043658_0001_m_000060_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1903, inMemoryMapOutputs.size() -> 182, commitMemory -> 247020, usedMemory ->248923\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000266_0 decomp: 863 len: 867 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 863 bytes from map-output for attempt_local1968043658_0001_m_000266_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 863, inMemoryMapOutputs.size() -> 183, commitMemory -> 248923, usedMemory ->249786\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000061_0 decomp: 1822 len: 1826 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1822 bytes from map-output for attempt_local1968043658_0001_m_000061_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1822, inMemoryMapOutputs.size() -> 184, commitMemory -> 249786, usedMemory ->251608\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000163_0 decomp: 1313 len: 1317 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1313 bytes from map-output for attempt_local1968043658_0001_m_000163_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1313, inMemoryMapOutputs.size() -> 185, commitMemory -> 251608, usedMemory ->252921\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000257_0 decomp: 1011 len: 1015 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1011 bytes from map-output for attempt_local1968043658_0001_m_000257_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1011, inMemoryMapOutputs.size() -> 186, commitMemory -> 252921, usedMemory ->253932\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000052_0 decomp: 1964 len: 1968 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1964 bytes from map-output for attempt_local1968043658_0001_m_000052_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1964, inMemoryMapOutputs.size() -> 187, commitMemory -> 253932, usedMemory ->255896\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000258_0 decomp: 969 len: 973 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 969 bytes from map-output for attempt_local1968043658_0001_m_000258_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 969, inMemoryMapOutputs.size() -> 188, commitMemory -> 255896, usedMemory ->256865\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000053_0 decomp: 1783 len: 1787 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1783 bytes from map-output for attempt_local1968043658_0001_m_000053_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1783, inMemoryMapOutputs.size() -> 189, commitMemory -> 256865, usedMemory ->258648\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000155_0 decomp: 1507 len: 1511 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1507 bytes from map-output for attempt_local1968043658_0001_m_000155_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1507, inMemoryMapOutputs.size() -> 190, commitMemory -> 258648, usedMemory ->260155\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000153_0 decomp: 1517 len: 1521 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1517 bytes from map-output for attempt_local1968043658_0001_m_000153_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1517, inMemoryMapOutputs.size() -> 191, commitMemory -> 260155, usedMemory ->261672\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000255_0 decomp: 955 len: 959 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 955 bytes from map-output for attempt_local1968043658_0001_m_000255_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 955, inMemoryMapOutputs.size() -> 192, commitMemory -> 261672, usedMemory ->262627\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000154_0 decomp: 1356 len: 1360 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1356 bytes from map-output for attempt_local1968043658_0001_m_000154_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1356, inMemoryMapOutputs.size() -> 193, commitMemory -> 262627, usedMemory ->263983\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000256_0 decomp: 913 len: 917 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 913 bytes from map-output for attempt_local1968043658_0001_m_000256_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 913, inMemoryMapOutputs.size() -> 194, commitMemory -> 263983, usedMemory ->264896\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000051_0 decomp: 1908 len: 1912 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1908 bytes from map-output for attempt_local1968043658_0001_m_000051_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1908, inMemoryMapOutputs.size() -> 195, commitMemory -> 264896, usedMemory ->266804\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000158_0 decomp: 1305 len: 1309 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1305 bytes from map-output for attempt_local1968043658_0001_m_000158_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1305, inMemoryMapOutputs.size() -> 196, commitMemory -> 266804, usedMemory ->268109\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000260_0 decomp: 1010 len: 1014 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1010 bytes from map-output for attempt_local1968043658_0001_m_000260_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1010, inMemoryMapOutputs.size() -> 197, commitMemory -> 268109, usedMemory ->269119\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000055_0 decomp: 1887 len: 1891 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1887 bytes from map-output for attempt_local1968043658_0001_m_000055_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1887, inMemoryMapOutputs.size() -> 198, commitMemory -> 269119, usedMemory ->271006\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000261_0 decomp: 980 len: 984 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 980 bytes from map-output for attempt_local1968043658_0001_m_000261_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 980, inMemoryMapOutputs.size() -> 199, commitMemory -> 271006, usedMemory ->271986\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000056_0 decomp: 1757 len: 1761 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1757 bytes from map-output for attempt_local1968043658_0001_m_000056_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1757, inMemoryMapOutputs.size() -> 200, commitMemory -> 271986, usedMemory ->273743\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000054_0 decomp: 1991 len: 1995 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1991 bytes from map-output for attempt_local1968043658_0001_m_000054_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1991, inMemoryMapOutputs.size() -> 201, commitMemory -> 273743, usedMemory ->275734\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000156_0 decomp: 1384 len: 1388 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1384 bytes from map-output for attempt_local1968043658_0001_m_000156_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1384, inMemoryMapOutputs.size() -> 202, commitMemory -> 275734, usedMemory ->277118\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000157_0 decomp: 1239 len: 1243 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1239 bytes from map-output for attempt_local1968043658_0001_m_000157_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1239, inMemoryMapOutputs.size() -> 203, commitMemory -> 277118, usedMemory ->278357\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000259_0 decomp: 987 len: 991 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 987 bytes from map-output for attempt_local1968043658_0001_m_000259_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 987, inMemoryMapOutputs.size() -> 204, commitMemory -> 278357, usedMemory ->279344\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000046_0 decomp: 2049 len: 2053 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 2049 bytes from map-output for attempt_local1968043658_0001_m_000046_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2049, inMemoryMapOutputs.size() -> 205, commitMemory -> 279344, usedMemory ->281393\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000148_0 decomp: 1240 len: 1244 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1240 bytes from map-output for attempt_local1968043658_0001_m_000148_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1240, inMemoryMapOutputs.size() -> 206, commitMemory -> 281393, usedMemory ->282633\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000149_0 decomp: 1464 len: 1468 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1464 bytes from map-output for attempt_local1968043658_0001_m_000149_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1464, inMemoryMapOutputs.size() -> 207, commitMemory -> 282633, usedMemory ->284097\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000251_0 decomp: 1091 len: 1095 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1091 bytes from map-output for attempt_local1968043658_0001_m_000251_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1091, inMemoryMapOutputs.size() -> 208, commitMemory -> 284097, usedMemory ->285188\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000249_0 decomp: 1068 len: 1072 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1068 bytes from map-output for attempt_local1968043658_0001_m_000249_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1068, inMemoryMapOutputs.size() -> 209, commitMemory -> 285188, usedMemory ->286256\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000044_0 decomp: 1804 len: 1808 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1804 bytes from map-output for attempt_local1968043658_0001_m_000044_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1804, inMemoryMapOutputs.size() -> 210, commitMemory -> 286256, usedMemory ->288060\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000250_0 decomp: 980 len: 984 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 980 bytes from map-output for attempt_local1968043658_0001_m_000250_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 980, inMemoryMapOutputs.size() -> 211, commitMemory -> 288060, usedMemory ->289040\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000045_0 decomp: 1886 len: 1890 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1886 bytes from map-output for attempt_local1968043658_0001_m_000045_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1886, inMemoryMapOutputs.size() -> 212, commitMemory -> 289040, usedMemory ->290926\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000147_0 decomp: 1350 len: 1354 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1350 bytes from map-output for attempt_local1968043658_0001_m_000147_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1350, inMemoryMapOutputs.size() -> 213, commitMemory -> 290926, usedMemory ->292276\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000254_0 decomp: 923 len: 927 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 923 bytes from map-output for attempt_local1968043658_0001_m_000254_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 923, inMemoryMapOutputs.size() -> 214, commitMemory -> 292276, usedMemory ->293199\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000049_0 decomp: 1849 len: 1853 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1849 bytes from map-output for attempt_local1968043658_0001_m_000049_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1849, inMemoryMapOutputs.size() -> 215, commitMemory -> 293199, usedMemory ->295048\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000151_0 decomp: 1314 len: 1318 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1314 bytes from map-output for attempt_local1968043658_0001_m_000151_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1314, inMemoryMapOutputs.size() -> 216, commitMemory -> 295048, usedMemory ->296362\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000050_0 decomp: 1980 len: 1984 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1980 bytes from map-output for attempt_local1968043658_0001_m_000050_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1980, inMemoryMapOutputs.size() -> 217, commitMemory -> 296362, usedMemory ->298342\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000152_0 decomp: 1311 len: 1315 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1311 bytes from map-output for attempt_local1968043658_0001_m_000152_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1311, inMemoryMapOutputs.size() -> 218, commitMemory -> 298342, usedMemory ->299653\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000150_0 decomp: 1492 len: 1496 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1492 bytes from map-output for attempt_local1968043658_0001_m_000150_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1492, inMemoryMapOutputs.size() -> 219, commitMemory -> 299653, usedMemory ->301145\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000252_0 decomp: 929 len: 933 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 929 bytes from map-output for attempt_local1968043658_0001_m_000252_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 929, inMemoryMapOutputs.size() -> 220, commitMemory -> 301145, usedMemory ->302074\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000047_0 decomp: 1787 len: 1791 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1787 bytes from map-output for attempt_local1968043658_0001_m_000047_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1787, inMemoryMapOutputs.size() -> 221, commitMemory -> 302074, usedMemory ->303861\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000253_0 decomp: 963 len: 967 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 963 bytes from map-output for attempt_local1968043658_0001_m_000253_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 963, inMemoryMapOutputs.size() -> 222, commitMemory -> 303861, usedMemory ->304824\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000048_0 decomp: 1855 len: 1859 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1855 bytes from map-output for attempt_local1968043658_0001_m_000048_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1855, inMemoryMapOutputs.size() -> 223, commitMemory -> 304824, usedMemory ->306679\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000142_0 decomp: 1543 len: 1547 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1543 bytes from map-output for attempt_local1968043658_0001_m_000142_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1543, inMemoryMapOutputs.size() -> 224, commitMemory -> 306679, usedMemory ->308222\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000244_0 decomp: 1091 len: 1095 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1091 bytes from map-output for attempt_local1968043658_0001_m_000244_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1091, inMemoryMapOutputs.size() -> 225, commitMemory -> 308222, usedMemory ->309313\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000039_0 decomp: 2067 len: 2071 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 2067 bytes from map-output for attempt_local1968043658_0001_m_000039_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2067, inMemoryMapOutputs.size() -> 226, commitMemory -> 309313, usedMemory ->311380\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000245_0 decomp: 1005 len: 1009 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1005 bytes from map-output for attempt_local1968043658_0001_m_000245_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1005, inMemoryMapOutputs.size() -> 227, commitMemory -> 311380, usedMemory ->312385\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000040_0 decomp: 1980 len: 1984 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1980 bytes from map-output for attempt_local1968043658_0001_m_000040_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1980, inMemoryMapOutputs.size() -> 228, commitMemory -> 312385, usedMemory ->314365\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000347_0 decomp: 306 len: 310 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 306 bytes from map-output for attempt_local1968043658_0001_m_000347_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 306, inMemoryMapOutputs.size() -> 229, commitMemory -> 314365, usedMemory ->314671\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000038_0 decomp: 2074 len: 2078 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 2074 bytes from map-output for attempt_local1968043658_0001_m_000038_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2074, inMemoryMapOutputs.size() -> 230, commitMemory -> 314671, usedMemory ->316745\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000345_0 decomp: 509 len: 513 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 509 bytes from map-output for attempt_local1968043658_0001_m_000345_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 509, inMemoryMapOutputs.size() -> 231, commitMemory -> 316745, usedMemory ->317254\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000140_0 decomp: 1514 len: 1518 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1514 bytes from map-output for attempt_local1968043658_0001_m_000140_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1514, inMemoryMapOutputs.size() -> 232, commitMemory -> 317254, usedMemory ->318768\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000346_0 decomp: 486 len: 490 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 486 bytes from map-output for attempt_local1968043658_0001_m_000346_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 486, inMemoryMapOutputs.size() -> 233, commitMemory -> 318768, usedMemory ->319254\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000141_0 decomp: 1375 len: 1379 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1375 bytes from map-output for attempt_local1968043658_0001_m_000141_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1375, inMemoryMapOutputs.size() -> 234, commitMemory -> 319254, usedMemory ->320629\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000243_0 decomp: 1158 len: 1162 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1158 bytes from map-output for attempt_local1968043658_0001_m_000243_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1158, inMemoryMapOutputs.size() -> 235, commitMemory -> 320629, usedMemory ->321787\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000145_0 decomp: 1361 len: 1365 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1361 bytes from map-output for attempt_local1968043658_0001_m_000145_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1361, inMemoryMapOutputs.size() -> 236, commitMemory -> 321787, usedMemory ->323148\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000247_0 decomp: 949 len: 953 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 949 bytes from map-output for attempt_local1968043658_0001_m_000247_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 949, inMemoryMapOutputs.size() -> 237, commitMemory -> 323148, usedMemory ->324097\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000146_0 decomp: 1301 len: 1305 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1301 bytes from map-output for attempt_local1968043658_0001_m_000146_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1301, inMemoryMapOutputs.size() -> 238, commitMemory -> 324097, usedMemory ->325398\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000248_0 decomp: 1001 len: 1005 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1001 bytes from map-output for attempt_local1968043658_0001_m_000248_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1001, inMemoryMapOutputs.size() -> 239, commitMemory -> 325398, usedMemory ->326399\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000043_0 decomp: 1973 len: 1977 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1973 bytes from map-output for attempt_local1968043658_0001_m_000043_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1973, inMemoryMapOutputs.size() -> 240, commitMemory -> 326399, usedMemory ->328372\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000246_0 decomp: 977 len: 981 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 977 bytes from map-output for attempt_local1968043658_0001_m_000246_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 977, inMemoryMapOutputs.size() -> 241, commitMemory -> 328372, usedMemory ->329349\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000041_0 decomp: 1972 len: 1976 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1972 bytes from map-output for attempt_local1968043658_0001_m_000041_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1972, inMemoryMapOutputs.size() -> 242, commitMemory -> 329349, usedMemory ->331321\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000143_0 decomp: 1318 len: 1322 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1318 bytes from map-output for attempt_local1968043658_0001_m_000143_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1318, inMemoryMapOutputs.size() -> 243, commitMemory -> 331321, usedMemory ->332639\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000042_0 decomp: 1906 len: 1910 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1906 bytes from map-output for attempt_local1968043658_0001_m_000042_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1906, inMemoryMapOutputs.size() -> 244, commitMemory -> 332639, usedMemory ->334545\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000144_0 decomp: 1441 len: 1445 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1441 bytes from map-output for attempt_local1968043658_0001_m_000144_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1441, inMemoryMapOutputs.size() -> 245, commitMemory -> 334545, usedMemory ->335986\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000238_0 decomp: 1043 len: 1047 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1043 bytes from map-output for attempt_local1968043658_0001_m_000238_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1043, inMemoryMapOutputs.size() -> 246, commitMemory -> 335986, usedMemory ->337029\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000033_0 decomp: 2090 len: 2094 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 2090 bytes from map-output for attempt_local1968043658_0001_m_000033_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2090, inMemoryMapOutputs.size() -> 247, commitMemory -> 337029, usedMemory ->339119\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000340_0 decomp: 573 len: 577 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 573 bytes from map-output for attempt_local1968043658_0001_m_000340_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 573, inMemoryMapOutputs.size() -> 248, commitMemory -> 339119, usedMemory ->339692\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000135_0 decomp: 1530 len: 1534 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1530 bytes from map-output for attempt_local1968043658_0001_m_000135_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1530, inMemoryMapOutputs.size() -> 249, commitMemory -> 339692, usedMemory ->341222\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000034_0 decomp: 1939 len: 1943 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1939 bytes from map-output for attempt_local1968043658_0001_m_000034_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1939, inMemoryMapOutputs.size() -> 250, commitMemory -> 341222, usedMemory ->343161\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000341_0 decomp: 534 len: 538 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 534 bytes from map-output for attempt_local1968043658_0001_m_000341_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 534, inMemoryMapOutputs.size() -> 251, commitMemory -> 343161, usedMemory ->343695\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000136_0 decomp: 1436 len: 1440 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1436 bytes from map-output for attempt_local1968043658_0001_m_000136_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1436, inMemoryMapOutputs.size() -> 252, commitMemory -> 343695, usedMemory ->345131\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000134_0 decomp: 1341 len: 1345 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1341 bytes from map-output for attempt_local1968043658_0001_m_000134_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1341, inMemoryMapOutputs.size() -> 253, commitMemory -> 345131, usedMemory ->346472\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000236_0 decomp: 1119 len: 1123 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1119 bytes from map-output for attempt_local1968043658_0001_m_000236_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1119, inMemoryMapOutputs.size() -> 254, commitMemory -> 346472, usedMemory ->347591\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000031_0 decomp: 2119 len: 2123 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 2119 bytes from map-output for attempt_local1968043658_0001_m_000031_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2119, inMemoryMapOutputs.size() -> 255, commitMemory -> 347591, usedMemory ->349710\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000237_0 decomp: 1118 len: 1122 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1118 bytes from map-output for attempt_local1968043658_0001_m_000237_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1118, inMemoryMapOutputs.size() -> 256, commitMemory -> 349710, usedMemory ->350828\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000032_0 decomp: 2075 len: 2079 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 2075 bytes from map-output for attempt_local1968043658_0001_m_000032_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2075, inMemoryMapOutputs.size() -> 257, commitMemory -> 350828, usedMemory ->352903\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000339_0 decomp: 561 len: 565 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 561 bytes from map-output for attempt_local1968043658_0001_m_000339_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 561, inMemoryMapOutputs.size() -> 258, commitMemory -> 352903, usedMemory ->353464\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000241_0 decomp: 1001 len: 1005 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1001 bytes from map-output for attempt_local1968043658_0001_m_000241_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1001, inMemoryMapOutputs.size() -> 259, commitMemory -> 353464, usedMemory ->354465\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000036_0 decomp: 2012 len: 2016 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 2012 bytes from map-output for attempt_local1968043658_0001_m_000036_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2012, inMemoryMapOutputs.size() -> 260, commitMemory -> 354465, usedMemory ->356477\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000343_0 decomp: 544 len: 548 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 544 bytes from map-output for attempt_local1968043658_0001_m_000343_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 544, inMemoryMapOutputs.size() -> 261, commitMemory -> 356477, usedMemory ->357021\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000242_0 decomp: 974 len: 978 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 974 bytes from map-output for attempt_local1968043658_0001_m_000242_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 974, inMemoryMapOutputs.size() -> 262, commitMemory -> 357021, usedMemory ->357995\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000037_0 decomp: 2050 len: 2054 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 2050 bytes from map-output for attempt_local1968043658_0001_m_000037_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2050, inMemoryMapOutputs.size() -> 263, commitMemory -> 357995, usedMemory ->360045\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000344_0 decomp: 511 len: 515 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 511 bytes from map-output for attempt_local1968043658_0001_m_000344_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 511, inMemoryMapOutputs.size() -> 264, commitMemory -> 360045, usedMemory ->360556\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000139_0 decomp: 1371 len: 1375 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1371 bytes from map-output for attempt_local1968043658_0001_m_000139_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1371, inMemoryMapOutputs.size() -> 265, commitMemory -> 360556, usedMemory ->361927\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000342_0 decomp: 520 len: 524 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 520 bytes from map-output for attempt_local1968043658_0001_m_000342_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 520, inMemoryMapOutputs.size() -> 266, commitMemory -> 361927, usedMemory ->362447\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000137_0 decomp: 1415 len: 1419 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1415 bytes from map-output for attempt_local1968043658_0001_m_000137_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1415, inMemoryMapOutputs.size() -> 267, commitMemory -> 362447, usedMemory ->363862\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000239_0 decomp: 968 len: 972 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 968 bytes from map-output for attempt_local1968043658_0001_m_000239_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 968, inMemoryMapOutputs.size() -> 268, commitMemory -> 363862, usedMemory ->364830\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000138_0 decomp: 1374 len: 1378 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1374 bytes from map-output for attempt_local1968043658_0001_m_000138_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1374, inMemoryMapOutputs.size() -> 269, commitMemory -> 364830, usedMemory ->366204\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000240_0 decomp: 995 len: 999 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 995 bytes from map-output for attempt_local1968043658_0001_m_000240_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 995, inMemoryMapOutputs.size() -> 270, commitMemory -> 366204, usedMemory ->367199\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000035_0 decomp: 2175 len: 2179 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 2175 bytes from map-output for attempt_local1968043658_0001_m_000035_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2175, inMemoryMapOutputs.size() -> 271, commitMemory -> 367199, usedMemory ->369374\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000334_0 decomp: 597 len: 601 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 597 bytes from map-output for attempt_local1968043658_0001_m_000334_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 597, inMemoryMapOutputs.size() -> 272, commitMemory -> 369374, usedMemory ->369971\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000129_0 decomp: 1501 len: 1505 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1501 bytes from map-output for attempt_local1968043658_0001_m_000129_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1501, inMemoryMapOutputs.size() -> 273, commitMemory -> 369971, usedMemory ->371472\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000231_0 decomp: 1147 len: 1151 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1147 bytes from map-output for attempt_local1968043658_0001_m_000231_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1147, inMemoryMapOutputs.size() -> 274, commitMemory -> 371472, usedMemory ->372619\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000130_0 decomp: 1481 len: 1485 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1481 bytes from map-output for attempt_local1968043658_0001_m_000130_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1481, inMemoryMapOutputs.size() -> 275, commitMemory -> 372619, usedMemory ->374100\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000232_0 decomp: 1062 len: 1066 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1062 bytes from map-output for attempt_local1968043658_0001_m_000232_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1062, inMemoryMapOutputs.size() -> 276, commitMemory -> 374100, usedMemory ->375162\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000027_0 decomp: 2096 len: 2100 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 2096 bytes from map-output for attempt_local1968043658_0001_m_000027_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2096, inMemoryMapOutputs.size() -> 277, commitMemory -> 375162, usedMemory ->377258\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000230_0 decomp: 1067 len: 1071 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1067 bytes from map-output for attempt_local1968043658_0001_m_000230_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1067, inMemoryMapOutputs.size() -> 278, commitMemory -> 377258, usedMemory ->378325\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000025_0 decomp: 2368 len: 2372 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 2368 bytes from map-output for attempt_local1968043658_0001_m_000025_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2368, inMemoryMapOutputs.size() -> 279, commitMemory -> 378325, usedMemory ->380693\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000332_0 decomp: 618 len: 622 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 618 bytes from map-output for attempt_local1968043658_0001_m_000332_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 618, inMemoryMapOutputs.size() -> 280, commitMemory -> 380693, usedMemory ->381311\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000127_0 decomp: 1487 len: 1491 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1487 bytes from map-output for attempt_local1968043658_0001_m_000127_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1487, inMemoryMapOutputs.size() -> 281, commitMemory -> 381311, usedMemory ->382798\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000026_0 decomp: 2310 len: 2314 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 2310 bytes from map-output for attempt_local1968043658_0001_m_000026_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2310, inMemoryMapOutputs.size() -> 282, commitMemory -> 382798, usedMemory ->385108\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000333_0 decomp: 647 len: 651 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 647 bytes from map-output for attempt_local1968043658_0001_m_000333_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 647, inMemoryMapOutputs.size() -> 283, commitMemory -> 385108, usedMemory ->385755\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000128_0 decomp: 1427 len: 1431 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1427 bytes from map-output for attempt_local1968043658_0001_m_000128_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1427, inMemoryMapOutputs.size() -> 284, commitMemory -> 385755, usedMemory ->387182\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000030_0 decomp: 2155 len: 2159 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 2155 bytes from map-output for attempt_local1968043658_0001_m_000030_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2155, inMemoryMapOutputs.size() -> 285, commitMemory -> 387182, usedMemory ->389337\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000337_0 decomp: 609 len: 613 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 609 bytes from map-output for attempt_local1968043658_0001_m_000337_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 609, inMemoryMapOutputs.size() -> 286, commitMemory -> 389337, usedMemory ->389946\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000132_0 decomp: 1406 len: 1410 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1406 bytes from map-output for attempt_local1968043658_0001_m_000132_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1406, inMemoryMapOutputs.size() -> 287, commitMemory -> 389946, usedMemory ->391352\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000338_0 decomp: 598 len: 602 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 598 bytes from map-output for attempt_local1968043658_0001_m_000338_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 598, inMemoryMapOutputs.size() -> 288, commitMemory -> 391352, usedMemory ->391950\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000133_0 decomp: 1279 len: 1283 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1279 bytes from map-output for attempt_local1968043658_0001_m_000133_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1279, inMemoryMapOutputs.size() -> 289, commitMemory -> 391950, usedMemory ->393229\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000235_0 decomp: 1044 len: 1048 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1044 bytes from map-output for attempt_local1968043658_0001_m_000235_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1044, inMemoryMapOutputs.size() -> 290, commitMemory -> 393229, usedMemory ->394273\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000233_0 decomp: 1115 len: 1119 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1115 bytes from map-output for attempt_local1968043658_0001_m_000233_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1115, inMemoryMapOutputs.size() -> 291, commitMemory -> 394273, usedMemory ->395388\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000028_0 decomp: 2177 len: 2181 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 2177 bytes from map-output for attempt_local1968043658_0001_m_000028_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2177, inMemoryMapOutputs.size() -> 292, commitMemory -> 395388, usedMemory ->397565\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000335_0 decomp: 602 len: 606 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 602 bytes from map-output for attempt_local1968043658_0001_m_000335_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 602, inMemoryMapOutputs.size() -> 293, commitMemory -> 397565, usedMemory ->398167\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000234_0 decomp: 1162 len: 1166 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1162 bytes from map-output for attempt_local1968043658_0001_m_000234_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1162, inMemoryMapOutputs.size() -> 294, commitMemory -> 398167, usedMemory ->399329\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000029_0 decomp: 2220 len: 2224 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 2220 bytes from map-output for attempt_local1968043658_0001_m_000029_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2220, inMemoryMapOutputs.size() -> 295, commitMemory -> 399329, usedMemory ->401549\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000336_0 decomp: 574 len: 578 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 574 bytes from map-output for attempt_local1968043658_0001_m_000336_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 574, inMemoryMapOutputs.size() -> 296, commitMemory -> 401549, usedMemory ->402123\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000131_0 decomp: 1613 len: 1617 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1613 bytes from map-output for attempt_local1968043658_0001_m_000131_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1613, inMemoryMapOutputs.size() -> 297, commitMemory -> 402123, usedMemory ->403736\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000225_0 decomp: 1163 len: 1167 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1163 bytes from map-output for attempt_local1968043658_0001_m_000225_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1163, inMemoryMapOutputs.size() -> 298, commitMemory -> 403736, usedMemory ->404899\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000020_0 decomp: 2272 len: 2276 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 2272 bytes from map-output for attempt_local1968043658_0001_m_000020_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2272, inMemoryMapOutputs.size() -> 299, commitMemory -> 404899, usedMemory ->407171\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000327_0 decomp: 678 len: 682 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 678 bytes from map-output for attempt_local1968043658_0001_m_000327_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 678, inMemoryMapOutputs.size() -> 300, commitMemory -> 407171, usedMemory ->407849\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000226_0 decomp: 1192 len: 1196 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1192 bytes from map-output for attempt_local1968043658_0001_m_000226_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1192, inMemoryMapOutputs.size() -> 301, commitMemory -> 407849, usedMemory ->409041\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000021_0 decomp: 2557 len: 2561 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 2557 bytes from map-output for attempt_local1968043658_0001_m_000021_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2557, inMemoryMapOutputs.size() -> 302, commitMemory -> 409041, usedMemory ->411598\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000328_0 decomp: 659 len: 663 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 659 bytes from map-output for attempt_local1968043658_0001_m_000328_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 659, inMemoryMapOutputs.size() -> 303, commitMemory -> 411598, usedMemory ->412257\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000123_0 decomp: 1436 len: 1440 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1436 bytes from map-output for attempt_local1968043658_0001_m_000123_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1436, inMemoryMapOutputs.size() -> 304, commitMemory -> 412257, usedMemory ->413693\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000326_0 decomp: 655 len: 659 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 655 bytes from map-output for attempt_local1968043658_0001_m_000326_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 655, inMemoryMapOutputs.size() -> 305, commitMemory -> 413693, usedMemory ->414348\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000121_0 decomp: 1423 len: 1427 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1423 bytes from map-output for attempt_local1968043658_0001_m_000121_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1423, inMemoryMapOutputs.size() -> 306, commitMemory -> 414348, usedMemory ->415771\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000223_0 decomp: 1188 len: 1192 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1188 bytes from map-output for attempt_local1968043658_0001_m_000223_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1188, inMemoryMapOutputs.size() -> 307, commitMemory -> 415771, usedMemory ->416959\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000122_0 decomp: 1409 len: 1413 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1409 bytes from map-output for attempt_local1968043658_0001_m_000122_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1409, inMemoryMapOutputs.size() -> 308, commitMemory -> 416959, usedMemory ->418368\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000224_0 decomp: 1189 len: 1193 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1189 bytes from map-output for attempt_local1968043658_0001_m_000224_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1189, inMemoryMapOutputs.size() -> 309, commitMemory -> 418368, usedMemory ->419557\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000019_0 decomp: 2639 len: 2643 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 2639 bytes from map-output for attempt_local1968043658_0001_m_000019_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2639, inMemoryMapOutputs.size() -> 310, commitMemory -> 419557, usedMemory ->422196\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000126_0 decomp: 1452 len: 1456 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1452 bytes from map-output for attempt_local1968043658_0001_m_000126_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1452, inMemoryMapOutputs.size() -> 311, commitMemory -> 422196, usedMemory ->423648\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000228_0 decomp: 1114 len: 1118 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1114 bytes from map-output for attempt_local1968043658_0001_m_000228_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1114, inMemoryMapOutputs.size() -> 312, commitMemory -> 423648, usedMemory ->424762\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000023_0 decomp: 2256 len: 2260 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 2256 bytes from map-output for attempt_local1968043658_0001_m_000023_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2256, inMemoryMapOutputs.size() -> 313, commitMemory -> 424762, usedMemory ->427018\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000229_0 decomp: 1048 len: 1052 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1048 bytes from map-output for attempt_local1968043658_0001_m_000229_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1048, inMemoryMapOutputs.size() -> 314, commitMemory -> 427018, usedMemory ->428066\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000024_0 decomp: 2416 len: 2420 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 2416 bytes from map-output for attempt_local1968043658_0001_m_000024_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2416, inMemoryMapOutputs.size() -> 315, commitMemory -> 428066, usedMemory ->430482\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000331_0 decomp: 653 len: 657 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 653 bytes from map-output for attempt_local1968043658_0001_m_000331_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 653, inMemoryMapOutputs.size() -> 316, commitMemory -> 430482, usedMemory ->431135\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000022_0 decomp: 2425 len: 2429 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 2425 bytes from map-output for attempt_local1968043658_0001_m_000022_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2425, inMemoryMapOutputs.size() -> 317, commitMemory -> 431135, usedMemory ->433560\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000329_0 decomp: 636 len: 640 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 636 bytes from map-output for attempt_local1968043658_0001_m_000329_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 636, inMemoryMapOutputs.size() -> 318, commitMemory -> 433560, usedMemory ->434196\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000124_0 decomp: 1464 len: 1468 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1464 bytes from map-output for attempt_local1968043658_0001_m_000124_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1464, inMemoryMapOutputs.size() -> 319, commitMemory -> 434196, usedMemory ->435660\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000330_0 decomp: 608 len: 612 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 608 bytes from map-output for attempt_local1968043658_0001_m_000330_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 608, inMemoryMapOutputs.size() -> 320, commitMemory -> 435660, usedMemory ->436268\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000125_0 decomp: 1585 len: 1589 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1585 bytes from map-output for attempt_local1968043658_0001_m_000125_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1585, inMemoryMapOutputs.size() -> 321, commitMemory -> 436268, usedMemory ->437853\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000227_0 decomp: 1092 len: 1096 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1092 bytes from map-output for attempt_local1968043658_0001_m_000227_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1092, inMemoryMapOutputs.size() -> 322, commitMemory -> 437853, usedMemory ->438945\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000014_0 decomp: 2765 len: 2769 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 2765 bytes from map-output for attempt_local1968043658_0001_m_000014_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2765, inMemoryMapOutputs.size() -> 323, commitMemory -> 438945, usedMemory ->441710\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000321_0 decomp: 659 len: 663 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 659 bytes from map-output for attempt_local1968043658_0001_m_000321_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 659, inMemoryMapOutputs.size() -> 324, commitMemory -> 441710, usedMemory ->442369\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000116_0 decomp: 1422 len: 1426 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1422 bytes from map-output for attempt_local1968043658_0001_m_000116_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1422, inMemoryMapOutputs.size() -> 325, commitMemory -> 442369, usedMemory ->443791\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000322_0 decomp: 685 len: 689 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 685 bytes from map-output for attempt_local1968043658_0001_m_000322_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 685, inMemoryMapOutputs.size() -> 326, commitMemory -> 443791, usedMemory ->444476\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000117_0 decomp: 1580 len: 1584 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1580 bytes from map-output for attempt_local1968043658_0001_m_000117_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1580, inMemoryMapOutputs.size() -> 327, commitMemory -> 444476, usedMemory ->446056\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000219_0 decomp: 1057 len: 1061 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1057 bytes from map-output for attempt_local1968043658_0001_m_000219_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1057, inMemoryMapOutputs.size() -> 328, commitMemory -> 446056, usedMemory ->447113\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000217_0 decomp: 1111 len: 1115 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1111 bytes from map-output for attempt_local1968043658_0001_m_000217_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1111, inMemoryMapOutputs.size() -> 329, commitMemory -> 447113, usedMemory ->448224\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000012_0 decomp: 2761 len: 2765 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 2761 bytes from map-output for attempt_local1968043658_0001_m_000012_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2761, inMemoryMapOutputs.size() -> 330, commitMemory -> 448224, usedMemory ->450985\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000319_0 decomp: 724 len: 728 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 724 bytes from map-output for attempt_local1968043658_0001_m_000319_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 724, inMemoryMapOutputs.size() -> 331, commitMemory -> 450985, usedMemory ->451709\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000218_0 decomp: 1111 len: 1115 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1111 bytes from map-output for attempt_local1968043658_0001_m_000218_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1111, inMemoryMapOutputs.size() -> 332, commitMemory -> 451709, usedMemory ->452820\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000013_0 decomp: 2653 len: 2657 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 2653 bytes from map-output for attempt_local1968043658_0001_m_000013_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2653, inMemoryMapOutputs.size() -> 333, commitMemory -> 452820, usedMemory ->455473\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000320_0 decomp: 714 len: 718 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 714 bytes from map-output for attempt_local1968043658_0001_m_000320_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 714, inMemoryMapOutputs.size() -> 334, commitMemory -> 455473, usedMemory ->456187\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000115_0 decomp: 1538 len: 1542 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1538 bytes from map-output for attempt_local1968043658_0001_m_000115_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1538, inMemoryMapOutputs.size() -> 335, commitMemory -> 456187, usedMemory ->457725\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000222_0 decomp: 1121 len: 1125 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1121 bytes from map-output for attempt_local1968043658_0001_m_000222_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1121, inMemoryMapOutputs.size() -> 336, commitMemory -> 457725, usedMemory ->458846\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000017_0 decomp: 2527 len: 2531 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 2527 bytes from map-output for attempt_local1968043658_0001_m_000017_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2527, inMemoryMapOutputs.size() -> 337, commitMemory -> 458846, usedMemory ->461373\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000324_0 decomp: 660 len: 664 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 660 bytes from map-output for attempt_local1968043658_0001_m_000324_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 660, inMemoryMapOutputs.size() -> 338, commitMemory -> 461373, usedMemory ->462033\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000119_0 decomp: 1420 len: 1424 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1420 bytes from map-output for attempt_local1968043658_0001_m_000119_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1420, inMemoryMapOutputs.size() -> 339, commitMemory -> 462033, usedMemory ->463453\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000018_0 decomp: 2539 len: 2543 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 2539 bytes from map-output for attempt_local1968043658_0001_m_000018_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2539, inMemoryMapOutputs.size() -> 340, commitMemory -> 463453, usedMemory ->465992\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000325_0 decomp: 697 len: 701 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 697 bytes from map-output for attempt_local1968043658_0001_m_000325_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 697, inMemoryMapOutputs.size() -> 341, commitMemory -> 465992, usedMemory ->466689\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000120_0 decomp: 1480 len: 1484 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1480 bytes from map-output for attempt_local1968043658_0001_m_000120_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1480, inMemoryMapOutputs.size() -> 342, commitMemory -> 466689, usedMemory ->468169\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000118_0 decomp: 1525 len: 1529 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1525 bytes from map-output for attempt_local1968043658_0001_m_000118_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1525, inMemoryMapOutputs.size() -> 343, commitMemory -> 468169, usedMemory ->469694\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000220_0 decomp: 1189 len: 1193 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1189 bytes from map-output for attempt_local1968043658_0001_m_000220_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1189, inMemoryMapOutputs.size() -> 344, commitMemory -> 469694, usedMemory ->470883\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000015_0 decomp: 2529 len: 2533 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 2529 bytes from map-output for attempt_local1968043658_0001_m_000015_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2529, inMemoryMapOutputs.size() -> 345, commitMemory -> 470883, usedMemory ->473412\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000221_0 decomp: 1076 len: 1080 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 1076 bytes from map-output for attempt_local1968043658_0001_m_000221_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1076, inMemoryMapOutputs.size() -> 346, commitMemory -> 473412, usedMemory ->474488\r\n",
      "25/08/31 12:04:09 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000016_0 decomp: 2466 len: 2470 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 2466 bytes from map-output for attempt_local1968043658_0001_m_000016_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2466, inMemoryMapOutputs.size() -> 347, commitMemory -> 474488, usedMemory ->476954\r\n",
      "25/08/31 12:04:09 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1968043658_0001_m_000323_0 decomp: 662 len: 666 to MEMORY\r\n",
      "25/08/31 12:04:09 INFO reduce.InMemoryMapOutput: Read 662 bytes from map-output for attempt_local1968043658_0001_m_000323_0\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 662, inMemoryMapOutputs.size() -> 348, commitMemory -> 476954, usedMemory ->477616\r\n",
      "25/08/31 12:04:09 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: 348 / 348 copied.\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: finalMerge called with 348 in-memory map-outputs and 0 on-disk map-outputs\r\n",
      "25/08/31 12:04:09 INFO mapred.Merger: Merging 348 sorted segments\r\n",
      "25/08/31 12:04:09 INFO mapred.Merger: Down to the last merge-pass, with 348 segments left of total size: 463889 bytes\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: Merged 348 segments, 477616 bytes to disk to satisfy reduce memory limit\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: Merging 1 files, 476926 bytes from disk\r\n",
      "25/08/31 12:04:09 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce\r\n",
      "25/08/31 12:04:09 INFO mapred.Merger: Merging 1 sorted segments\r\n",
      "25/08/31 12:04:09 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 476793 bytes\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: 348 / 348 copied.\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/reducer_title_occurrences.py]\r\n",
      "25/08/31 12:04:09 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\r\n",
      "25/08/31 12:04:09 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: Records R/W=3280/1\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: R/W/S=10000/7145/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/31 12:04:09 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Task:attempt_local1968043658_0001_r_000000_0 is done. And is in the process of committing\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: 348 / 348 copied.\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Task attempt_local1968043658_0001_r_000000_0 is allowed to commit now\r\n",
      "25/08/31 12:04:09 INFO output.FileOutputCommitter: Saved output of task 'attempt_local1968043658_0001_r_000000_0' to hdfs://localhost:54310/user/ubuntu/map_reduce/title_occurrences/_temporary/0/task_local1968043658_0001_r_000000\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Records R/W=3280/1 > reduce\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Task 'attempt_local1968043658_0001_r_000000_0' done.\r\n",
      "25/08/31 12:04:09 INFO mapred.Task: Final Counters for attempt_local1968043658_0001_r_000000_0: Counters: 29\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=2649662\r\n",
      "\t\tFILE: Number of bytes written=1655702\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1183870\r\n",
      "\t\tHDFS: Number of bytes written=453028\r\n",
      "\t\tHDFS: Number of read operations=703\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=3\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tCombine output records=0\r\n",
      "\t\tReduce input groups=10315\r\n",
      "\t\tReduce shuffle bytes=479008\r\n",
      "\t\tReduce input records=11127\r\n",
      "\t\tReduce output records=10315\r\n",
      "\t\tSpilled Records=11127\r\n",
      "\t\tShuffled Maps =348\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=348\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=3016753152\r\n",
      "\tShuffle Errors\r\n",
      "\t\tBAD_ID=0\r\n",
      "\t\tCONNECTION=0\r\n",
      "\t\tIO_ERROR=0\r\n",
      "\t\tWRONG_LENGTH=0\r\n",
      "\t\tWRONG_MAP=0\r\n",
      "\t\tWRONG_REDUCE=0\r\n",
      "\tFile Output Format Counters \r\n",
      "\t\tBytes Written=453028\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: Finishing task: attempt_local1968043658_0001_r_000000_0\r\n",
      "25/08/31 12:04:09 INFO mapred.LocalJobRunner: reduce task executor complete.\r\n",
      "25/08/31 12:04:10 INFO mapreduce.Job:  map 100% reduce 100%\r\n",
      "25/08/31 12:04:10 INFO mapreduce.Job: Job job_local1968043658_0001 completed successfully\r\n",
      "25/08/31 12:04:10 INFO mapreduce.Job: Counters: 35\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=327947038\r\n",
      "\t\tFILE: Number of bytes written=345275477\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=239823798\r\n",
      "\t\tHDFS: Number of bytes written=453028\r\n",
      "\t\tHDFS: Number of read operations=123547\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=351\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=11127\r\n",
      "\t\tMap output records=11127\r\n",
      "\t\tMap output bytes=454600\r\n",
      "\t\tMap output materialized bytes=479008\r\n",
      "\t\tInput split bytes=57072\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tCombine output records=0\r\n",
      "\t\tReduce input groups=10315\r\n",
      "\t\tReduce shuffle bytes=479008\r\n",
      "\t\tReduce input records=11127\r\n",
      "\t\tReduce output records=10315\r\n",
      "\t\tSpilled Records=22254\r\n",
      "\t\tShuffled Maps =348\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=348\r\n",
      "\t\tGC time elapsed (ms)=439\r\n",
      "\t\tTotal committed heap usage (bytes)=929415299072\r\n",
      "\tShuffle Errors\r\n",
      "\t\tBAD_ID=0\r\n",
      "\t\tCONNECTION=0\r\n",
      "\t\tIO_ERROR=0\r\n",
      "\t\tWRONG_LENGTH=0\r\n",
      "\t\tWRONG_MAP=0\r\n",
      "\t\tWRONG_REDUCE=0\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=1183870\r\n",
      "\tFile Output Format Counters \r\n",
      "\t\tBytes Written=453028\r\n",
      "25/08/31 12:04:10 INFO streaming.StreamJob: Output directory: /user/ubuntu/map_reduce/title_occurrences/\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Join\n",
    "\n",
    "This MapReduce job joins the preprocessed dataset with the title occurrences. As a result we'll have an additional column carrying that information."
   ],
   "id": "416a1a724a1776bb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-24T18:13:41.777038Z",
     "start_time": "2025-08-24T18:13:27.891163Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mapper = '/home/ubuntu/jupyter/MapReduce/mapper_join.py'\n",
    "reducer = '/home/ubuntu/jupyter/MapReduce/reducer_join.py'\n",
    "\n",
    "dataset1 = '/user/ubuntu/dataset_preprocessed/'\n",
    "dataset2 = '/user/ubuntu/map_reduce/title_occurrences/'\n",
    "\n",
    "out_dataset = '/user/ubuntu/map_reduce/joint_dataset/'\n",
    "\n",
    "streaming_jar = '/usr/local/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.10.0.jar'\n",
    "\n",
    "# Delete any old join MapReduce job output, if necessary\n",
    "!hadoop fs -rm -r $out_dataset\n",
    "\n",
    "# Execute the actual join MapReduce job\n",
    "!hadoop jar $streaming_jar -files $mapper,$reducer -mapper $mapper -reducer $reducer -input $dataset1 -input $dataset2 -output $out_dataset"
   ],
   "id": "1bd0ee83019783b9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: `/user/ubuntu/map_reduce/joint_dataset/': No such file or directory\r\n",
      "25/08/24 20:13:30 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id\r\n",
      "25/08/24 20:13:30 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=\r\n",
      "25/08/24 20:13:30 INFO jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\r\n",
      "25/08/24 20:13:30 INFO mapred.FileInputFormat: Total input files to process : 349\r\n",
      "25/08/24 20:13:30 INFO mapreduce.JobSubmitter: number of splits:349\r\n",
      "25/08/24 20:13:30 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1384700255_0001\r\n",
      "25/08/24 20:13:31 INFO mapred.LocalDistributedCacheManager: Creating symlink: /app/hadoop/tmp/mapred/local/1756059211023/mapper_join.py <- /home/ubuntu/mapper_join.py\r\n",
      "25/08/24 20:13:31 INFO mapred.LocalDistributedCacheManager: Localized file:/home/ubuntu/jupyter/MapReduce/mapper_join.py as file:/app/hadoop/tmp/mapred/local/1756059211023/mapper_join.py\r\n",
      "25/08/24 20:13:31 INFO mapred.LocalDistributedCacheManager: Creating symlink: /app/hadoop/tmp/mapred/local/1756059211024/reducer_join.py <- /home/ubuntu/reducer_join.py\r\n",
      "25/08/24 20:13:31 INFO mapred.LocalDistributedCacheManager: Localized file:/home/ubuntu/jupyter/MapReduce/reducer_join.py as file:/app/hadoop/tmp/mapred/local/1756059211024/reducer_join.py\r\n",
      "25/08/24 20:13:31 INFO mapreduce.Job: The url to track the job: http://localhost:8080/\r\n",
      "25/08/24 20:13:31 INFO mapred.LocalJobRunner: OutputCommitter set in config null\r\n",
      "25/08/24 20:13:31 INFO mapreduce.Job: Running job: job_local1384700255_0001\r\n",
      "25/08/24 20:13:31 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapred.FileOutputCommitter\r\n",
      "25/08/24 20:13:31 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:31 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:31 INFO mapred.LocalJobRunner: Waiting for map tasks\r\n",
      "25/08/24 20:13:31 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000000_0\r\n",
      "25/08/24 20:13:31 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:31 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:31 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/map_reduce/title_occurrences/part-00000:0+453028\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:31 INFO Configuration.deprecation: mapred.work.output.dir is deprecated. Instead, use mapreduce.task.output.dir\r\n",
      "25/08/24 20:13:31 INFO Configuration.deprecation: map.input.start is deprecated. Instead, use mapreduce.map.input.start\r\n",
      "25/08/24 20:13:31 INFO Configuration.deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap\r\n",
      "25/08/24 20:13:31 INFO Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id\r\n",
      "25/08/24 20:13:31 INFO Configuration.deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id\r\n",
      "25/08/24 20:13:31 INFO Configuration.deprecation: mapred.local.dir is deprecated. Instead, use mapreduce.cluster.local.dir\r\n",
      "25/08/24 20:13:31 INFO Configuration.deprecation: map.input.file is deprecated. Instead, use mapreduce.map.input.file\r\n",
      "25/08/24 20:13:31 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords\r\n",
      "25/08/24 20:13:31 INFO Configuration.deprecation: map.input.length is deprecated. Instead, use mapreduce.map.input.length\r\n",
      "25/08/24 20:13:31 INFO Configuration.deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id\r\n",
      "25/08/24 20:13:31 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name\r\n",
      "25/08/24 20:13:31 INFO Configuration.deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: Records R/W=3055/1\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: R/W/S=10000/7464/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:31 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: bufstart = 0; bufend = 762543; bufvoid = 104857600\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26173140(104692560); length = 41257/6553600\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:31 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000000_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:31 INFO mapred.LocalJobRunner: Records R/W=3055/1\r\n",
      "25/08/24 20:13:31 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000000_0' done.\r\n",
      "25/08/24 20:13:31 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000000_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=147287\r\n",
      "\t\tFILE: Number of bytes written=1473267\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=453028\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=8\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=10315\r\n",
      "\t\tMap output records=10315\r\n",
      "\t\tMap output bytes=762543\r\n",
      "\t\tMap output materialized bytes=783245\r\n",
      "\t\tInput split bytes=126\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=10315\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=232259584\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=453028\r\n",
      "25/08/24 20:13:31 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000000_0\r\n",
      "25/08/24 20:13:31 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000001_0\r\n",
      "25/08/24 20:13:31 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:31 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:31 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00000-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+14902\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:31 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: bufstart = 0; bufend = 15609; bufvoid = 104857600\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:31 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000001_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:31 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:31 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000001_0' done.\r\n",
      "25/08/24 20:13:31 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000001_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=151839\r\n",
      "\t\tFILE: Number of bytes written=1489046\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=467930\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=10\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=15609\r\n",
      "\t\tMap output materialized bytes=15747\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=337641472\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=14902\r\n",
      "25/08/24 20:13:31 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000001_0\r\n",
      "25/08/24 20:13:31 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000002_0\r\n",
      "25/08/24 20:13:31 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:31 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:31 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00001-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+10647\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:31 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: bufstart = 0; bufend = 11344; bufvoid = 104857600\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:31 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000002_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:31 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:31 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000002_0' done.\r\n",
      "25/08/24 20:13:31 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000002_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=156391\r\n",
      "\t\tFILE: Number of bytes written=1500549\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=478577\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=12\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=11344\r\n",
      "\t\tMap output materialized bytes=11471\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=56\r\n",
      "\t\tTotal committed heap usage (bytes)=535298048\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=10647\r\n",
      "25/08/24 20:13:31 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000002_0\r\n",
      "25/08/24 20:13:31 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000003_0\r\n",
      "25/08/24 20:13:31 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:31 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:31 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00002-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+8611\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:31 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: bufstart = 0; bufend = 9294; bufvoid = 104857600\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:31 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000003_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:31 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:31 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000003_0' done.\r\n",
      "25/08/24 20:13:31 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000003_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=160943\r\n",
      "\t\tFILE: Number of bytes written=1509989\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=487188\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=14\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=9294\r\n",
      "\t\tMap output materialized bytes=9408\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=535298048\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=8611\r\n",
      "25/08/24 20:13:31 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000003_0\r\n",
      "25/08/24 20:13:31 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000004_0\r\n",
      "25/08/24 20:13:31 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:31 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:31 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00003-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+7538\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:31 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: bufstart = 0; bufend = 8208; bufvoid = 104857600\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:31 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000004_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:31 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:31 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000004_0' done.\r\n",
      "25/08/24 20:13:31 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000004_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=165495\r\n",
      "\t\tFILE: Number of bytes written=1518329\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=494726\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=16\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=8208\r\n",
      "\t\tMap output materialized bytes=8308\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=535298048\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=7538\r\n",
      "25/08/24 20:13:31 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000004_0\r\n",
      "25/08/24 20:13:31 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000005_0\r\n",
      "25/08/24 20:13:31 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:31 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:31 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00004-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+6916\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:31 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: bufstart = 0; bufend = 7580; bufvoid = 104857600\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:31 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000005_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:31 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:31 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000005_0' done.\r\n",
      "25/08/24 20:13:31 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000005_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=170047\r\n",
      "\t\tFILE: Number of bytes written=1526035\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=501642\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=18\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=7580\r\n",
      "\t\tMap output materialized bytes=7674\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=2\r\n",
      "\t\tTotal committed heap usage (bytes)=535298048\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=6916\r\n",
      "25/08/24 20:13:31 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000005_0\r\n",
      "25/08/24 20:13:31 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000006_0\r\n",
      "25/08/24 20:13:31 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:31 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:31 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00005-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+6637\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:31 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: bufstart = 0; bufend = 7295; bufvoid = 104857600\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:31 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000006_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:31 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:31 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000006_0' done.\r\n",
      "25/08/24 20:13:31 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000006_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=174599\r\n",
      "\t\tFILE: Number of bytes written=1533451\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=508279\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=20\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=7295\r\n",
      "\t\tMap output materialized bytes=7384\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=535298048\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=6637\r\n",
      "25/08/24 20:13:31 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000006_0\r\n",
      "25/08/24 20:13:31 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000007_0\r\n",
      "25/08/24 20:13:31 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:31 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:31 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00006-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+6551\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:31 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: bufstart = 0; bufend = 7207; bufvoid = 104857600\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:31 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000007_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:31 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:31 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000007_0' done.\r\n",
      "25/08/24 20:13:31 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000007_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=179151\r\n",
      "\t\tFILE: Number of bytes written=1540776\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=514830\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=22\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=7207\r\n",
      "\t\tMap output materialized bytes=7293\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=640679936\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=6551\r\n",
      "25/08/24 20:13:31 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000007_0\r\n",
      "25/08/24 20:13:31 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000008_0\r\n",
      "25/08/24 20:13:31 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:31 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:31 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00007-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+6527\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:31 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: bufstart = 0; bufend = 7183; bufvoid = 104857600\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:31 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000008_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:31 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:31 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000008_0' done.\r\n",
      "25/08/24 20:13:31 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000008_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=183703\r\n",
      "\t\tFILE: Number of bytes written=1548077\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=521357\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=24\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=7183\r\n",
      "\t\tMap output materialized bytes=7269\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=2\r\n",
      "\t\tTotal committed heap usage (bytes)=801636352\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=6527\r\n",
      "25/08/24 20:13:31 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000008_0\r\n",
      "25/08/24 20:13:31 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000009_0\r\n",
      "25/08/24 20:13:31 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:31 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:31 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00008-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+6207\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:31 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: bufstart = 0; bufend = 6861; bufvoid = 104857600\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:31 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000009_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:31 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:31 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000009_0' done.\r\n",
      "25/08/24 20:13:31 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000009_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=188255\r\n",
      "\t\tFILE: Number of bytes written=1555054\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=527564\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=26\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=6861\r\n",
      "\t\tMap output materialized bytes=6945\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=801636352\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=6207\r\n",
      "25/08/24 20:13:31 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000009_0\r\n",
      "25/08/24 20:13:31 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000010_0\r\n",
      "25/08/24 20:13:31 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:31 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:31 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00009-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+6134\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:31 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: bufstart = 0; bufend = 6787; bufvoid = 104857600\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:31 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000010_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:31 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:31 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000010_0' done.\r\n",
      "25/08/24 20:13:31 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000010_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=192807\r\n",
      "\t\tFILE: Number of bytes written=1561956\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=533698\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=28\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=6787\r\n",
      "\t\tMap output materialized bytes=6870\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=907018240\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=6134\r\n",
      "25/08/24 20:13:31 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000010_0\r\n",
      "25/08/24 20:13:31 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000011_0\r\n",
      "25/08/24 20:13:31 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:31 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:31 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00010-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+5912\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:31 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: bufstart = 0; bufend = 6564; bufvoid = 104857600\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:31 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000011_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:31 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:31 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000011_0' done.\r\n",
      "25/08/24 20:13:31 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000011_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=197359\r\n",
      "\t\tFILE: Number of bytes written=1568634\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=539610\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=30\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=6564\r\n",
      "\t\tMap output materialized bytes=6646\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1012400128\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=5912\r\n",
      "25/08/24 20:13:31 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000011_0\r\n",
      "25/08/24 20:13:31 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000012_0\r\n",
      "25/08/24 20:13:31 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:31 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:31 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00011-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+5786\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:31 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: bufstart = 0; bufend = 6436; bufvoid = 104857600\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:31 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000012_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:31 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:31 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000012_0' done.\r\n",
      "25/08/24 20:13:31 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000012_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=201911\r\n",
      "\t\tFILE: Number of bytes written=1575183\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=545396\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=32\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=6436\r\n",
      "\t\tMap output materialized bytes=6517\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1117782016\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=5786\r\n",
      "25/08/24 20:13:31 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000012_0\r\n",
      "25/08/24 20:13:31 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000013_0\r\n",
      "25/08/24 20:13:31 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:31 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:31 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00013-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+5670\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:31 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: bufstart = 0; bufend = 6318; bufvoid = 104857600\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:31 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000013_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:31 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:31 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000013_0' done.\r\n",
      "25/08/24 20:13:31 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000013_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=206463\r\n",
      "\t\tFILE: Number of bytes written=1581612\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=551066\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=34\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=6318\r\n",
      "\t\tMap output materialized bytes=6397\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1223163904\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=5670\r\n",
      "25/08/24 20:13:31 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000013_0\r\n",
      "25/08/24 20:13:31 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000014_0\r\n",
      "25/08/24 20:13:31 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:31 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:31 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00012-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+5617\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:31 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: bufstart = 0; bufend = 6267; bufvoid = 104857600\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:31 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000014_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:31 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:31 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000014_0' done.\r\n",
      "25/08/24 20:13:31 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000014_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=211015\r\n",
      "\t\tFILE: Number of bytes written=1587991\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=556683\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=36\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=6267\r\n",
      "\t\tMap output materialized bytes=6347\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1328545792\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=5617\r\n",
      "25/08/24 20:13:31 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000014_0\r\n",
      "25/08/24 20:13:31 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000015_0\r\n",
      "25/08/24 20:13:31 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:31 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:31 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00014-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+5593\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:31 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: bufstart = 0; bufend = 6240; bufvoid = 104857600\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:31 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000015_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:31 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:31 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000015_0' done.\r\n",
      "25/08/24 20:13:31 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000015_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=215567\r\n",
      "\t\tFILE: Number of bytes written=1594341\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=562276\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=38\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=6240\r\n",
      "\t\tMap output materialized bytes=6318\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1433927680\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=5593\r\n",
      "25/08/24 20:13:31 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000015_0\r\n",
      "25/08/24 20:13:31 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000016_0\r\n",
      "25/08/24 20:13:31 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:31 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:31 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00015-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+5569\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:31 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:31 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: bufstart = 0; bufend = 6220; bufvoid = 104857600\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:31 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000016_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:31 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:31 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000016_0' done.\r\n",
      "25/08/24 20:13:31 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000016_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=220119\r\n",
      "\t\tFILE: Number of bytes written=1600674\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=567845\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=40\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=6220\r\n",
      "\t\tMap output materialized bytes=6301\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1539309568\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=5569\r\n",
      "25/08/24 20:13:31 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000016_0\r\n",
      "25/08/24 20:13:31 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000017_0\r\n",
      "25/08/24 20:13:31 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:31 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:31 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00017-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+5503\r\n",
      "25/08/24 20:13:31 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: bufstart = 0; bufend = 6154; bufvoid = 104857600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:32 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000017_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:32 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000017_0' done.\r\n",
      "25/08/24 20:13:32 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000017_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=224671\r\n",
      "\t\tFILE: Number of bytes written=1606941\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=573348\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=42\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=6154\r\n",
      "\t\tMap output materialized bytes=6235\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1644691456\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=5503\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000017_0\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000018_0\r\n",
      "25/08/24 20:13:32 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:32 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:32 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00025-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+5427\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: bufstart = 0; bufend = 6075; bufvoid = 104857600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:32 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000018_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:32 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000018_0' done.\r\n",
      "25/08/24 20:13:32 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000018_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=229223\r\n",
      "\t\tFILE: Number of bytes written=1613126\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=578775\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=44\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=6075\r\n",
      "\t\tMap output materialized bytes=6153\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=2\r\n",
      "\t\tTotal committed heap usage (bytes)=1750597632\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=5427\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000018_0\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000019_0\r\n",
      "25/08/24 20:13:32 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:32 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:32 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00018-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+5389\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: bufstart = 0; bufend = 6036; bufvoid = 104857600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:32 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000019_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:32 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000019_0' done.\r\n",
      "25/08/24 20:13:32 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000019_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=233775\r\n",
      "\t\tFILE: Number of bytes written=1619273\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=584164\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=46\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=6036\r\n",
      "\t\tMap output materialized bytes=6115\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1750597632\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=5389\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000019_0\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000020_0\r\n",
      "25/08/24 20:13:32 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:32 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:32 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00016-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+5387\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:32 INFO mapreduce.Job: Job job_local1384700255_0001 running in uber mode : false\r\n",
      "25/08/24 20:13:32 INFO mapreduce.Job:  map 100% reduce 0%\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: bufstart = 0; bufend = 6033; bufvoid = 104857600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:32 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000020_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:32 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000020_0' done.\r\n",
      "25/08/24 20:13:32 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000020_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=238327\r\n",
      "\t\tFILE: Number of bytes written=1625414\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=589551\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=48\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=6033\r\n",
      "\t\tMap output materialized bytes=6109\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1855979520\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=5387\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000020_0\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000021_0\r\n",
      "25/08/24 20:13:32 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:32 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:32 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00023-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+5323\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: bufstart = 0; bufend = 5972; bufvoid = 104857600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:32 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000021_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:32 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000021_0' done.\r\n",
      "25/08/24 20:13:32 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000021_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=242879\r\n",
      "\t\tFILE: Number of bytes written=1631498\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=594874\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=50\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=5972\r\n",
      "\t\tMap output materialized bytes=6052\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1961361408\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=5323\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000021_0\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000022_0\r\n",
      "25/08/24 20:13:32 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:32 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:32 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00019-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+5288\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: bufstart = 0; bufend = 5935; bufvoid = 104857600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:32 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000022_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:32 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000022_0' done.\r\n",
      "25/08/24 20:13:32 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000022_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=247431\r\n",
      "\t\tFILE: Number of bytes written=1637542\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=600162\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=52\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=5935\r\n",
      "\t\tMap output materialized bytes=6012\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2066743296\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=5288\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000022_0\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000023_0\r\n",
      "25/08/24 20:13:32 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:32 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:32 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00028-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+5225\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: bufstart = 0; bufend = 5873; bufvoid = 104857600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:32 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000023_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:32 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000023_0' done.\r\n",
      "25/08/24 20:13:32 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000023_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=251983\r\n",
      "\t\tFILE: Number of bytes written=1643525\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=605387\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=54\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=5873\r\n",
      "\t\tMap output materialized bytes=5951\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2172125184\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=5225\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000023_0\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000024_0\r\n",
      "25/08/24 20:13:32 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:32 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:32 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00020-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+5223\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: bufstart = 0; bufend = 5871; bufvoid = 104857600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:32 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000024_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:32 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000024_0' done.\r\n",
      "25/08/24 20:13:32 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000024_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=256535\r\n",
      "\t\tFILE: Number of bytes written=1649506\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=610610\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=56\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=5871\r\n",
      "\t\tMap output materialized bytes=5949\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2277507072\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=5223\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000024_0\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000025_0\r\n",
      "25/08/24 20:13:32 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:32 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:32 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00024-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+5200\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: bufstart = 0; bufend = 5846; bufvoid = 104857600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:32 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000025_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:32 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000025_0' done.\r\n",
      "25/08/24 20:13:32 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000025_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=261087\r\n",
      "\t\tFILE: Number of bytes written=1655460\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=615810\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=58\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=5846\r\n",
      "\t\tMap output materialized bytes=5922\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2382888960\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=5200\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000025_0\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000026_0\r\n",
      "25/08/24 20:13:32 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:32 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:32 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00021-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+5125\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: bufstart = 0; bufend = 5770; bufvoid = 104857600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:32 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000026_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:32 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000026_0' done.\r\n",
      "25/08/24 20:13:32 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000026_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=265639\r\n",
      "\t\tFILE: Number of bytes written=1661337\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=620935\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=60\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=5770\r\n",
      "\t\tMap output materialized bytes=5845\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2488270848\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=5125\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000026_0\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000027_0\r\n",
      "25/08/24 20:13:32 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:32 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:32 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00027-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+5085\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: bufstart = 0; bufend = 5730; bufvoid = 104857600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:32 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000027_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:32 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000027_0' done.\r\n",
      "25/08/24 20:13:32 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000027_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=270191\r\n",
      "\t\tFILE: Number of bytes written=1667176\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=626020\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=62\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=5730\r\n",
      "\t\tMap output materialized bytes=5807\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=3\r\n",
      "\t\tTotal committed heap usage (bytes)=2620391424\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=5085\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000027_0\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000028_0\r\n",
      "25/08/24 20:13:32 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:32 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:32 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00022-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4984\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: bufstart = 0; bufend = 5631; bufvoid = 104857600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:32 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000028_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:32 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000028_0' done.\r\n",
      "25/08/24 20:13:32 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000028_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=274743\r\n",
      "\t\tFILE: Number of bytes written=1672916\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=631004\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=64\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=5631\r\n",
      "\t\tMap output materialized bytes=5708\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2620391424\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4984\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000028_0\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000029_0\r\n",
      "25/08/24 20:13:32 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:32 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:32 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00030-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4981\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: bufstart = 0; bufend = 5627; bufvoid = 104857600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:32 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000029_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:32 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000029_0' done.\r\n",
      "25/08/24 20:13:32 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000029_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=279295\r\n",
      "\t\tFILE: Number of bytes written=1678651\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=635985\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=66\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=5627\r\n",
      "\t\tMap output materialized bytes=5703\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2725773312\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4981\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000029_0\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000030_0\r\n",
      "25/08/24 20:13:32 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:32 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:32 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00036-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4965\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: bufstart = 0; bufend = 5612; bufvoid = 104857600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:32 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000030_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:32 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000030_0' done.\r\n",
      "25/08/24 20:13:32 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000030_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=283847\r\n",
      "\t\tFILE: Number of bytes written=1684372\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=640950\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=68\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=5612\r\n",
      "\t\tMap output materialized bytes=5689\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2831155200\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4965\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000030_0\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000031_0\r\n",
      "25/08/24 20:13:32 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:32 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:32 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00032-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4907\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: bufstart = 0; bufend = 5552; bufvoid = 104857600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:32 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000031_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:32 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000031_0' done.\r\n",
      "25/08/24 20:13:32 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000031_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=288399\r\n",
      "\t\tFILE: Number of bytes written=1690033\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=645857\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=70\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=5552\r\n",
      "\t\tMap output materialized bytes=5629\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2936537088\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4907\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000031_0\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000032_0\r\n",
      "25/08/24 20:13:32 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:32 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:32 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00034-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4868\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: bufstart = 0; bufend = 5513; bufvoid = 104857600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:32 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000032_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:32 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000032_0' done.\r\n",
      "25/08/24 20:13:32 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000032_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=292951\r\n",
      "\t\tFILE: Number of bytes written=1695654\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=650725\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=72\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=5513\r\n",
      "\t\tMap output materialized bytes=5589\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=3041918976\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4868\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000032_0\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000033_0\r\n",
      "25/08/24 20:13:32 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:32 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:32 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00029-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4863\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: bufstart = 0; bufend = 5512; bufvoid = 104857600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:32 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000033_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:32 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000033_0' done.\r\n",
      "25/08/24 20:13:32 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000033_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=297503\r\n",
      "\t\tFILE: Number of bytes written=1701277\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=655588\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=74\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=5512\r\n",
      "\t\tMap output materialized bytes=5591\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=3147300864\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4863\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000033_0\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000034_0\r\n",
      "25/08/24 20:13:32 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:32 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:32 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00031-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4853\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: bufstart = 0; bufend = 5499; bufvoid = 104857600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:32 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000034_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:32 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000034_0' done.\r\n",
      "25/08/24 20:13:32 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000034_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=302055\r\n",
      "\t\tFILE: Number of bytes written=1706884\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=660441\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=76\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=5499\r\n",
      "\t\tMap output materialized bytes=5575\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=3252682752\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4853\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000034_0\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000035_0\r\n",
      "25/08/24 20:13:32 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:32 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:32 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00037-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4843\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: bufstart = 0; bufend = 5490; bufvoid = 104857600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:32 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000035_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:32 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000035_0' done.\r\n",
      "25/08/24 20:13:32 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000035_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=306607\r\n",
      "\t\tFILE: Number of bytes written=1712483\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=665284\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=78\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=5490\r\n",
      "\t\tMap output materialized bytes=5567\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=3358064640\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4843\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000035_0\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000036_0\r\n",
      "25/08/24 20:13:32 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:32 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:32 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00026-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4842\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: bufstart = 0; bufend = 5483; bufvoid = 104857600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:32 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000036_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:32 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000036_0' done.\r\n",
      "25/08/24 20:13:32 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000036_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=311159\r\n",
      "\t\tFILE: Number of bytes written=1718069\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=670126\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=80\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=5483\r\n",
      "\t\tMap output materialized bytes=5554\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=3463446528\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4842\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000036_0\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000037_0\r\n",
      "25/08/24 20:13:32 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:32 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:32 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00033-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4836\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: bufstart = 0; bufend = 5484; bufvoid = 104857600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:32 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000037_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:32 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000037_0' done.\r\n",
      "25/08/24 20:13:32 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000037_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=315711\r\n",
      "\t\tFILE: Number of bytes written=1723663\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=674962\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=82\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=5484\r\n",
      "\t\tMap output materialized bytes=5562\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=3568828416\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4836\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000037_0\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000038_0\r\n",
      "25/08/24 20:13:32 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:32 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:32 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00038-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4805\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: bufstart = 0; bufend = 5450; bufvoid = 104857600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:32 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000038_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:32 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000038_0' done.\r\n",
      "25/08/24 20:13:32 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000038_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=320263\r\n",
      "\t\tFILE: Number of bytes written=1729220\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=679767\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=84\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=5450\r\n",
      "\t\tMap output materialized bytes=5525\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=3674210304\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4805\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000038_0\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000039_0\r\n",
      "25/08/24 20:13:32 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:32 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:32 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00052-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4778\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: bufstart = 0; bufend = 5423; bufvoid = 104857600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:32 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000039_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:32 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000039_0' done.\r\n",
      "25/08/24 20:13:32 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000039_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=324815\r\n",
      "\t\tFILE: Number of bytes written=1734750\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=684545\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=86\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=5423\r\n",
      "\t\tMap output materialized bytes=5498\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=3779592192\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4778\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000039_0\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000040_0\r\n",
      "25/08/24 20:13:32 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:32 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:32 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00035-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4764\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: bufstart = 0; bufend = 5410; bufvoid = 104857600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:32 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000040_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:32 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000040_0' done.\r\n",
      "25/08/24 20:13:32 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000040_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=329367\r\n",
      "\t\tFILE: Number of bytes written=1740268\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=689309\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=88\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=5410\r\n",
      "\t\tMap output materialized bytes=5486\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=3884974080\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4764\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000040_0\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000041_0\r\n",
      "25/08/24 20:13:32 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:32 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:32 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00044-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4764\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: bufstart = 0; bufend = 5407; bufvoid = 104857600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:32 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000041_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:32 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000041_0' done.\r\n",
      "25/08/24 20:13:32 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000041_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=333919\r\n",
      "\t\tFILE: Number of bytes written=1745782\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=694073\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=90\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=5407\r\n",
      "\t\tMap output materialized bytes=5482\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=3990355968\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4764\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000041_0\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000042_0\r\n",
      "25/08/24 20:13:32 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:32 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:32 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00051-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4740\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: bufstart = 0; bufend = 5387; bufvoid = 104857600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:32 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000042_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:32 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000042_0' done.\r\n",
      "25/08/24 20:13:32 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000042_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=338471\r\n",
      "\t\tFILE: Number of bytes written=1751278\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=698813\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=92\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=5387\r\n",
      "\t\tMap output materialized bytes=5464\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=4095737856\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4740\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000042_0\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000043_0\r\n",
      "25/08/24 20:13:32 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:32 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:32 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00048-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4725\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: bufstart = 0; bufend = 5371; bufvoid = 104857600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:32 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000043_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:32 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000043_0' done.\r\n",
      "25/08/24 20:13:32 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000043_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=343023\r\n",
      "\t\tFILE: Number of bytes written=1756758\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=703538\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=94\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=5371\r\n",
      "\t\tMap output materialized bytes=5448\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=6\r\n",
      "\t\tTotal committed heap usage (bytes)=4204789760\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4725\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000043_0\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000044_0\r\n",
      "25/08/24 20:13:32 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:32 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:32 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00049-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4702\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:32 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: bufstart = 0; bufend = 5350; bufvoid = 104857600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:32 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000044_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:32 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000044_0' done.\r\n",
      "25/08/24 20:13:32 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000044_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=347575\r\n",
      "\t\tFILE: Number of bytes written=1762218\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=708240\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=96\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=5350\r\n",
      "\t\tMap output materialized bytes=5428\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=4204789760\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4702\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000044_0\r\n",
      "25/08/24 20:13:32 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000045_0\r\n",
      "25/08/24 20:13:32 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:32 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:32 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00039-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4693\r\n",
      "25/08/24 20:13:32 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: bufstart = 0; bufend = 5340; bufvoid = 104857600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:33 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000045_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:33 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000045_0' done.\r\n",
      "25/08/24 20:13:33 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000045_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=352127\r\n",
      "\t\tFILE: Number of bytes written=1767667\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=712933\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=98\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=5340\r\n",
      "\t\tMap output materialized bytes=5417\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=4310171648\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4693\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000045_0\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000046_0\r\n",
      "25/08/24 20:13:33 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:33 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:33 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00042-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4650\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: bufstart = 0; bufend = 5294; bufvoid = 104857600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:33 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000046_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:33 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000046_0' done.\r\n",
      "25/08/24 20:13:33 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000046_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=356679\r\n",
      "\t\tFILE: Number of bytes written=1773067\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=717583\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=100\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=5294\r\n",
      "\t\tMap output materialized bytes=5368\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=4415553536\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4650\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000046_0\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000047_0\r\n",
      "25/08/24 20:13:33 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:33 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:33 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00060-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4634\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: bufstart = 0; bufend = 5275; bufvoid = 104857600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:33 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000047_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:33 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000047_0' done.\r\n",
      "25/08/24 20:13:33 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000047_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=361231\r\n",
      "\t\tFILE: Number of bytes written=1778446\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=722217\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=102\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=5275\r\n",
      "\t\tMap output materialized bytes=5347\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=4520935424\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4634\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000047_0\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000048_0\r\n",
      "25/08/24 20:13:33 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:33 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:33 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00041-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4627\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: bufstart = 0; bufend = 5274; bufvoid = 104857600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:33 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000048_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:33 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000048_0' done.\r\n",
      "25/08/24 20:13:33 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000048_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=365783\r\n",
      "\t\tFILE: Number of bytes written=1783830\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=726844\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=104\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=5274\r\n",
      "\t\tMap output materialized bytes=5352\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=4626317312\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4627\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000048_0\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000049_0\r\n",
      "25/08/24 20:13:33 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:33 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:33 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00065-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4627\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: bufstart = 0; bufend = 5274; bufvoid = 104857600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:33 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000049_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:33 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000049_0' done.\r\n",
      "25/08/24 20:13:33 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000049_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=370335\r\n",
      "\t\tFILE: Number of bytes written=1789214\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=731471\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=106\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=5274\r\n",
      "\t\tMap output materialized bytes=5352\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=4731699200\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4627\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000049_0\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000050_0\r\n",
      "25/08/24 20:13:33 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:33 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:33 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00056-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4599\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: bufstart = 0; bufend = 5244; bufvoid = 104857600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:33 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000050_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:33 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000050_0' done.\r\n",
      "25/08/24 20:13:33 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000050_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=374887\r\n",
      "\t\tFILE: Number of bytes written=1794565\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=736070\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=108\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=5244\r\n",
      "\t\tMap output materialized bytes=5319\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=4837081088\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4599\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000050_0\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000051_0\r\n",
      "25/08/24 20:13:33 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:33 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:33 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00070-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4598\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: bufstart = 0; bufend = 5243; bufvoid = 104857600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:33 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000051_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:33 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000051_0' done.\r\n",
      "25/08/24 20:13:33 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000051_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=379439\r\n",
      "\t\tFILE: Number of bytes written=1799915\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=740668\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=110\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=5243\r\n",
      "\t\tMap output materialized bytes=5318\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=4942462976\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4598\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000051_0\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000052_0\r\n",
      "25/08/24 20:13:33 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:33 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:33 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00054-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4594\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: bufstart = 0; bufend = 5238; bufvoid = 104857600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:33 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000052_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:33 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000052_0' done.\r\n",
      "25/08/24 20:13:33 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000052_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=383991\r\n",
      "\t\tFILE: Number of bytes written=1805259\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=745262\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=112\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=5238\r\n",
      "\t\tMap output materialized bytes=5312\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=5047844864\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4594\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000052_0\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000053_0\r\n",
      "25/08/24 20:13:33 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:33 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:33 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00043-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4580\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: bufstart = 0; bufend = 5222; bufvoid = 104857600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:33 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000053_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:33 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000053_0' done.\r\n",
      "25/08/24 20:13:33 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000053_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=388543\r\n",
      "\t\tFILE: Number of bytes written=1810585\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=749842\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=114\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=5222\r\n",
      "\t\tMap output materialized bytes=5294\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=5153226752\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4580\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000053_0\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000054_0\r\n",
      "25/08/24 20:13:33 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:33 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:33 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00066-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4580\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: bufstart = 0; bufend = 5228; bufvoid = 104857600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:33 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000054_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:33 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000054_0' done.\r\n",
      "25/08/24 20:13:33 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000054_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=393095\r\n",
      "\t\tFILE: Number of bytes written=1815924\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=754422\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=116\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=5228\r\n",
      "\t\tMap output materialized bytes=5307\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=5258608640\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4580\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000054_0\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000055_0\r\n",
      "25/08/24 20:13:33 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:33 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:33 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00040-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4560\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: bufstart = 0; bufend = 5204; bufvoid = 104857600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:33 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000055_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:33 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000055_0' done.\r\n",
      "25/08/24 20:13:33 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000055_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=397647\r\n",
      "\t\tFILE: Number of bytes written=1821234\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=758982\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=118\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=5204\r\n",
      "\t\tMap output materialized bytes=5278\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=5363990528\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4560\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000055_0\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000056_0\r\n",
      "25/08/24 20:13:33 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:33 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:33 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00046-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4551\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: bufstart = 0; bufend = 5195; bufvoid = 104857600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:33 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000056_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:33 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000056_0' done.\r\n",
      "25/08/24 20:13:33 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000056_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=402199\r\n",
      "\t\tFILE: Number of bytes written=1826535\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=763533\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=120\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=5195\r\n",
      "\t\tMap output materialized bytes=5269\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=5469372416\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4551\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000056_0\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000057_0\r\n",
      "25/08/24 20:13:33 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:33 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:33 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00068-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4547\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: bufstart = 0; bufend = 5196; bufvoid = 104857600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:33 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000057_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:33 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000057_0' done.\r\n",
      "25/08/24 20:13:33 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000057_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=406751\r\n",
      "\t\tFILE: Number of bytes written=1831842\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=768080\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=122\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=5196\r\n",
      "\t\tMap output materialized bytes=5275\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=5574754304\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4547\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000057_0\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000058_0\r\n",
      "25/08/24 20:13:33 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:33 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:33 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00063-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4532\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: bufstart = 0; bufend = 5173; bufvoid = 104857600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:33 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000058_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:33 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000058_0' done.\r\n",
      "25/08/24 20:13:33 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000058_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=411303\r\n",
      "\t\tFILE: Number of bytes written=1837118\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=772612\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=124\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=5173\r\n",
      "\t\tMap output materialized bytes=5244\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=5680136192\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4532\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000058_0\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000059_0\r\n",
      "25/08/24 20:13:33 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:33 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:33 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00047-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4516\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: bufstart = 0; bufend = 5159; bufvoid = 104857600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:33 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000059_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:33 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000059_0' done.\r\n",
      "25/08/24 20:13:33 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000059_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=415855\r\n",
      "\t\tFILE: Number of bytes written=1842382\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=777128\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=126\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=5159\r\n",
      "\t\tMap output materialized bytes=5232\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=5\r\n",
      "\t\tTotal committed heap usage (bytes)=5802295296\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4516\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000059_0\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000060_0\r\n",
      "25/08/24 20:13:33 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:33 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:33 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00075-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4501\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: bufstart = 0; bufend = 5145; bufvoid = 104857600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:33 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000060_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:33 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000060_0' done.\r\n",
      "25/08/24 20:13:33 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000060_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=420407\r\n",
      "\t\tFILE: Number of bytes written=1847633\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=781629\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=128\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=5145\r\n",
      "\t\tMap output materialized bytes=5219\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=5802295296\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4501\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000060_0\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000061_0\r\n",
      "25/08/24 20:13:33 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:33 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:33 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00058-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4484\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: bufstart = 0; bufend = 5129; bufvoid = 104857600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:33 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000061_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:33 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000061_0' done.\r\n",
      "25/08/24 20:13:33 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000061_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=424959\r\n",
      "\t\tFILE: Number of bytes written=1852869\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=786113\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=130\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=5129\r\n",
      "\t\tMap output materialized bytes=5204\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=5907677184\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4484\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000061_0\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000062_0\r\n",
      "25/08/24 20:13:33 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:33 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:33 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00089-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4472\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: bufstart = 0; bufend = 5115; bufvoid = 104857600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:33 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000062_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:33 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000062_0' done.\r\n",
      "25/08/24 20:13:33 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000062_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=429511\r\n",
      "\t\tFILE: Number of bytes written=1858090\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=790585\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=132\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=5115\r\n",
      "\t\tMap output materialized bytes=5189\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=6013059072\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4472\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000062_0\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000063_0\r\n",
      "25/08/24 20:13:33 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:33 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:33 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00081-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4468\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: bufstart = 0; bufend = 5109; bufvoid = 104857600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:33 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000063_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:33 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000063_0' done.\r\n",
      "25/08/24 20:13:33 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000063_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=434063\r\n",
      "\t\tFILE: Number of bytes written=1863302\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=795053\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=134\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=5109\r\n",
      "\t\tMap output materialized bytes=5180\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=6118440960\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4468\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000063_0\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000064_0\r\n",
      "25/08/24 20:13:33 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:33 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:33 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00055-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4456\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: bufstart = 0; bufend = 5097; bufvoid = 104857600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:33 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000064_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:33 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000064_0' done.\r\n",
      "25/08/24 20:13:33 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000064_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=438615\r\n",
      "\t\tFILE: Number of bytes written=1868502\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=799509\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=136\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=5097\r\n",
      "\t\tMap output materialized bytes=5168\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=6223822848\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4456\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000064_0\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000065_0\r\n",
      "25/08/24 20:13:33 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:33 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:33 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00050-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4455\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: bufstart = 0; bufend = 5100; bufvoid = 104857600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:33 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000065_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:33 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000065_0' done.\r\n",
      "25/08/24 20:13:33 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000065_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=443167\r\n",
      "\t\tFILE: Number of bytes written=1873710\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=803964\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=138\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=5100\r\n",
      "\t\tMap output materialized bytes=5176\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=6329204736\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4455\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000065_0\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000066_0\r\n",
      "25/08/24 20:13:33 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:33 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:33 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00062-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4452\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: bufstart = 0; bufend = 5098; bufvoid = 104857600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:33 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000066_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:33 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000066_0' done.\r\n",
      "25/08/24 20:13:33 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000066_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=447719\r\n",
      "\t\tFILE: Number of bytes written=1878916\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=808416\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=140\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=5098\r\n",
      "\t\tMap output materialized bytes=5174\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=6434586624\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4452\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000066_0\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000067_0\r\n",
      "25/08/24 20:13:33 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:33 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:33 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00059-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4449\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: bufstart = 0; bufend = 5093; bufvoid = 104857600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:33 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000067_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:33 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000067_0' done.\r\n",
      "25/08/24 20:13:33 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000067_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=452271\r\n",
      "\t\tFILE: Number of bytes written=1884115\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=812865\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=142\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=5093\r\n",
      "\t\tMap output materialized bytes=5167\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=6539968512\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4449\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000067_0\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000068_0\r\n",
      "25/08/24 20:13:33 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:33 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:33 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00069-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4442\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: bufstart = 0; bufend = 5087; bufvoid = 104857600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:33 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000068_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:33 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000068_0' done.\r\n",
      "25/08/24 20:13:33 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000068_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=456823\r\n",
      "\t\tFILE: Number of bytes written=1889310\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=817307\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=144\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=5087\r\n",
      "\t\tMap output materialized bytes=5163\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=6645350400\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4442\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000068_0\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000069_0\r\n",
      "25/08/24 20:13:33 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:33 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:33 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00045-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4440\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: bufstart = 0; bufend = 5084; bufvoid = 104857600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:33 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000069_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:33 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000069_0' done.\r\n",
      "25/08/24 20:13:33 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000069_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=461375\r\n",
      "\t\tFILE: Number of bytes written=1894501\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=821747\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=146\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=5084\r\n",
      "\t\tMap output materialized bytes=5159\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=6750732288\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4440\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000069_0\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000070_0\r\n",
      "25/08/24 20:13:33 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:33 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:33 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00080-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4434\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: bufstart = 0; bufend = 5079; bufvoid = 104857600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:33 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000070_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:33 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000070_0' done.\r\n",
      "25/08/24 20:13:33 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000070_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=465927\r\n",
      "\t\tFILE: Number of bytes written=1899687\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=826181\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=148\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=5079\r\n",
      "\t\tMap output materialized bytes=5154\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=6856114176\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4434\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000070_0\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000071_0\r\n",
      "25/08/24 20:13:33 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:33 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:33 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00064-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4427\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: bufstart = 0; bufend = 5070; bufvoid = 104857600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:33 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000071_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:33 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000071_0' done.\r\n",
      "25/08/24 20:13:33 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000071_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=470479\r\n",
      "\t\tFILE: Number of bytes written=1904862\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=830608\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=150\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=5070\r\n",
      "\t\tMap output materialized bytes=5143\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=6961496064\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4427\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000071_0\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000072_0\r\n",
      "25/08/24 20:13:33 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:33 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:33 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00053-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4413\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:33 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: bufstart = 0; bufend = 5059; bufvoid = 104857600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:33 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000072_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:33 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000072_0' done.\r\n",
      "25/08/24 20:13:33 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000072_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=475031\r\n",
      "\t\tFILE: Number of bytes written=1910029\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=835021\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=152\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=5059\r\n",
      "\t\tMap output materialized bytes=5135\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=7066877952\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4413\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000072_0\r\n",
      "25/08/24 20:13:33 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000073_0\r\n",
      "25/08/24 20:13:33 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:33 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:33 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00086-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4406\r\n",
      "25/08/24 20:13:33 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: bufstart = 0; bufend = 5050; bufvoid = 104857600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:34 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000073_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:34 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000073_0' done.\r\n",
      "25/08/24 20:13:34 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000073_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=479583\r\n",
      "\t\tFILE: Number of bytes written=1915188\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=839427\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=154\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=5050\r\n",
      "\t\tMap output materialized bytes=5127\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=7172259840\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4406\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000073_0\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000074_0\r\n",
      "25/08/24 20:13:34 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:34 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:34 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00067-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4404\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: bufstart = 0; bufend = 5047; bufvoid = 104857600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:34 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000074_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:34 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000074_0' done.\r\n",
      "25/08/24 20:13:34 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000074_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=484135\r\n",
      "\t\tFILE: Number of bytes written=1920341\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=843831\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=156\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=5047\r\n",
      "\t\tMap output materialized bytes=5121\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=7277641728\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4404\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000074_0\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000075_0\r\n",
      "25/08/24 20:13:34 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:34 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:34 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00057-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4402\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: bufstart = 0; bufend = 5044; bufvoid = 104857600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:34 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000075_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:34 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000075_0' done.\r\n",
      "25/08/24 20:13:34 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000075_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=488687\r\n",
      "\t\tFILE: Number of bytes written=1925489\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=848233\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=158\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=5044\r\n",
      "\t\tMap output materialized bytes=5116\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=7383023616\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4402\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000075_0\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000076_0\r\n",
      "25/08/24 20:13:34 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:34 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:34 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00079-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4402\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: bufstart = 0; bufend = 5048; bufvoid = 104857600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:34 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000076_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:34 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000076_0' done.\r\n",
      "25/08/24 20:13:34 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000076_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=493239\r\n",
      "\t\tFILE: Number of bytes written=1930645\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=852635\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=160\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=5048\r\n",
      "\t\tMap output materialized bytes=5124\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=7488405504\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4402\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000076_0\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000077_0\r\n",
      "25/08/24 20:13:34 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:34 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:34 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00077-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4392\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: bufstart = 0; bufend = 5035; bufvoid = 104857600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:34 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000077_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:34 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000077_0' done.\r\n",
      "25/08/24 20:13:34 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000077_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=497791\r\n",
      "\t\tFILE: Number of bytes written=1935785\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=857027\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=162\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=5035\r\n",
      "\t\tMap output materialized bytes=5108\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=7593787392\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4392\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000077_0\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000078_0\r\n",
      "25/08/24 20:13:34 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:34 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:34 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00083-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4391\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: bufstart = 0; bufend = 5035; bufvoid = 104857600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:34 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000078_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:34 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000078_0' done.\r\n",
      "25/08/24 20:13:34 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000078_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=502343\r\n",
      "\t\tFILE: Number of bytes written=1940927\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=861418\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=164\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=5035\r\n",
      "\t\tMap output materialized bytes=5110\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=7699169280\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4391\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000078_0\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000079_0\r\n",
      "25/08/24 20:13:34 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:34 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:34 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00094-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4375\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: bufstart = 0; bufend = 5020; bufvoid = 104857600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:34 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000079_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:34 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000079_0' done.\r\n",
      "25/08/24 20:13:34 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000079_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=506895\r\n",
      "\t\tFILE: Number of bytes written=1946055\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=865793\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=166\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=5020\r\n",
      "\t\tMap output materialized bytes=5096\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=7804551168\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4375\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000079_0\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000080_0\r\n",
      "25/08/24 20:13:34 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:34 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:34 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00061-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4373\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: bufstart = 0; bufend = 5016; bufvoid = 104857600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:34 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000080_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:34 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000080_0' done.\r\n",
      "25/08/24 20:13:34 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000080_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=511447\r\n",
      "\t\tFILE: Number of bytes written=1951176\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=870166\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=168\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=5016\r\n",
      "\t\tMap output materialized bytes=5089\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=6\r\n",
      "\t\tTotal committed heap usage (bytes)=7912554496\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4373\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000080_0\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000081_0\r\n",
      "25/08/24 20:13:34 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:34 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:34 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00073-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4369\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: bufstart = 0; bufend = 5013; bufvoid = 104857600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:34 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000081_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:34 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000081_0' done.\r\n",
      "25/08/24 20:13:34 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000081_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=515999\r\n",
      "\t\tFILE: Number of bytes written=1956295\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=874535\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=170\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=5013\r\n",
      "\t\tMap output materialized bytes=5087\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=7912554496\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4369\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000081_0\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000082_0\r\n",
      "25/08/24 20:13:34 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:34 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:34 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00087-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4365\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: bufstart = 0; bufend = 5006; bufvoid = 104857600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:34 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000082_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:34 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000082_0' done.\r\n",
      "25/08/24 20:13:34 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000082_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=520551\r\n",
      "\t\tFILE: Number of bytes written=1961405\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=878900\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=172\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=5006\r\n",
      "\t\tMap output materialized bytes=5078\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=8017936384\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4365\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000082_0\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000083_0\r\n",
      "25/08/24 20:13:34 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:34 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:34 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00090-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4365\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: bufstart = 0; bufend = 5008; bufvoid = 104857600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:34 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000083_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:34 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000083_0' done.\r\n",
      "25/08/24 20:13:34 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000083_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=525103\r\n",
      "\t\tFILE: Number of bytes written=1966518\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=883265\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=174\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=5008\r\n",
      "\t\tMap output materialized bytes=5081\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=8123318272\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4365\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000083_0\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000084_0\r\n",
      "25/08/24 20:13:34 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:34 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:34 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00092-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4362\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: bufstart = 0; bufend = 5005; bufvoid = 104857600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:34 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000084_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:34 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000084_0' done.\r\n",
      "25/08/24 20:13:34 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000084_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=529655\r\n",
      "\t\tFILE: Number of bytes written=1971628\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=887627\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=176\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=5005\r\n",
      "\t\tMap output materialized bytes=5078\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=8228700160\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4362\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000084_0\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000085_0\r\n",
      "25/08/24 20:13:34 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:34 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:34 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00076-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4351\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: bufstart = 0; bufend = 4994; bufvoid = 104857600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:34 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000085_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:34 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000085_0' done.\r\n",
      "25/08/24 20:13:34 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000085_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=534207\r\n",
      "\t\tFILE: Number of bytes written=1976727\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=891978\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=178\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4994\r\n",
      "\t\tMap output materialized bytes=5067\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=8334082048\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4351\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000085_0\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000086_0\r\n",
      "25/08/24 20:13:34 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:34 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:34 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00074-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4346\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: bufstart = 0; bufend = 4989; bufvoid = 104857600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:34 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000086_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:34 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000086_0' done.\r\n",
      "25/08/24 20:13:34 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000086_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=538759\r\n",
      "\t\tFILE: Number of bytes written=1981821\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=896324\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=180\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4989\r\n",
      "\t\tMap output materialized bytes=5062\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=8439463936\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4346\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000086_0\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000087_0\r\n",
      "25/08/24 20:13:34 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:34 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:34 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00078-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4326\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: bufstart = 0; bufend = 4969; bufvoid = 104857600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:34 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000087_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:34 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000087_0' done.\r\n",
      "25/08/24 20:13:34 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000087_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=543311\r\n",
      "\t\tFILE: Number of bytes written=1986895\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=900650\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=182\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4969\r\n",
      "\t\tMap output materialized bytes=5042\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=8544845824\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4326\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000087_0\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000088_0\r\n",
      "25/08/24 20:13:34 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:34 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:34 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00088-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4324\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: bufstart = 0; bufend = 4966; bufvoid = 104857600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:34 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000088_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:34 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000088_0' done.\r\n",
      "25/08/24 20:13:34 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000088_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=547863\r\n",
      "\t\tFILE: Number of bytes written=1991965\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=904974\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=184\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4966\r\n",
      "\t\tMap output materialized bytes=5038\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=8650227712\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4324\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000088_0\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000089_0\r\n",
      "25/08/24 20:13:34 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:34 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:34 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00112-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4316\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: bufstart = 0; bufend = 4961; bufvoid = 104857600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:34 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000089_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:34 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000089_0' done.\r\n",
      "25/08/24 20:13:34 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000089_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=552415\r\n",
      "\t\tFILE: Number of bytes written=1997034\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=909290\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=186\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4961\r\n",
      "\t\tMap output materialized bytes=5037\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=8755609600\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4316\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000089_0\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000090_0\r\n",
      "25/08/24 20:13:34 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:34 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:34 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00085-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4312\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: bufstart = 0; bufend = 4957; bufvoid = 104857600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:34 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000090_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:34 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000090_0' done.\r\n",
      "25/08/24 20:13:34 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000090_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=556967\r\n",
      "\t\tFILE: Number of bytes written=2002098\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=913602\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=188\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4957\r\n",
      "\t\tMap output materialized bytes=5032\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=8860991488\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4312\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000090_0\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000091_0\r\n",
      "25/08/24 20:13:34 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:34 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:34 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00071-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4297\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: bufstart = 0; bufend = 4942; bufvoid = 104857600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:34 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000091_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:34 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000091_0' done.\r\n",
      "25/08/24 20:13:34 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000091_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=561519\r\n",
      "\t\tFILE: Number of bytes written=2007148\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=917899\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=190\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4942\r\n",
      "\t\tMap output materialized bytes=5018\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=8966373376\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4297\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000091_0\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000092_0\r\n",
      "25/08/24 20:13:34 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:34 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:34 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00084-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4297\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: bufstart = 0; bufend = 4942; bufvoid = 104857600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:34 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000092_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:34 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000092_0' done.\r\n",
      "25/08/24 20:13:34 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000092_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=566071\r\n",
      "\t\tFILE: Number of bytes written=2012197\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=922196\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=192\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4942\r\n",
      "\t\tMap output materialized bytes=5017\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=9071755264\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4297\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000092_0\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000093_0\r\n",
      "25/08/24 20:13:34 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:34 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:34 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00105-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4278\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: bufstart = 0; bufend = 4924; bufvoid = 104857600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:34 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000093_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:34 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000093_0' done.\r\n",
      "25/08/24 20:13:34 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000093_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=570623\r\n",
      "\t\tFILE: Number of bytes written=2017229\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=926474\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=194\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4924\r\n",
      "\t\tMap output materialized bytes=5000\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=9177137152\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4278\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000093_0\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000094_0\r\n",
      "25/08/24 20:13:34 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:34 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:34 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00102-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4268\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: bufstart = 0; bufend = 4911; bufvoid = 104857600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:34 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000094_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:34 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000094_0' done.\r\n",
      "25/08/24 20:13:34 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000094_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=575175\r\n",
      "\t\tFILE: Number of bytes written=2022245\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=930742\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=196\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4911\r\n",
      "\t\tMap output materialized bytes=4984\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=9282519040\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4268\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000094_0\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000095_0\r\n",
      "25/08/24 20:13:34 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:34 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:34 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00082-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4263\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: bufstart = 0; bufend = 4907; bufvoid = 104857600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:34 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000095_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:34 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000095_0' done.\r\n",
      "25/08/24 20:13:34 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000095_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=579727\r\n",
      "\t\tFILE: Number of bytes written=2027258\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=935005\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=198\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4907\r\n",
      "\t\tMap output materialized bytes=4981\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=9387900928\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4263\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000095_0\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000096_0\r\n",
      "25/08/24 20:13:34 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:34 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:34 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00091-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4262\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: bufstart = 0; bufend = 4904; bufvoid = 104857600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:34 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000096_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:34 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000096_0' done.\r\n",
      "25/08/24 20:13:34 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000096_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=584279\r\n",
      "\t\tFILE: Number of bytes written=2032269\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=939267\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=200\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4904\r\n",
      "\t\tMap output materialized bytes=4979\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=9493282816\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4262\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000096_0\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000097_0\r\n",
      "25/08/24 20:13:34 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:34 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:34 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00096-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4249\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: bufstart = 0; bufend = 4892; bufvoid = 104857600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:34 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000097_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:34 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000097_0' done.\r\n",
      "25/08/24 20:13:34 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000097_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=588831\r\n",
      "\t\tFILE: Number of bytes written=2037266\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=943516\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=202\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4892\r\n",
      "\t\tMap output materialized bytes=4965\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=9598664704\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4249\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000097_0\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000098_0\r\n",
      "25/08/24 20:13:34 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:34 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:34 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00101-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4239\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: bufstart = 0; bufend = 4882; bufvoid = 104857600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:34 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000098_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:34 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000098_0' done.\r\n",
      "25/08/24 20:13:34 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000098_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=593383\r\n",
      "\t\tFILE: Number of bytes written=2042253\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=947755\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=204\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4882\r\n",
      "\t\tMap output materialized bytes=4955\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=9704046592\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4239\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000098_0\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000099_0\r\n",
      "25/08/24 20:13:34 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:34 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:34 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00098-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4234\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: bufstart = 0; bufend = 4878; bufvoid = 104857600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:34 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000099_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:34 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000099_0' done.\r\n",
      "25/08/24 20:13:34 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000099_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=597935\r\n",
      "\t\tFILE: Number of bytes written=2047237\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=951989\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=206\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4878\r\n",
      "\t\tMap output materialized bytes=4952\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=9809428480\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4234\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000099_0\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000100_0\r\n",
      "25/08/24 20:13:34 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:34 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:34 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00095-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4225\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:34 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: bufstart = 0; bufend = 4870; bufvoid = 104857600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:34 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000100_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:34 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000100_0' done.\r\n",
      "25/08/24 20:13:34 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000100_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=602487\r\n",
      "\t\tFILE: Number of bytes written=2052214\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=956214\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=208\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4870\r\n",
      "\t\tMap output materialized bytes=4945\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=9914810368\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4225\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000100_0\r\n",
      "25/08/24 20:13:34 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000101_0\r\n",
      "25/08/24 20:13:34 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:34 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:34 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00099-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4222\r\n",
      "25/08/24 20:13:34 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: bufstart = 0; bufend = 4864; bufvoid = 104857600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000101_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000101_0' done.\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000101_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=607039\r\n",
      "\t\tFILE: Number of bytes written=2057182\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=960436\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=210\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4864\r\n",
      "\t\tMap output materialized bytes=4936\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=10020192256\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4222\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000101_0\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000102_0\r\n",
      "25/08/24 20:13:35 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:35 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:35 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00109-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4220\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: bufstart = 0; bufend = 4862; bufvoid = 104857600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000102_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000102_0' done.\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000102_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=611591\r\n",
      "\t\tFILE: Number of bytes written=2062148\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=964656\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=212\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4862\r\n",
      "\t\tMap output materialized bytes=4934\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=10125574144\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4220\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000102_0\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000103_0\r\n",
      "25/08/24 20:13:35 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:35 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:35 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00111-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4219\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: bufstart = 0; bufend = 4861; bufvoid = 104857600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000103_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000103_0' done.\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000103_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=616143\r\n",
      "\t\tFILE: Number of bytes written=2067114\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=968875\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=214\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4861\r\n",
      "\t\tMap output materialized bytes=4934\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=6\r\n",
      "\t\tTotal committed heap usage (bytes)=10248781824\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4219\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000103_0\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000104_0\r\n",
      "25/08/24 20:13:35 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:35 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:35 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00107-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4215\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: bufstart = 0; bufend = 4858; bufvoid = 104857600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000104_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000104_0' done.\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000104_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=620695\r\n",
      "\t\tFILE: Number of bytes written=2072078\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=973090\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=216\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4858\r\n",
      "\t\tMap output materialized bytes=4932\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=10248781824\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4215\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000104_0\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000105_0\r\n",
      "25/08/24 20:13:35 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:35 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:35 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00093-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4212\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: bufstart = 0; bufend = 4856; bufvoid = 104857600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000105_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000105_0' done.\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000105_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=625247\r\n",
      "\t\tFILE: Number of bytes written=2077041\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=977302\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=218\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4856\r\n",
      "\t\tMap output materialized bytes=4931\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=10248781824\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4212\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000105_0\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000106_0\r\n",
      "25/08/24 20:13:35 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:35 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:35 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00116-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4164\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: bufstart = 0; bufend = 4807; bufvoid = 104857600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000106_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000106_0' done.\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000106_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=629799\r\n",
      "\t\tFILE: Number of bytes written=2081953\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=981466\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=220\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4807\r\n",
      "\t\tMap output materialized bytes=4880\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=7\r\n",
      "\t\tTotal committed heap usage (bytes)=10250878976\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4164\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000106_0\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000107_0\r\n",
      "25/08/24 20:13:35 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:35 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:35 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00104-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4149\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: bufstart = 0; bufend = 4791; bufvoid = 104857600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000107_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000107_0' done.\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000107_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=634351\r\n",
      "\t\tFILE: Number of bytes written=2086848\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=985615\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=222\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4791\r\n",
      "\t\tMap output materialized bytes=4863\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=10250878976\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4149\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000107_0\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000108_0\r\n",
      "25/08/24 20:13:35 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:35 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:35 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00119-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4129\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: bufstart = 0; bufend = 4771; bufvoid = 104857600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000108_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000108_0' done.\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000108_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=638903\r\n",
      "\t\tFILE: Number of bytes written=2091723\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=989744\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=224\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4771\r\n",
      "\t\tMap output materialized bytes=4843\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=7\r\n",
      "\t\tTotal committed heap usage (bytes)=10313793536\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4129\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000108_0\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000109_0\r\n",
      "25/08/24 20:13:35 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:35 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:35 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00114-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4123\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: bufstart = 0; bufend = 4765; bufvoid = 104857600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000109_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000109_0' done.\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000109_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=643455\r\n",
      "\t\tFILE: Number of bytes written=2096592\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=993867\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=226\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4765\r\n",
      "\t\tMap output materialized bytes=4837\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=10313793536\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4123\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000109_0\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000110_0\r\n",
      "25/08/24 20:13:35 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:35 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:35 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00128-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4120\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: bufstart = 0; bufend = 4763; bufvoid = 104857600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000110_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000110_0' done.\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000110_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=648007\r\n",
      "\t\tFILE: Number of bytes written=2101461\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=997987\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=228\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4763\r\n",
      "\t\tMap output materialized bytes=4837\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=7\r\n",
      "\t\tTotal committed heap usage (bytes)=10312220672\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4120\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000110_0\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000111_0\r\n",
      "25/08/24 20:13:35 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:35 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:35 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00100-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4118\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: bufstart = 0; bufend = 4760; bufvoid = 104857600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000111_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000111_0' done.\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000111_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=652559\r\n",
      "\t\tFILE: Number of bytes written=2106325\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1002105\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=230\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4760\r\n",
      "\t\tMap output materialized bytes=4832\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=10312220672\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4118\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000111_0\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000112_0\r\n",
      "25/08/24 20:13:35 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:35 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:35 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00124-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4103\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: bufstart = 0; bufend = 4745; bufvoid = 104857600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000112_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000112_0' done.\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000112_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=657111\r\n",
      "\t\tFILE: Number of bytes written=2111174\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1006208\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=232\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4745\r\n",
      "\t\tMap output materialized bytes=4817\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=7\r\n",
      "\t\tTotal committed heap usage (bytes)=10430709760\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4103\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000112_0\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000113_0\r\n",
      "25/08/24 20:13:35 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:35 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:35 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00120-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4087\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: bufstart = 0; bufend = 4729; bufvoid = 104857600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000113_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000113_0' done.\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000113_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=661663\r\n",
      "\t\tFILE: Number of bytes written=2116007\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1010295\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=234\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4729\r\n",
      "\t\tMap output materialized bytes=4801\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=10430709760\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4087\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000113_0\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000114_0\r\n",
      "25/08/24 20:13:35 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:35 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:35 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00106-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4083\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: bufstart = 0; bufend = 4726; bufvoid = 104857600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000114_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000114_0' done.\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000114_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=666215\r\n",
      "\t\tFILE: Number of bytes written=2120838\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1014378\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=236\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4726\r\n",
      "\t\tMap output materialized bytes=4799\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=10430709760\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4083\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000114_0\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000115_0\r\n",
      "25/08/24 20:13:35 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:35 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:35 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00108-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4074\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: bufstart = 0; bufend = 4720; bufvoid = 104857600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000115_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000115_0' done.\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000115_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=670767\r\n",
      "\t\tFILE: Number of bytes written=2125667\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1018452\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=238\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4720\r\n",
      "\t\tMap output materialized bytes=4797\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=7\r\n",
      "\t\tTotal committed heap usage (bytes)=10429136896\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4074\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000115_0\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000116_0\r\n",
      "25/08/24 20:13:35 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:35 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:35 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00072-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4071\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: bufstart = 0; bufend = 4715; bufvoid = 104857600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000116_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000116_0' done.\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000116_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=675319\r\n",
      "\t\tFILE: Number of bytes written=2130489\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1022523\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=240\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4715\r\n",
      "\t\tMap output materialized bytes=4790\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=10429136896\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4071\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000116_0\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000117_0\r\n",
      "25/08/24 20:13:35 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:35 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:35 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00123-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4065\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: bufstart = 0; bufend = 4710; bufvoid = 104857600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000117_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000117_0' done.\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000117_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=679871\r\n",
      "\t\tFILE: Number of bytes written=2135307\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1026588\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=242\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4710\r\n",
      "\t\tMap output materialized bytes=4786\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=10429136896\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4065\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000117_0\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000118_0\r\n",
      "25/08/24 20:13:35 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:35 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:35 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00097-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4062\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: bufstart = 0; bufend = 4706; bufvoid = 104857600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000118_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000118_0' done.\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000118_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=684423\r\n",
      "\t\tFILE: Number of bytes written=2140119\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1030650\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=244\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4706\r\n",
      "\t\tMap output materialized bytes=4780\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=7\r\n",
      "\t\tTotal committed heap usage (bytes)=10541334528\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4062\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000118_0\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000119_0\r\n",
      "25/08/24 20:13:35 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:35 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:35 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00115-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4062\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: bufstart = 0; bufend = 4705; bufvoid = 104857600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000119_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000119_0' done.\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000119_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=688975\r\n",
      "\t\tFILE: Number of bytes written=2144930\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1034712\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=246\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4705\r\n",
      "\t\tMap output materialized bytes=4779\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=10541334528\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4062\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000119_0\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000120_0\r\n",
      "25/08/24 20:13:35 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:35 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:35 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00129-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4042\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: bufstart = 0; bufend = 4684; bufvoid = 104857600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000120_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000120_0' done.\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000120_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=693527\r\n",
      "\t\tFILE: Number of bytes written=2149718\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1038754\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=248\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4684\r\n",
      "\t\tMap output materialized bytes=4756\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=10541334528\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4042\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000120_0\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000121_0\r\n",
      "25/08/24 20:13:35 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:35 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:35 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00130-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4041\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: bufstart = 0; bufend = 4685; bufvoid = 104857600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000121_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000121_0' done.\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000121_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=698079\r\n",
      "\t\tFILE: Number of bytes written=2154510\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1042795\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=250\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4685\r\n",
      "\t\tMap output materialized bytes=4760\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=10541334528\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4041\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000121_0\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000122_0\r\n",
      "25/08/24 20:13:35 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:35 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:35 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00127-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4028\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: bufstart = 0; bufend = 4670; bufvoid = 104857600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000122_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000122_0' done.\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000122_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=702631\r\n",
      "\t\tFILE: Number of bytes written=2159284\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1046823\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=252\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4670\r\n",
      "\t\tMap output materialized bytes=4742\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=6\r\n",
      "\t\tTotal committed heap usage (bytes)=10542383104\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4028\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000122_0\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000123_0\r\n",
      "25/08/24 20:13:35 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:35 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:35 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00126-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4022\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: bufstart = 0; bufend = 4662; bufvoid = 104857600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000123_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000123_0' done.\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000123_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=707183\r\n",
      "\t\tFILE: Number of bytes written=2164048\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1050845\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=254\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4662\r\n",
      "\t\tMap output materialized bytes=4732\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=10542383104\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4022\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000123_0\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000124_0\r\n",
      "25/08/24 20:13:35 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:35 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:35 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00121-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4014\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: bufstart = 0; bufend = 4656; bufvoid = 104857600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000124_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000124_0' done.\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000124_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=711735\r\n",
      "\t\tFILE: Number of bytes written=2168808\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1054859\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=256\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4656\r\n",
      "\t\tMap output materialized bytes=4728\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=10542383104\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4014\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000124_0\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000125_0\r\n",
      "25/08/24 20:13:35 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:35 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:35 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00113-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4011\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: bufstart = 0; bufend = 4654; bufvoid = 104857600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000125_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000125_0' done.\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000125_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=716287\r\n",
      "\t\tFILE: Number of bytes written=2173567\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1058870\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=258\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4654\r\n",
      "\t\tMap output materialized bytes=4727\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=10542383104\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4011\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000125_0\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000126_0\r\n",
      "25/08/24 20:13:35 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:35 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:35 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00103-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4001\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: bufstart = 0; bufend = 4641; bufvoid = 104857600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000126_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000126_0' done.\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000126_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=720839\r\n",
      "\t\tFILE: Number of bytes written=2178310\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1062871\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=260\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4641\r\n",
      "\t\tMap output materialized bytes=4711\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=6\r\n",
      "\t\tTotal committed heap usage (bytes)=10677125120\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4001\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000126_0\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000127_0\r\n",
      "25/08/24 20:13:35 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:35 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:35 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00131-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+4001\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: bufstart = 0; bufend = 4645; bufvoid = 104857600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000127_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000127_0' done.\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000127_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=725391\r\n",
      "\t\tFILE: Number of bytes written=2183061\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1066872\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=262\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4645\r\n",
      "\t\tMap output materialized bytes=4719\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=10677125120\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=4001\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000127_0\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000128_0\r\n",
      "25/08/24 20:13:35 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:35 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:35 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00110-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3996\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: bufstart = 0; bufend = 4640; bufvoid = 104857600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000128_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000128_0' done.\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000128_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=729943\r\n",
      "\t\tFILE: Number of bytes written=2187808\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1070868\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=264\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4640\r\n",
      "\t\tMap output materialized bytes=4715\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=10677125120\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3996\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000128_0\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000129_0\r\n",
      "25/08/24 20:13:35 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:35 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:35 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00147-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3989\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: bufstart = 0; bufend = 4631; bufvoid = 104857600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000129_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000129_0' done.\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000129_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=734495\r\n",
      "\t\tFILE: Number of bytes written=2192544\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1074857\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=266\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4631\r\n",
      "\t\tMap output materialized bytes=4704\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=10677125120\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3989\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000129_0\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000130_0\r\n",
      "25/08/24 20:13:35 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:35 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:35 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00137-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3988\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: bufstart = 0; bufend = 4629; bufvoid = 104857600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000130_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000130_0' done.\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000130_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=739047\r\n",
      "\t\tFILE: Number of bytes written=2197276\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1078845\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=268\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4629\r\n",
      "\t\tMap output materialized bytes=4700\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=10677125120\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3988\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000130_0\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000131_0\r\n",
      "25/08/24 20:13:35 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:35 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:35 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00139-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3988\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: bufstart = 0; bufend = 4630; bufvoid = 104857600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000131_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000131_0' done.\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000131_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=743599\r\n",
      "\t\tFILE: Number of bytes written=2202010\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1082833\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=270\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4630\r\n",
      "\t\tMap output materialized bytes=4702\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=6\r\n",
      "\t\tTotal committed heap usage (bytes)=10681319424\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3988\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000131_0\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000132_0\r\n",
      "25/08/24 20:13:35 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:35 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:35 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00146-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3968\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: bufstart = 0; bufend = 4608; bufvoid = 104857600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000132_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000132_0' done.\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000132_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=748151\r\n",
      "\t\tFILE: Number of bytes written=2206720\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1086801\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=272\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4608\r\n",
      "\t\tMap output materialized bytes=4678\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=10681319424\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3968\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000132_0\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000133_0\r\n",
      "25/08/24 20:13:35 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:35 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:35 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00142-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3967\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: bufstart = 0; bufend = 4611; bufvoid = 104857600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000133_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000133_0' done.\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000133_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=752703\r\n",
      "\t\tFILE: Number of bytes written=2211438\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1090768\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=274\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4611\r\n",
      "\t\tMap output materialized bytes=4686\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=10681319424\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3967\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000133_0\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000134_0\r\n",
      "25/08/24 20:13:35 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:35 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:35 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00133-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3961\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: bufstart = 0; bufend = 4607; bufvoid = 104857600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000134_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000134_0' done.\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000134_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=757255\r\n",
      "\t\tFILE: Number of bytes written=2216153\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1094729\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=276\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4607\r\n",
      "\t\tMap output materialized bytes=4683\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=10681319424\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3961\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000134_0\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000135_0\r\n",
      "25/08/24 20:13:35 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:35 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:35 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00140-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3959\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: bufstart = 0; bufend = 4603; bufvoid = 104857600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000135_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000135_0' done.\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000135_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=761807\r\n",
      "\t\tFILE: Number of bytes written=2220862\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1098688\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=278\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4603\r\n",
      "\t\tMap output materialized bytes=4677\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=10681319424\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3959\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000135_0\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000136_0\r\n",
      "25/08/24 20:13:35 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:35 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:35 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00143-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3958\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: bufstart = 0; bufend = 4599; bufvoid = 104857600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000136_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000136_0' done.\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000136_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=766359\r\n",
      "\t\tFILE: Number of bytes written=2225564\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1102646\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=280\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4599\r\n",
      "\t\tMap output materialized bytes=4670\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=7\r\n",
      "\t\tTotal committed heap usage (bytes)=10846470144\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3958\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000136_0\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000137_0\r\n",
      "25/08/24 20:13:35 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:35 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:35 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00118-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3950\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: bufstart = 0; bufend = 4593; bufvoid = 104857600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000137_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000137_0' done.\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000137_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=770911\r\n",
      "\t\tFILE: Number of bytes written=2230262\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1106596\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=282\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4593\r\n",
      "\t\tMap output materialized bytes=4666\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=10846470144\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3950\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000137_0\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000138_0\r\n",
      "25/08/24 20:13:35 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:35 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:35 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00122-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3948\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: bufstart = 0; bufend = 4590; bufvoid = 104857600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000138_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000138_0' done.\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000138_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=775463\r\n",
      "\t\tFILE: Number of bytes written=2234956\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1110544\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=284\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4590\r\n",
      "\t\tMap output materialized bytes=4662\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=10846470144\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3948\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000138_0\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000139_0\r\n",
      "25/08/24 20:13:35 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:35 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:35 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00144-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3947\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: bufstart = 0; bufend = 4588; bufvoid = 104857600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000139_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000139_0' done.\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000139_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=780015\r\n",
      "\t\tFILE: Number of bytes written=2239648\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1114491\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=286\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4588\r\n",
      "\t\tMap output materialized bytes=4660\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=10846470144\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3947\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000139_0\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000140_0\r\n",
      "25/08/24 20:13:35 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:35 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:35 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00141-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3946\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: bufstart = 0; bufend = 4588; bufvoid = 104857600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000140_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000140_0' done.\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000140_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=784567\r\n",
      "\t\tFILE: Number of bytes written=2244340\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1118437\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=288\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4588\r\n",
      "\t\tMap output materialized bytes=4660\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=10846470144\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3946\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000140_0\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000141_0\r\n",
      "25/08/24 20:13:35 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:35 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:35 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00150-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3937\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: bufstart = 0; bufend = 4578; bufvoid = 104857600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000141_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000141_0' done.\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000141_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=789119\r\n",
      "\t\tFILE: Number of bytes written=2249021\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1122374\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=290\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4578\r\n",
      "\t\tMap output materialized bytes=4649\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=10846470144\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3937\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000141_0\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000142_0\r\n",
      "25/08/24 20:13:35 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:35 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:35 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00153-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3933\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:35 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: bufstart = 0; bufend = 4573; bufvoid = 104857600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000142_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000142_0' done.\r\n",
      "25/08/24 20:13:35 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000142_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=793671\r\n",
      "\t\tFILE: Number of bytes written=2253696\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1126307\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=292\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4573\r\n",
      "\t\tMap output materialized bytes=4643\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=10846470144\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3933\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000142_0\r\n",
      "25/08/24 20:13:35 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000143_0\r\n",
      "25/08/24 20:13:35 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:35 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:35 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00145-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3932\r\n",
      "25/08/24 20:13:35 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: bufstart = 0; bufend = 4572; bufvoid = 104857600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000143_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000143_0' done.\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000143_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=798223\r\n",
      "\t\tFILE: Number of bytes written=2258371\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1130239\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=294\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4572\r\n",
      "\t\tMap output materialized bytes=4643\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=6\r\n",
      "\t\tTotal committed heap usage (bytes)=10850140160\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3932\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000143_0\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000144_0\r\n",
      "25/08/24 20:13:36 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:36 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:36 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00148-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3912\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: bufstart = 0; bufend = 4554; bufvoid = 104857600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000144_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000144_0' done.\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000144_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=802775\r\n",
      "\t\tFILE: Number of bytes written=2263029\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1134151\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=296\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4554\r\n",
      "\t\tMap output materialized bytes=4626\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=10850140160\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3912\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000144_0\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000145_0\r\n",
      "25/08/24 20:13:36 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:36 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:36 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00155-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3910\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: bufstart = 0; bufend = 4553; bufvoid = 104857600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000145_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000145_0' done.\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000145_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=807327\r\n",
      "\t\tFILE: Number of bytes written=2267687\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1138061\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=298\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4553\r\n",
      "\t\tMap output materialized bytes=4626\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=10850140160\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3910\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000145_0\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000146_0\r\n",
      "25/08/24 20:13:36 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:36 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:36 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00156-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3902\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: bufstart = 0; bufend = 4544; bufvoid = 104857600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000146_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000146_0' done.\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000146_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=811879\r\n",
      "\t\tFILE: Number of bytes written=2272335\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1141963\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=300\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4544\r\n",
      "\t\tMap output materialized bytes=4616\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=10850140160\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3902\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000146_0\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000147_0\r\n",
      "25/08/24 20:13:36 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:36 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:36 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00152-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3898\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: bufstart = 0; bufend = 4539; bufvoid = 104857600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000147_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000147_0' done.\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000147_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=816431\r\n",
      "\t\tFILE: Number of bytes written=2276977\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1145861\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=302\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4539\r\n",
      "\t\tMap output materialized bytes=4610\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=10850140160\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3898\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000147_0\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000148_0\r\n",
      "25/08/24 20:13:36 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:36 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:36 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00138-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3897\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: bufstart = 0; bufend = 4538; bufvoid = 104857600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000148_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:36 INFO mapreduce.Job:  map 42% reduce 0%\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000148_0' done.\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000148_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=820983\r\n",
      "\t\tFILE: Number of bytes written=2281619\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1149758\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=304\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4538\r\n",
      "\t\tMap output materialized bytes=4610\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=10850140160\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3897\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000148_0\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000149_0\r\n",
      "25/08/24 20:13:36 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:36 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:36 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00160-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3883\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: bufstart = 0; bufend = 4524; bufvoid = 104857600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000149_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000149_0' done.\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000149_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=825535\r\n",
      "\t\tFILE: Number of bytes written=2286247\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1153641\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=306\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4524\r\n",
      "\t\tMap output materialized bytes=4596\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=406\r\n",
      "\t\tTotal committed heap usage (bytes)=1557659648\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3883\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000149_0\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000150_0\r\n",
      "25/08/24 20:13:36 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:36 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:36 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00149-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3881\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: bufstart = 0; bufend = 4522; bufvoid = 104857600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000150_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000150_0' done.\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000150_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=830087\r\n",
      "\t\tFILE: Number of bytes written=2290872\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1157522\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=308\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4522\r\n",
      "\t\tMap output materialized bytes=4593\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1557659648\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3881\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000150_0\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000151_0\r\n",
      "25/08/24 20:13:36 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:36 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:36 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00117-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3877\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: bufstart = 0; bufend = 4520; bufvoid = 104857600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000151_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000151_0' done.\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000151_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=834639\r\n",
      "\t\tFILE: Number of bytes written=2295497\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1161399\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=310\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4520\r\n",
      "\t\tMap output materialized bytes=4593\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1557659648\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3877\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000151_0\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000152_0\r\n",
      "25/08/24 20:13:36 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:36 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:36 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00125-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3875\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: bufstart = 0; bufend = 4516; bufvoid = 104857600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000152_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000152_0' done.\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000152_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=839191\r\n",
      "\t\tFILE: Number of bytes written=2300116\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1165274\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=312\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4516\r\n",
      "\t\tMap output materialized bytes=4587\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1557659648\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3875\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000152_0\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000153_0\r\n",
      "25/08/24 20:13:36 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:36 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:36 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00134-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3872\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: bufstart = 0; bufend = 4516; bufvoid = 104857600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000153_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000153_0' done.\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000153_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=843743\r\n",
      "\t\tFILE: Number of bytes written=2304738\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1169146\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=314\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4516\r\n",
      "\t\tMap output materialized bytes=4590\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1557659648\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3872\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000153_0\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000154_0\r\n",
      "25/08/24 20:13:36 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:36 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:36 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00135-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3871\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: bufstart = 0; bufend = 4512; bufvoid = 104857600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000154_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000154_0' done.\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000154_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=848295\r\n",
      "\t\tFILE: Number of bytes written=2309353\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1173017\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=316\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4512\r\n",
      "\t\tMap output materialized bytes=4583\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1557659648\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3871\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000154_0\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000155_0\r\n",
      "25/08/24 20:13:36 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:36 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:36 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00154-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3868\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: bufstart = 0; bufend = 4509; bufvoid = 104857600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000155_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000155_0' done.\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000155_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=852847\r\n",
      "\t\tFILE: Number of bytes written=2313965\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1176885\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=318\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4509\r\n",
      "\t\tMap output materialized bytes=4580\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1557659648\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3868\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000155_0\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000156_0\r\n",
      "25/08/24 20:13:36 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:36 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:36 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00132-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3860\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: bufstart = 0; bufend = 4500; bufvoid = 104857600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000156_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000156_0' done.\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000156_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=857399\r\n",
      "\t\tFILE: Number of bytes written=2318567\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1180745\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=320\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4500\r\n",
      "\t\tMap output materialized bytes=4570\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1557659648\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3860\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000156_0\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000157_0\r\n",
      "25/08/24 20:13:36 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:36 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:36 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00157-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3860\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: bufstart = 0; bufend = 4501; bufvoid = 104857600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000157_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000157_0' done.\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000157_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=861951\r\n",
      "\t\tFILE: Number of bytes written=2323173\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1184605\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=322\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4501\r\n",
      "\t\tMap output materialized bytes=4574\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1557659648\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3860\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000157_0\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000158_0\r\n",
      "25/08/24 20:13:36 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:36 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:36 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00151-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3851\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: bufstart = 0; bufend = 4493; bufvoid = 104857600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000158_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000158_0' done.\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000158_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=866503\r\n",
      "\t\tFILE: Number of bytes written=2327771\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1188456\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=324\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4493\r\n",
      "\t\tMap output materialized bytes=4566\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=1\r\n",
      "\t\tTotal committed heap usage (bytes)=1556611072\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3851\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000158_0\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000159_0\r\n",
      "25/08/24 20:13:36 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:36 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:36 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00162-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3850\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: bufstart = 0; bufend = 4491; bufvoid = 104857600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000159_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000159_0' done.\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000159_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=871055\r\n",
      "\t\tFILE: Number of bytes written=2332365\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1192306\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=326\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4491\r\n",
      "\t\tMap output materialized bytes=4562\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1556611072\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3850\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000159_0\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000160_0\r\n",
      "25/08/24 20:13:36 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:36 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:36 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00163-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3849\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: bufstart = 0; bufend = 4491; bufvoid = 104857600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000160_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000160_0' done.\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000160_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=875607\r\n",
      "\t\tFILE: Number of bytes written=2336960\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1196155\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=328\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4491\r\n",
      "\t\tMap output materialized bytes=4563\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1556611072\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3849\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000160_0\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000161_0\r\n",
      "25/08/24 20:13:36 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:36 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:36 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00161-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3847\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: bufstart = 0; bufend = 4487; bufvoid = 104857600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000161_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000161_0' done.\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000161_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=880159\r\n",
      "\t\tFILE: Number of bytes written=2341549\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1200002\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=330\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4487\r\n",
      "\t\tMap output materialized bytes=4557\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1556611072\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3847\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000161_0\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000162_0\r\n",
      "25/08/24 20:13:36 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:36 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:36 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00164-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3839\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: bufstart = 0; bufend = 4480; bufvoid = 104857600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000162_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000162_0' done.\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000162_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=884711\r\n",
      "\t\tFILE: Number of bytes written=2346133\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1203841\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=332\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4480\r\n",
      "\t\tMap output materialized bytes=4552\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1556611072\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3839\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000162_0\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000163_0\r\n",
      "25/08/24 20:13:36 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:36 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:36 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00165-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3823\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: bufstart = 0; bufend = 4463; bufvoid = 104857600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000163_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000163_0' done.\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000163_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=889263\r\n",
      "\t\tFILE: Number of bytes written=2350698\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1207664\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=334\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4463\r\n",
      "\t\tMap output materialized bytes=4533\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1556611072\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3823\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000163_0\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000164_0\r\n",
      "25/08/24 20:13:36 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:36 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:36 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00167-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3809\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: bufstart = 0; bufend = 4451; bufvoid = 104857600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000164_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000164_0' done.\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000164_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=893815\r\n",
      "\t\tFILE: Number of bytes written=2355254\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1211473\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=336\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4451\r\n",
      "\t\tMap output materialized bytes=4524\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1556611072\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3809\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000164_0\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000165_0\r\n",
      "25/08/24 20:13:36 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:36 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:36 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00168-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3809\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: bufstart = 0; bufend = 4449; bufvoid = 104857600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000165_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000165_0' done.\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000165_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=898367\r\n",
      "\t\tFILE: Number of bytes written=2359805\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1215282\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=338\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4449\r\n",
      "\t\tMap output materialized bytes=4519\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1556611072\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3809\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000165_0\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000166_0\r\n",
      "25/08/24 20:13:36 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:36 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:36 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00136-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3797\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: bufstart = 0; bufend = 4437; bufvoid = 104857600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000166_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000166_0' done.\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000166_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=902919\r\n",
      "\t\tFILE: Number of bytes written=2364344\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1219079\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=340\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4437\r\n",
      "\t\tMap output materialized bytes=4507\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=1\r\n",
      "\t\tTotal committed heap usage (bytes)=1737490432\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3797\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000166_0\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000167_0\r\n",
      "25/08/24 20:13:36 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:36 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:36 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00159-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3789\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: bufstart = 0; bufend = 4429; bufvoid = 104857600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000167_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000167_0' done.\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000167_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=907471\r\n",
      "\t\tFILE: Number of bytes written=2368875\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1222868\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=342\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4429\r\n",
      "\t\tMap output materialized bytes=4499\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1737490432\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3789\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000167_0\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000168_0\r\n",
      "25/08/24 20:13:36 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:36 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:36 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00171-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3789\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: bufstart = 0; bufend = 4430; bufvoid = 104857600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000168_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000168_0' done.\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000168_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=912023\r\n",
      "\t\tFILE: Number of bytes written=2373408\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1226657\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=344\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4430\r\n",
      "\t\tMap output materialized bytes=4501\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1737490432\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3789\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000168_0\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000169_0\r\n",
      "25/08/24 20:13:36 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:36 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:36 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00158-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3781\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: bufstart = 0; bufend = 4421; bufvoid = 104857600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000169_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000169_0' done.\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000169_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=916575\r\n",
      "\t\tFILE: Number of bytes written=2377931\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1230438\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=346\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4421\r\n",
      "\t\tMap output materialized bytes=4491\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1737490432\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3781\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000169_0\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000170_0\r\n",
      "25/08/24 20:13:36 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:36 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:36 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00166-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3761\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: bufstart = 0; bufend = 4401; bufvoid = 104857600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000170_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000170_0' done.\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000170_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=921127\r\n",
      "\t\tFILE: Number of bytes written=2382434\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1234199\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=348\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4401\r\n",
      "\t\tMap output materialized bytes=4471\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1737490432\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3761\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000170_0\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000171_0\r\n",
      "25/08/24 20:13:36 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:36 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:36 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00169-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3753\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:36 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: bufstart = 0; bufend = 4394; bufvoid = 104857600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000171_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000171_0' done.\r\n",
      "25/08/24 20:13:36 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000171_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=925679\r\n",
      "\t\tFILE: Number of bytes written=2386931\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1237952\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=350\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4394\r\n",
      "\t\tMap output materialized bytes=4465\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1737490432\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3753\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000171_0\r\n",
      "25/08/24 20:13:36 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000172_0\r\n",
      "25/08/24 20:13:36 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:36 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:36 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00173-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3753\r\n",
      "25/08/24 20:13:36 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufend = 4393; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000172_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000172_0' done.\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000172_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=930231\r\n",
      "\t\tFILE: Number of bytes written=2391426\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1241705\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=352\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4393\r\n",
      "\t\tMap output materialized bytes=4463\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1737490432\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3753\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000172_0\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000173_0\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:37 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00175-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3753\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufend = 4393; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000173_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000173_0' done.\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000173_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=934783\r\n",
      "\t\tFILE: Number of bytes written=2395921\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1245458\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=354\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4393\r\n",
      "\t\tMap output materialized bytes=4463\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1737490432\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3753\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000173_0\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000174_0\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:37 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00174-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3742\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufend = 4382; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000174_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000174_0' done.\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000174_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=939335\r\n",
      "\t\tFILE: Number of bytes written=2400406\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1249200\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=356\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4382\r\n",
      "\t\tMap output materialized bytes=4453\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1737490432\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3742\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000174_0\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000175_0\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:37 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00176-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3741\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufend = 4382; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000175_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000175_0' done.\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000175_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=943887\r\n",
      "\t\tFILE: Number of bytes written=2404891\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1252941\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=358\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4382\r\n",
      "\t\tMap output materialized bytes=4453\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1737490432\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3741\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000175_0\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000176_0\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:37 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00170-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3729\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO mapreduce.Job:  map 100% reduce 0%\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufend = 4369; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000176_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000176_0' done.\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000176_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=948439\r\n",
      "\t\tFILE: Number of bytes written=2409362\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1256670\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=360\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4369\r\n",
      "\t\tMap output materialized bytes=4439\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=1\r\n",
      "\t\tTotal committed heap usage (bytes)=1756364800\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3729\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000176_0\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000177_0\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:37 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00180-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3719\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufend = 4359; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000177_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000177_0' done.\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000177_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=952991\r\n",
      "\t\tFILE: Number of bytes written=2413824\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1260389\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=362\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4359\r\n",
      "\t\tMap output materialized bytes=4430\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1756364800\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3719\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000177_0\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000178_0\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:37 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00178-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3715\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufend = 4355; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000178_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000178_0' done.\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000178_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=957543\r\n",
      "\t\tFILE: Number of bytes written=2418281\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1264104\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=364\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4355\r\n",
      "\t\tMap output materialized bytes=4425\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1756364800\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3715\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000178_0\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000179_0\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:37 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00177-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3711\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufend = 4351; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000179_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000179_0' done.\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000179_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=962095\r\n",
      "\t\tFILE: Number of bytes written=2422734\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1267815\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=366\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4351\r\n",
      "\t\tMap output materialized bytes=4421\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1756364800\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3711\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000179_0\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000180_0\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:37 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00179-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3698\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufend = 4338; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000180_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000180_0' done.\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000180_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=966647\r\n",
      "\t\tFILE: Number of bytes written=2427174\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1271513\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=368\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4338\r\n",
      "\t\tMap output materialized bytes=4408\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1756364800\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3698\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000180_0\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000181_0\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:37 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00181-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3690\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufend = 4330; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000181_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000181_0' done.\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000181_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=971199\r\n",
      "\t\tFILE: Number of bytes written=2431606\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1275203\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=370\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4330\r\n",
      "\t\tMap output materialized bytes=4400\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1756364800\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3690\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000181_0\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000182_0\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:37 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00182-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3688\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufend = 4328; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000182_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000182_0' done.\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000182_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=975751\r\n",
      "\t\tFILE: Number of bytes written=2436036\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1278891\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=372\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4328\r\n",
      "\t\tMap output materialized bytes=4398\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1756364800\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3688\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000182_0\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000183_0\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:37 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00172-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3687\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufend = 4327; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000183_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000183_0' done.\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000183_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=980303\r\n",
      "\t\tFILE: Number of bytes written=2440465\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1282578\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=374\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4327\r\n",
      "\t\tMap output materialized bytes=4397\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1756364800\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3687\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000183_0\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000184_0\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:37 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00184-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3683\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufend = 4323; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000184_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000184_0' done.\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000184_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=984855\r\n",
      "\t\tFILE: Number of bytes written=2444890\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1286261\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=376\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4323\r\n",
      "\t\tMap output materialized bytes=4393\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1756364800\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3683\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000184_0\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000185_0\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:37 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00183-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3673\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufend = 4313; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000185_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000185_0' done.\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000185_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=989407\r\n",
      "\t\tFILE: Number of bytes written=2449305\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1289934\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=378\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4313\r\n",
      "\t\tMap output materialized bytes=4383\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1756364800\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3673\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000185_0\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000186_0\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:37 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00185-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3672\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufend = 4313; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000186_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000186_0' done.\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000186_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=993959\r\n",
      "\t\tFILE: Number of bytes written=2453721\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1293606\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=380\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4313\r\n",
      "\t\tMap output materialized bytes=4384\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=2\r\n",
      "\t\tTotal committed heap usage (bytes)=1931476992\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3672\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000186_0\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000187_0\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:37 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00188-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3660\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufend = 4300; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000187_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000187_0' done.\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000187_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=998511\r\n",
      "\t\tFILE: Number of bytes written=2458123\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1297266\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=382\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4300\r\n",
      "\t\tMap output materialized bytes=4370\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1931476992\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3660\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000187_0\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000188_0\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:37 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00186-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3656\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufend = 4296; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000188_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000188_0' done.\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000188_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1003063\r\n",
      "\t\tFILE: Number of bytes written=2462521\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1300922\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=384\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4296\r\n",
      "\t\tMap output materialized bytes=4366\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1931476992\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3656\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000188_0\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000189_0\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:37 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00187-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3653\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufend = 4293; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000189_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000189_0' done.\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000189_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1007615\r\n",
      "\t\tFILE: Number of bytes written=2466916\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1304575\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=386\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4293\r\n",
      "\t\tMap output materialized bytes=4363\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1931476992\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3653\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000189_0\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000190_0\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:37 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00189-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3648\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufend = 4288; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000190_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000190_0' done.\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000190_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1012167\r\n",
      "\t\tFILE: Number of bytes written=2471306\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1308223\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=388\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4288\r\n",
      "\t\tMap output materialized bytes=4358\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1931476992\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3648\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000190_0\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000191_0\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:37 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00191-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3630\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufend = 4270; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000191_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000191_0' done.\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000191_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1016719\r\n",
      "\t\tFILE: Number of bytes written=2475678\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1311853\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=390\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4270\r\n",
      "\t\tMap output materialized bytes=4340\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1931476992\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3630\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000191_0\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000192_0\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:37 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00192-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3630\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufend = 4270; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000192_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000192_0' done.\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000192_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1021271\r\n",
      "\t\tFILE: Number of bytes written=2480050\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1315483\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=392\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4270\r\n",
      "\t\tMap output materialized bytes=4340\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1931476992\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3630\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000192_0\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000193_0\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:37 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00190-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3624\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufend = 4264; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000193_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000193_0' done.\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000193_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1025823\r\n",
      "\t\tFILE: Number of bytes written=2484416\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1319107\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=394\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4264\r\n",
      "\t\tMap output materialized bytes=4334\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1931476992\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3624\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000193_0\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000194_0\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:37 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00193-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3623\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufend = 4263; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000194_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000194_0' done.\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000194_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1030375\r\n",
      "\t\tFILE: Number of bytes written=2488781\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1322730\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=396\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4263\r\n",
      "\t\tMap output materialized bytes=4333\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1931476992\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3623\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000194_0\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000195_0\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:37 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00194-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3605\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufend = 4245; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000195_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000195_0' done.\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000195_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1034927\r\n",
      "\t\tFILE: Number of bytes written=2493128\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1326335\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=398\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4245\r\n",
      "\t\tMap output materialized bytes=4315\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1931476992\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3605\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000195_0\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000196_0\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:37 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00196-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3595\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufend = 4235; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000196_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000196_0' done.\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000196_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1039479\r\n",
      "\t\tFILE: Number of bytes written=2497465\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1329930\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=400\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4235\r\n",
      "\t\tMap output materialized bytes=4305\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1931476992\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3595\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000196_0\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000197_0\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:37 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00198-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3591\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufend = 4231; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000197_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000197_0' done.\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000197_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1044031\r\n",
      "\t\tFILE: Number of bytes written=2501798\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1333521\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=402\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4231\r\n",
      "\t\tMap output materialized bytes=4301\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=1\r\n",
      "\t\tTotal committed heap usage (bytes)=1947729920\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3591\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000197_0\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000198_0\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:37 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00195-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3590\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufend = 4230; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000198_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000198_0' done.\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000198_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1048583\r\n",
      "\t\tFILE: Number of bytes written=2506130\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1337111\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=404\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4230\r\n",
      "\t\tMap output materialized bytes=4300\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1947729920\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3590\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000198_0\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000199_0\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:37 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00197-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3589\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufend = 4229; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000199_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000199_0' done.\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000199_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1053135\r\n",
      "\t\tFILE: Number of bytes written=2510461\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1340700\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=406\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4229\r\n",
      "\t\tMap output materialized bytes=4299\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1947729920\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3589\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000199_0\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000200_0\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:37 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00199-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3573\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufend = 4214; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000200_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000200_0' done.\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000200_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1057687\r\n",
      "\t\tFILE: Number of bytes written=2514778\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1344273\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=408\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4214\r\n",
      "\t\tMap output materialized bytes=4285\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1947729920\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3573\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000200_0\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000201_0\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:37 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00203-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3563\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufend = 4203; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000201_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000201_0' done.\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000201_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1062239\r\n",
      "\t\tFILE: Number of bytes written=2519083\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1347836\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=410\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4203\r\n",
      "\t\tMap output materialized bytes=4273\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1947729920\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3563\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000201_0\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000202_0\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:37 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00204-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3559\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufend = 4199; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000202_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000202_0' done.\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000202_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1066791\r\n",
      "\t\tFILE: Number of bytes written=2523384\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1351395\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=412\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4199\r\n",
      "\t\tMap output materialized bytes=4269\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1947729920\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3559\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000202_0\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000203_0\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:37 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00200-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3556\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufend = 4196; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000203_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000203_0' done.\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000203_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1071343\r\n",
      "\t\tFILE: Number of bytes written=2527682\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1354951\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=414\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4196\r\n",
      "\t\tMap output materialized bytes=4266\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1947729920\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3556\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000203_0\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000204_0\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:37 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00202-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3554\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufend = 4194; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000204_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000204_0' done.\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000204_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1075895\r\n",
      "\t\tFILE: Number of bytes written=2531978\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1358505\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=416\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4194\r\n",
      "\t\tMap output materialized bytes=4264\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1947729920\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3554\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000204_0\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000205_0\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:37 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00201-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3550\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufend = 4190; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000205_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000205_0' done.\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000205_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1080447\r\n",
      "\t\tFILE: Number of bytes written=2536270\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1362055\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=418\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4190\r\n",
      "\t\tMap output materialized bytes=4260\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1947729920\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3550\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000205_0\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000206_0\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:37 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00209-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3532\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufend = 4172; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000206_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000206_0' done.\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000206_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1084999\r\n",
      "\t\tFILE: Number of bytes written=2540544\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1365587\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=420\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4172\r\n",
      "\t\tMap output materialized bytes=4242\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1947729920\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3532\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000206_0\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000207_0\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:37 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00205-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3528\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufend = 4168; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000207_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000207_0' done.\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000207_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1089551\r\n",
      "\t\tFILE: Number of bytes written=2544814\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1369115\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=422\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4168\r\n",
      "\t\tMap output materialized bytes=4238\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=1947729920\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3528\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000207_0\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000208_0\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:37 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00207-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3528\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufend = 4168; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000208_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000208_0' done.\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000208_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1094103\r\n",
      "\t\tFILE: Number of bytes written=2549084\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1372643\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=424\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4168\r\n",
      "\t\tMap output materialized bytes=4238\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=2\r\n",
      "\t\tTotal committed heap usage (bytes)=2105540608\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3528\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000208_0\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000209_0\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:37 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00208-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3522\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufend = 4162; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000209_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000209_0' done.\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000209_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1098655\r\n",
      "\t\tFILE: Number of bytes written=2553348\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1376165\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=426\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4162\r\n",
      "\t\tMap output materialized bytes=4232\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2105540608\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3522\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000209_0\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000210_0\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:37 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00206-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3513\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufend = 4153; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000210_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000210_0' done.\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000210_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1103207\r\n",
      "\t\tFILE: Number of bytes written=2557603\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1379678\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=428\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4153\r\n",
      "\t\tMap output materialized bytes=4223\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2105540608\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3513\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000210_0\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000211_0\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:37 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00210-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3507\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufend = 4147; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000211_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000211_0' done.\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000211_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1107759\r\n",
      "\t\tFILE: Number of bytes written=2561852\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1383185\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=430\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4147\r\n",
      "\t\tMap output materialized bytes=4217\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2105540608\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3507\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000211_0\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000212_0\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:37 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00213-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3496\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufend = 4136; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000212_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000212_0' done.\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000212_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1112311\r\n",
      "\t\tFILE: Number of bytes written=2566090\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1386681\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=432\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4136\r\n",
      "\t\tMap output materialized bytes=4206\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2105540608\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3496\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000212_0\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000213_0\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:37 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00214-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3496\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufend = 4136; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000213_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000213_0' done.\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000213_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1116863\r\n",
      "\t\tFILE: Number of bytes written=2570328\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1390177\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=434\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4136\r\n",
      "\t\tMap output materialized bytes=4206\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2105540608\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3496\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000213_0\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000214_0\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:37 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00212-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3495\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufend = 4135; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000214_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000214_0' done.\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000214_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1121415\r\n",
      "\t\tFILE: Number of bytes written=2574565\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1393672\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=436\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4135\r\n",
      "\t\tMap output materialized bytes=4205\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2105540608\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3495\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000214_0\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000215_0\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:37 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00211-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3488\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufend = 4128; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000215_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000215_0' done.\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000215_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1125967\r\n",
      "\t\tFILE: Number of bytes written=2578795\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1397160\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=438\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4128\r\n",
      "\t\tMap output materialized bytes=4198\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2105540608\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3488\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000215_0\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000216_0\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:37 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00215-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3477\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufend = 4117; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000216_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000216_0' done.\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000216_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1130519\r\n",
      "\t\tFILE: Number of bytes written=2583014\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1400637\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=440\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4117\r\n",
      "\t\tMap output materialized bytes=4187\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2105540608\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3477\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000216_0\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000217_0\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:37 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00216-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3466\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufend = 4106; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000217_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000217_0' done.\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000217_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1135071\r\n",
      "\t\tFILE: Number of bytes written=2587222\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1404103\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=442\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4106\r\n",
      "\t\tMap output materialized bytes=4176\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2105540608\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3466\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000217_0\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000218_0\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:37 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00217-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3462\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufend = 4102; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000218_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000218_0' done.\r\n",
      "25/08/24 20:13:37 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000218_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1139623\r\n",
      "\t\tFILE: Number of bytes written=2591426\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1407565\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=444\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4102\r\n",
      "\t\tMap output materialized bytes=4172\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2105540608\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3462\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000218_0\r\n",
      "25/08/24 20:13:37 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000219_0\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:37 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:37 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00219-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3461\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:37 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:37 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufend = 4101; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000219_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000219_0' done.\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000219_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1144175\r\n",
      "\t\tFILE: Number of bytes written=2595629\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1411026\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=446\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4101\r\n",
      "\t\tMap output materialized bytes=4171\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2105540608\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3461\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000219_0\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000220_0\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:38 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00218-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3460\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufend = 4100; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000220_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000220_0' done.\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000220_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1148727\r\n",
      "\t\tFILE: Number of bytes written=2599831\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1414486\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=448\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4100\r\n",
      "\t\tMap output materialized bytes=4170\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=1\r\n",
      "\t\tTotal committed heap usage (bytes)=2123366400\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3460\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000220_0\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000221_0\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:38 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00223-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3435\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufend = 4075; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000221_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000221_0' done.\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000221_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1153279\r\n",
      "\t\tFILE: Number of bytes written=2604008\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1417921\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=450\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4075\r\n",
      "\t\tMap output materialized bytes=4145\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2123366400\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3435\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000221_0\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000222_0\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:38 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00220-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3434\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufend = 4074; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000222_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000222_0' done.\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000222_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1157831\r\n",
      "\t\tFILE: Number of bytes written=2608184\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1421355\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=452\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4074\r\n",
      "\t\tMap output materialized bytes=4144\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2123366400\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3434\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000222_0\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000223_0\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:38 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00222-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3432\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufend = 4072; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000223_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000223_0' done.\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000223_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1162383\r\n",
      "\t\tFILE: Number of bytes written=2612358\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1424787\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=454\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4072\r\n",
      "\t\tMap output materialized bytes=4142\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2123366400\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3432\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000223_0\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000224_0\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:38 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00224-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3415\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufend = 4055; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000224_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000224_0' done.\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000224_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1166935\r\n",
      "\t\tFILE: Number of bytes written=2616515\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1428202\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=456\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4055\r\n",
      "\t\tMap output materialized bytes=4125\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2123366400\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3415\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000224_0\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000225_0\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:38 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00221-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3411\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufend = 4051; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000225_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000225_0' done.\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000225_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1171487\r\n",
      "\t\tFILE: Number of bytes written=2620668\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1431613\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=458\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4051\r\n",
      "\t\tMap output materialized bytes=4121\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2123366400\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3411\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000225_0\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000226_0\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:38 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00227-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3405\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufend = 4045; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000226_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000226_0' done.\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000226_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1176039\r\n",
      "\t\tFILE: Number of bytes written=2624815\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1435018\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=460\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4045\r\n",
      "\t\tMap output materialized bytes=4115\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2123366400\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3405\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000226_0\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000227_0\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:38 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00228-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3401\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufend = 4041; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000227_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000227_0' done.\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000227_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1180591\r\n",
      "\t\tFILE: Number of bytes written=2628958\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1438419\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=462\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4041\r\n",
      "\t\tMap output materialized bytes=4111\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2123366400\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3401\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000227_0\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000228_0\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:38 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00225-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3394\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufend = 4034; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000228_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000228_0' done.\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000228_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1185143\r\n",
      "\t\tFILE: Number of bytes written=2633094\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1441813\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=464\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4034\r\n",
      "\t\tMap output materialized bytes=4104\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2123366400\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3394\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000228_0\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000229_0\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:38 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00226-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3382\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufend = 4022; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000229_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000229_0' done.\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000229_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1189695\r\n",
      "\t\tFILE: Number of bytes written=2637218\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1445195\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=466\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4022\r\n",
      "\t\tMap output materialized bytes=4092\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2123366400\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3382\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000229_0\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000230_0\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:38 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00231-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3380\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufend = 4020; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000230_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000230_0' done.\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000230_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1194247\r\n",
      "\t\tFILE: Number of bytes written=2641340\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1448575\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=468\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4020\r\n",
      "\t\tMap output materialized bytes=4090\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2123366400\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3380\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000230_0\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000231_0\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:38 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00229-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3378\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufend = 4018; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000231_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000231_0' done.\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000231_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1198799\r\n",
      "\t\tFILE: Number of bytes written=2645460\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1451953\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=470\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4018\r\n",
      "\t\tMap output materialized bytes=4088\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2123366400\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3378\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000231_0\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000232_0\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:38 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00230-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3366\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufend = 4006; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000232_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000232_0' done.\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000232_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1203351\r\n",
      "\t\tFILE: Number of bytes written=2649568\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1455319\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=472\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4006\r\n",
      "\t\tMap output materialized bytes=4076\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=2\r\n",
      "\t\tTotal committed heap usage (bytes)=2259681280\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3366\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000232_0\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000233_0\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:38 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00233-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3366\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufend = 4006; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000233_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000233_0' done.\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000233_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1207903\r\n",
      "\t\tFILE: Number of bytes written=2653676\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1458685\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=474\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4006\r\n",
      "\t\tMap output materialized bytes=4076\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2259681280\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3366\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000233_0\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000234_0\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:38 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00232-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3362\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufend = 4002; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000234_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000234_0' done.\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000234_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1212455\r\n",
      "\t\tFILE: Number of bytes written=2657780\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1462047\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=476\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=4002\r\n",
      "\t\tMap output materialized bytes=4072\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2259681280\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3362\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000234_0\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000235_0\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:38 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00234-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3357\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufend = 3997; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000235_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000235_0' done.\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000235_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1217007\r\n",
      "\t\tFILE: Number of bytes written=2661879\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1465404\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=478\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3997\r\n",
      "\t\tMap output materialized bytes=4067\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2259681280\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3357\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000235_0\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000236_0\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:38 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00238-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3341\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufend = 3981; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000236_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000236_0' done.\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000236_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1221559\r\n",
      "\t\tFILE: Number of bytes written=2665962\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1468745\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=480\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3981\r\n",
      "\t\tMap output materialized bytes=4051\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2259681280\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3341\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000236_0\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000237_0\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:38 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00237-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3337\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufend = 3977; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000237_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000237_0' done.\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000237_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1226111\r\n",
      "\t\tFILE: Number of bytes written=2670041\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1472082\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=482\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3977\r\n",
      "\t\tMap output materialized bytes=4047\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2259681280\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3337\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000237_0\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000238_0\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:38 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00235-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3331\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufend = 3971; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000238_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000238_0' done.\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000238_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1230663\r\n",
      "\t\tFILE: Number of bytes written=2674114\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1475413\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=484\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3971\r\n",
      "\t\tMap output materialized bytes=4041\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2259681280\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3331\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000238_0\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000239_0\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:38 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00236-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3327\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufend = 3967; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000239_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000239_0' done.\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000239_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1235215\r\n",
      "\t\tFILE: Number of bytes written=2678183\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1478740\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=486\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3967\r\n",
      "\t\tMap output materialized bytes=4037\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2259681280\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3327\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000239_0\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000240_0\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:38 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00239-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3315\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufend = 3955; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000240_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000240_0' done.\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000240_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1239767\r\n",
      "\t\tFILE: Number of bytes written=2682240\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1482055\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=488\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3955\r\n",
      "\t\tMap output materialized bytes=4025\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2259681280\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3315\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000240_0\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000241_0\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:38 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00242-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3298\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufend = 3938; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000241_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000241_0' done.\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000241_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1244319\r\n",
      "\t\tFILE: Number of bytes written=2686280\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1485353\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=490\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3938\r\n",
      "\t\tMap output materialized bytes=4008\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2259681280\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3298\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000241_0\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000242_0\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:38 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00240-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3297\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufend = 3937; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000242_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000242_0' done.\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000242_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1248871\r\n",
      "\t\tFILE: Number of bytes written=2690319\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1488650\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=492\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3937\r\n",
      "\t\tMap output materialized bytes=4007\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2259681280\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3297\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000242_0\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000243_0\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:38 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00241-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3297\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufend = 3937; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000243_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000243_0' done.\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000243_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1253423\r\n",
      "\t\tFILE: Number of bytes written=2694358\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1491947\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=494\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3937\r\n",
      "\t\tMap output materialized bytes=4007\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2259681280\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3297\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000243_0\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000244_0\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:38 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00243-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3295\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufend = 3935; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000244_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000244_0' done.\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000244_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1257975\r\n",
      "\t\tFILE: Number of bytes written=2698395\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1495242\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=496\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3935\r\n",
      "\t\tMap output materialized bytes=4005\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2259681280\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3295\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000244_0\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000245_0\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:38 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00247-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3275\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufend = 3915; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000245_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000245_0' done.\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000245_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1262527\r\n",
      "\t\tFILE: Number of bytes written=2702412\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1498517\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=498\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3915\r\n",
      "\t\tMap output materialized bytes=3985\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=1\r\n",
      "\t\tTotal committed heap usage (bytes)=2270691328\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3275\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000245_0\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000246_0\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:38 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00246-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3271\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufend = 3911; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000246_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000246_0' done.\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000246_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1267079\r\n",
      "\t\tFILE: Number of bytes written=2706425\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1501788\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=500\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3911\r\n",
      "\t\tMap output materialized bytes=3981\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2270691328\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3271\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000246_0\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000247_0\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:38 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00244-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3269\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufend = 3909; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000247_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000247_0' done.\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000247_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1271631\r\n",
      "\t\tFILE: Number of bytes written=2710436\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1505057\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=502\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3909\r\n",
      "\t\tMap output materialized bytes=3979\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2270691328\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3269\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000247_0\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000248_0\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:38 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00245-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3259\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufend = 3899; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000248_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000248_0' done.\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000248_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1276183\r\n",
      "\t\tFILE: Number of bytes written=2714437\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1508316\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=504\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3899\r\n",
      "\t\tMap output materialized bytes=3969\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2270691328\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3259\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000248_0\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000249_0\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:38 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00248-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3256\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufend = 3896; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000249_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000249_0' done.\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000249_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1280735\r\n",
      "\t\tFILE: Number of bytes written=2718435\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1511572\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=506\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3896\r\n",
      "\t\tMap output materialized bytes=3966\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2270691328\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3256\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000249_0\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000250_0\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:38 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00250-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3248\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufend = 3888; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000250_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000250_0' done.\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000250_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1285287\r\n",
      "\t\tFILE: Number of bytes written=2722425\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1514820\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=508\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3888\r\n",
      "\t\tMap output materialized bytes=3958\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2270691328\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3248\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000250_0\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000251_0\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:38 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00249-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3245\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufend = 3885; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000251_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000251_0' done.\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000251_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1289839\r\n",
      "\t\tFILE: Number of bytes written=2726412\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1518065\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=510\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3885\r\n",
      "\t\tMap output materialized bytes=3955\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2270691328\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3245\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000251_0\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000252_0\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:38 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00252-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3239\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufend = 3879; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000252_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000252_0' done.\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000252_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1294391\r\n",
      "\t\tFILE: Number of bytes written=2730393\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1521304\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=512\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3879\r\n",
      "\t\tMap output materialized bytes=3949\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2270691328\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3239\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000252_0\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000253_0\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:38 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00251-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3231\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufend = 3871; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000253_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000253_0' done.\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000253_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1298943\r\n",
      "\t\tFILE: Number of bytes written=2734366\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1524535\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=514\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3871\r\n",
      "\t\tMap output materialized bytes=3941\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2270691328\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3231\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000253_0\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000254_0\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:38 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00254-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3208\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufend = 3848; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000254_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000254_0' done.\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000254_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1303495\r\n",
      "\t\tFILE: Number of bytes written=2738316\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1527743\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=516\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3848\r\n",
      "\t\tMap output materialized bytes=3918\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2270691328\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3208\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000254_0\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000255_0\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:38 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00253-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3206\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufend = 3846; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000255_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000255_0' done.\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000255_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1308047\r\n",
      "\t\tFILE: Number of bytes written=2742264\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1530949\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=518\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3846\r\n",
      "\t\tMap output materialized bytes=3916\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2270691328\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3206\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000255_0\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000256_0\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:38 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00255-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3206\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufend = 3846; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000256_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000256_0' done.\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000256_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1312599\r\n",
      "\t\tFILE: Number of bytes written=2746212\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1534155\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=520\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3846\r\n",
      "\t\tMap output materialized bytes=3916\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2270691328\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3206\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000256_0\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000257_0\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:38 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00256-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3204\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufend = 3844; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000257_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000257_0' done.\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000257_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1317151\r\n",
      "\t\tFILE: Number of bytes written=2750158\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1537359\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=522\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3844\r\n",
      "\t\tMap output materialized bytes=3914\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2270691328\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3204\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000257_0\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000258_0\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:38 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00259-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3179\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufend = 3819; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000258_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000258_0' done.\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000258_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1321703\r\n",
      "\t\tFILE: Number of bytes written=2754079\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1540538\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=524\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3819\r\n",
      "\t\tMap output materialized bytes=3889\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=2\r\n",
      "\t\tTotal committed heap usage (bytes)=2371878912\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3179\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000258_0\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000259_0\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:38 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00258-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3177\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufend = 3817; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000259_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000259_0' done.\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000259_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1326255\r\n",
      "\t\tFILE: Number of bytes written=2757998\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1543715\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=526\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3817\r\n",
      "\t\tMap output materialized bytes=3887\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2371878912\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3177\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000259_0\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000260_0\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:38 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00257-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3175\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufend = 3815; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000260_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000260_0' done.\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000260_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1330807\r\n",
      "\t\tFILE: Number of bytes written=2761915\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1546890\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=528\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3815\r\n",
      "\t\tMap output materialized bytes=3885\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2371878912\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3175\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000260_0\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000261_0\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:38 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00260-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3170\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufend = 3810; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000261_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000261_0' done.\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000261_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1335359\r\n",
      "\t\tFILE: Number of bytes written=2765827\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1550060\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=530\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3810\r\n",
      "\t\tMap output materialized bytes=3880\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2371878912\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3170\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000261_0\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000262_0\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:38 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00261-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3152\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufend = 3792; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000262_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000262_0' done.\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000262_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1339911\r\n",
      "\t\tFILE: Number of bytes written=2769721\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1553212\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=532\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3792\r\n",
      "\t\tMap output materialized bytes=3862\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2371878912\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3152\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000262_0\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000263_0\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:38 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00262-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3146\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufend = 3786; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000263_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000263_0' done.\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000263_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1344463\r\n",
      "\t\tFILE: Number of bytes written=2773609\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1556358\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=534\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3786\r\n",
      "\t\tMap output materialized bytes=3856\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2371878912\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3146\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000263_0\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000264_0\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:38 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00263-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3143\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufend = 3783; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000264_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000264_0' done.\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000264_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1349015\r\n",
      "\t\tFILE: Number of bytes written=2777494\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1559501\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=536\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3783\r\n",
      "\t\tMap output materialized bytes=3853\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2371878912\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3143\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000264_0\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000265_0\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:38 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00264-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3142\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufend = 3782; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000265_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000265_0' done.\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000265_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1353567\r\n",
      "\t\tFILE: Number of bytes written=2781378\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1562643\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=538\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3782\r\n",
      "\t\tMap output materialized bytes=3852\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2371878912\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3142\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000265_0\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000266_0\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:38 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00265-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3132\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufend = 3772; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000266_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000266_0' done.\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000266_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1358119\r\n",
      "\t\tFILE: Number of bytes written=2785252\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1565775\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=540\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3772\r\n",
      "\t\tMap output materialized bytes=3842\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2371878912\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3132\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000266_0\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000267_0\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:38 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00267-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3116\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufend = 3756; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000267_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000267_0' done.\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000267_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1362671\r\n",
      "\t\tFILE: Number of bytes written=2789110\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1568891\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=542\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3756\r\n",
      "\t\tMap output materialized bytes=3826\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2371878912\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3116\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000267_0\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000268_0\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:38 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00266-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3114\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufend = 3754; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000268_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000268_0' done.\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000268_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1367223\r\n",
      "\t\tFILE: Number of bytes written=2792966\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1572005\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=544\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3754\r\n",
      "\t\tMap output materialized bytes=3824\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2371878912\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3114\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000268_0\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000269_0\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:38 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00269-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3113\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufend = 3753; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000269_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000269_0' done.\r\n",
      "25/08/24 20:13:38 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000269_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1371775\r\n",
      "\t\tFILE: Number of bytes written=2796821\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1575118\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=546\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3753\r\n",
      "\t\tMap output materialized bytes=3823\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2371878912\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3113\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000269_0\r\n",
      "25/08/24 20:13:38 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000270_0\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:38 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:38 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00268-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3099\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:38 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:38 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufend = 3739; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000270_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000270_0' done.\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000270_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1376327\r\n",
      "\t\tFILE: Number of bytes written=2800662\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1578217\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=548\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3739\r\n",
      "\t\tMap output materialized bytes=3809\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2371878912\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3099\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000270_0\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000271_0\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:39 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00270-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3095\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufend = 3735; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000271_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000271_0' done.\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000271_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1380879\r\n",
      "\t\tFILE: Number of bytes written=2804499\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1581312\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=550\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3735\r\n",
      "\t\tMap output materialized bytes=3805\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2371878912\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3095\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000271_0\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000272_0\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:39 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00271-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3086\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufend = 3726; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000272_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000272_0' done.\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000272_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1385431\r\n",
      "\t\tFILE: Number of bytes written=2808327\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1584398\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=552\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3726\r\n",
      "\t\tMap output materialized bytes=3796\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=2\r\n",
      "\t\tTotal committed heap usage (bytes)=2377646080\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3086\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000272_0\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000273_0\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:39 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00272-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3083\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufend = 3723; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000273_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000273_0' done.\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000273_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1389983\r\n",
      "\t\tFILE: Number of bytes written=2812152\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1587481\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=554\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3723\r\n",
      "\t\tMap output materialized bytes=3793\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2377646080\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3083\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000273_0\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000274_0\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:39 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00273-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3077\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufend = 3717; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000274_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000274_0' done.\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000274_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1394535\r\n",
      "\t\tFILE: Number of bytes written=2815971\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1590558\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=556\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3717\r\n",
      "\t\tMap output materialized bytes=3787\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2377646080\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3077\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000274_0\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000275_0\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:39 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00274-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3060\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufend = 3700; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000275_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000275_0' done.\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000275_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1399087\r\n",
      "\t\tFILE: Number of bytes written=2819773\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1593618\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=558\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3700\r\n",
      "\t\tMap output materialized bytes=3770\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2377646080\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3060\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000275_0\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000276_0\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:39 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00278-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3054\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufend = 3694; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000276_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000276_0' done.\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000276_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1403639\r\n",
      "\t\tFILE: Number of bytes written=2823569\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1596672\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=560\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3694\r\n",
      "\t\tMap output materialized bytes=3764\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2377646080\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3054\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000276_0\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000277_0\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:39 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00275-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3047\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufend = 3687; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000277_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000277_0' done.\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000277_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1408191\r\n",
      "\t\tFILE: Number of bytes written=2827358\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1599719\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=562\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3687\r\n",
      "\t\tMap output materialized bytes=3757\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2377646080\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3047\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000277_0\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000278_0\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:39 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00276-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3046\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufend = 3686; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000278_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000278_0' done.\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000278_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1412743\r\n",
      "\t\tFILE: Number of bytes written=2831146\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1602765\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=564\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3686\r\n",
      "\t\tMap output materialized bytes=3756\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2377646080\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3046\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000278_0\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000279_0\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:39 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00277-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3045\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufend = 3685; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000279_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000279_0' done.\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000279_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1417295\r\n",
      "\t\tFILE: Number of bytes written=2834933\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1605810\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=566\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3685\r\n",
      "\t\tMap output materialized bytes=3755\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2377646080\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3045\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000279_0\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000280_0\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:39 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00279-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3022\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufend = 3662; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000280_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000280_0' done.\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000280_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1421847\r\n",
      "\t\tFILE: Number of bytes written=2838697\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1608832\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=568\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3662\r\n",
      "\t\tMap output materialized bytes=3732\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2377646080\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3022\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000280_0\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000281_0\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:39 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00281-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3020\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufend = 3660; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000281_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000281_0' done.\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000281_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1426399\r\n",
      "\t\tFILE: Number of bytes written=2842459\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1611852\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=570\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3660\r\n",
      "\t\tMap output materialized bytes=3730\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2377646080\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3020\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000281_0\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000282_0\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:39 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00282-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3019\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufend = 3659; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000282_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000282_0' done.\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000282_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1430951\r\n",
      "\t\tFILE: Number of bytes written=2846220\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1614871\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=572\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3659\r\n",
      "\t\tMap output materialized bytes=3729\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2377646080\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3019\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000282_0\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000283_0\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:39 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00280-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3013\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufend = 3653; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000283_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000283_0' done.\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000283_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1435503\r\n",
      "\t\tFILE: Number of bytes written=2849975\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1617884\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=574\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3653\r\n",
      "\t\tMap output materialized bytes=3723\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2377646080\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3013\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000283_0\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000284_0\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:39 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00283-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+3003\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufend = 3643; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000284_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000284_0' done.\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000284_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1440055\r\n",
      "\t\tFILE: Number of bytes written=2853720\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1620887\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=576\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3643\r\n",
      "\t\tMap output materialized bytes=3713\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2377646080\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=3003\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000284_0\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000285_0\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:39 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00285-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+2985\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufend = 3625; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000285_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000285_0' done.\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000285_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1444607\r\n",
      "\t\tFILE: Number of bytes written=2857447\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1623872\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=578\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3625\r\n",
      "\t\tMap output materialized bytes=3695\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2377646080\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2985\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000285_0\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000286_0\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:39 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00286-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+2985\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufend = 3625; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000286_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000286_0' done.\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000286_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1449159\r\n",
      "\t\tFILE: Number of bytes written=2861174\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1626857\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=580\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3625\r\n",
      "\t\tMap output materialized bytes=3695\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=1\r\n",
      "\t\tTotal committed heap usage (bytes)=2463105024\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2985\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000286_0\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000287_0\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:39 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00284-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+2980\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufend = 3620; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000287_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000287_0' done.\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000287_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1453711\r\n",
      "\t\tFILE: Number of bytes written=2864896\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1629837\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=582\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3620\r\n",
      "\t\tMap output materialized bytes=3690\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2463105024\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2980\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000287_0\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000288_0\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:39 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00287-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+2974\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufend = 3614; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000288_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000288_0' done.\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000288_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1458263\r\n",
      "\t\tFILE: Number of bytes written=2868612\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1632811\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=584\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3614\r\n",
      "\t\tMap output materialized bytes=3684\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2463105024\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2974\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000288_0\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000289_0\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:39 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00290-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+2945\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufend = 3585; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000289_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000289_0' done.\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000289_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1462815\r\n",
      "\t\tFILE: Number of bytes written=2872299\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1635756\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=586\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3585\r\n",
      "\t\tMap output materialized bytes=3655\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2463105024\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2945\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000289_0\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000290_0\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:39 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00288-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+2942\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufend = 3582; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000290_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000290_0' done.\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000290_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1467367\r\n",
      "\t\tFILE: Number of bytes written=2875983\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1638698\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=588\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3582\r\n",
      "\t\tMap output materialized bytes=3652\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2463105024\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2942\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000290_0\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000291_0\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:39 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00289-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+2938\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufend = 3578; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000291_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000291_0' done.\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000291_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1471919\r\n",
      "\t\tFILE: Number of bytes written=2879663\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1641636\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=590\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3578\r\n",
      "\t\tMap output materialized bytes=3648\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2463105024\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2938\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000291_0\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000292_0\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:39 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00291-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+2934\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufend = 3574; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000292_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000292_0' done.\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000292_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1476471\r\n",
      "\t\tFILE: Number of bytes written=2883339\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1644570\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=592\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3574\r\n",
      "\t\tMap output materialized bytes=3644\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2463105024\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2934\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000292_0\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000293_0\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:39 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00293-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+2924\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufend = 3564; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000293_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000293_0' done.\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000293_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1481023\r\n",
      "\t\tFILE: Number of bytes written=2887005\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1647494\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=594\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3564\r\n",
      "\t\tMap output materialized bytes=3634\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2463105024\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2924\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000293_0\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000294_0\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:39 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00292-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+2923\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufend = 3563; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000294_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000294_0' done.\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000294_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1485575\r\n",
      "\t\tFILE: Number of bytes written=2890670\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1650417\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=596\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3563\r\n",
      "\t\tMap output materialized bytes=3633\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2463105024\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2923\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000294_0\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000295_0\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:39 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00294-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+2910\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufend = 3550; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000295_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000295_0' done.\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000295_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1490127\r\n",
      "\t\tFILE: Number of bytes written=2894322\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1653327\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=598\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3550\r\n",
      "\t\tMap output materialized bytes=3620\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2463105024\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2910\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000295_0\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000296_0\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:39 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00298-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+2898\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufend = 3538; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000296_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000296_0' done.\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000296_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1494679\r\n",
      "\t\tFILE: Number of bytes written=2897962\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1656225\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=600\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3538\r\n",
      "\t\tMap output materialized bytes=3608\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2463105024\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2898\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000296_0\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000297_0\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:39 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00297-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+2890\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufend = 3530; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000297_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000297_0' done.\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000297_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1499231\r\n",
      "\t\tFILE: Number of bytes written=2901594\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1659115\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=602\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3530\r\n",
      "\t\tMap output materialized bytes=3600\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2463105024\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2890\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000297_0\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000298_0\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:39 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00296-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+2883\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufend = 3523; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000298_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000298_0' done.\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000298_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1503783\r\n",
      "\t\tFILE: Number of bytes written=2905219\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1661998\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=604\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3523\r\n",
      "\t\tMap output materialized bytes=3593\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2463105024\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2883\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000298_0\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000299_0\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:39 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00295-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+2877\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufend = 3517; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000299_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000299_0' done.\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000299_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1508335\r\n",
      "\t\tFILE: Number of bytes written=2908838\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1664875\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=606\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3517\r\n",
      "\t\tMap output materialized bytes=3587\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2463105024\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2877\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000299_0\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000300_0\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:39 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00302-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+2861\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufend = 3501; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000300_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000300_0' done.\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000300_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1512887\r\n",
      "\t\tFILE: Number of bytes written=2912441\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1667736\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=608\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3501\r\n",
      "\t\tMap output materialized bytes=3571\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=2\r\n",
      "\t\tTotal committed heap usage (bytes)=2472542208\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2861\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000300_0\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000301_0\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:39 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00299-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+2857\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufend = 3497; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000301_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000301_0' done.\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000301_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1517439\r\n",
      "\t\tFILE: Number of bytes written=2916040\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1670593\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=610\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3497\r\n",
      "\t\tMap output materialized bytes=3567\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2472542208\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2857\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000301_0\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000302_0\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:39 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00301-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+2855\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufend = 3495; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000302_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000302_0' done.\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000302_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1521991\r\n",
      "\t\tFILE: Number of bytes written=2919637\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1673448\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=612\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3495\r\n",
      "\t\tMap output materialized bytes=3565\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2472542208\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2855\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000302_0\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000303_0\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:39 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00300-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+2850\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufend = 3490; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000303_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000303_0' done.\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000303_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1526543\r\n",
      "\t\tFILE: Number of bytes written=2923229\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1676298\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=614\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3490\r\n",
      "\t\tMap output materialized bytes=3560\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2472542208\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2850\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000303_0\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000304_0\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:39 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00303-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+2837\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufend = 3477; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000304_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000304_0' done.\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000304_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1531095\r\n",
      "\t\tFILE: Number of bytes written=2926808\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1679135\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=616\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3477\r\n",
      "\t\tMap output materialized bytes=3547\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2472542208\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2837\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000304_0\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000305_0\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:39 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00306-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+2823\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufend = 3463; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000305_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000305_0' done.\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000305_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1535647\r\n",
      "\t\tFILE: Number of bytes written=2930373\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1681958\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=618\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3463\r\n",
      "\t\tMap output materialized bytes=3533\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2472542208\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2823\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000305_0\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000306_0\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:39 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00305-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+2820\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufend = 3460; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000306_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000306_0' done.\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000306_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1540199\r\n",
      "\t\tFILE: Number of bytes written=2933935\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1684778\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=620\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3460\r\n",
      "\t\tMap output materialized bytes=3530\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2472542208\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2820\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000306_0\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000307_0\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:39 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00304-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+2818\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufend = 3458; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000307_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000307_0' done.\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000307_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1544751\r\n",
      "\t\tFILE: Number of bytes written=2937495\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1687596\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=622\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3458\r\n",
      "\t\tMap output materialized bytes=3528\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2472542208\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2818\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000307_0\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000308_0\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:39 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00308-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+2797\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufend = 3437; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000308_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000308_0' done.\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000308_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1549303\r\n",
      "\t\tFILE: Number of bytes written=2941034\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1690393\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=624\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3437\r\n",
      "\t\tMap output materialized bytes=3507\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2472542208\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2797\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000308_0\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000309_0\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:39 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00309-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+2796\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufend = 3436; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000309_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000309_0' done.\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000309_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1553855\r\n",
      "\t\tFILE: Number of bytes written=2944572\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1693189\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=626\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3436\r\n",
      "\t\tMap output materialized bytes=3506\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2472542208\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2796\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000309_0\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000310_0\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:39 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00307-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+2793\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufend = 3433; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000310_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000310_0' done.\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000310_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1558407\r\n",
      "\t\tFILE: Number of bytes written=2948107\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1695982\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=628\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3433\r\n",
      "\t\tMap output materialized bytes=3503\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2472542208\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2793\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000310_0\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000311_0\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:39 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00310-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+2783\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufend = 3423; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000311_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000311_0' done.\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000311_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1562959\r\n",
      "\t\tFILE: Number of bytes written=2951632\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1698765\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=630\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3423\r\n",
      "\t\tMap output materialized bytes=3493\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2472542208\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2783\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000311_0\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000312_0\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:39 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00312-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+2766\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufend = 3406; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000312_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000312_0' done.\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000312_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1567511\r\n",
      "\t\tFILE: Number of bytes written=2955140\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1701531\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=632\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3406\r\n",
      "\t\tMap output materialized bytes=3476\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2472542208\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2766\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000312_0\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000313_0\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:39 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00311-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+2760\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufend = 3400; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000313_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000313_0' done.\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000313_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1572063\r\n",
      "\t\tFILE: Number of bytes written=2958642\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1704291\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=634\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3400\r\n",
      "\t\tMap output materialized bytes=3470\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2472542208\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2760\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000313_0\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000314_0\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:39 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00313-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+2749\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufend = 3389; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000314_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000314_0' done.\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000314_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1576615\r\n",
      "\t\tFILE: Number of bytes written=2962133\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1707040\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=636\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3389\r\n",
      "\t\tMap output materialized bytes=3459\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=1\r\n",
      "\t\tTotal committed heap usage (bytes)=2553806848\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2749\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000314_0\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000315_0\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:39 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00314-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+2741\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufend = 3381; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000315_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000315_0' done.\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000315_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1581167\r\n",
      "\t\tFILE: Number of bytes written=2965616\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1709781\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=638\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3381\r\n",
      "\t\tMap output materialized bytes=3451\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2553806848\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2741\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000315_0\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000316_0\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:39 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00315-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+2727\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufend = 3367; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000316_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000316_0' done.\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000316_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1585719\r\n",
      "\t\tFILE: Number of bytes written=2969085\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1712508\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=640\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3367\r\n",
      "\t\tMap output materialized bytes=3437\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2553806848\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2727\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000316_0\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000317_0\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:39 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00317-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+2723\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufend = 3363; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000317_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000317_0' done.\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000317_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1590271\r\n",
      "\t\tFILE: Number of bytes written=2972550\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1715231\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=642\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3363\r\n",
      "\t\tMap output materialized bytes=3433\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2553806848\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2723\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000317_0\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000318_0\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:39 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00316-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+2721\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufend = 3361; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000318_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000318_0' done.\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000318_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1594823\r\n",
      "\t\tFILE: Number of bytes written=2976013\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1717952\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=644\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3361\r\n",
      "\t\tMap output materialized bytes=3431\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2553806848\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2721\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000318_0\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000319_0\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:39 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00318-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+2697\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufend = 3337; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000319_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000319_0' done.\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000319_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1599375\r\n",
      "\t\tFILE: Number of bytes written=2979452\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1720649\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=646\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3337\r\n",
      "\t\tMap output materialized bytes=3407\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2553806848\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2697\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000319_0\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000320_0\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:39 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00319-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+2697\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufend = 3337; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000320_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000320_0' done.\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000320_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1603927\r\n",
      "\t\tFILE: Number of bytes written=2982891\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1723346\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=648\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3337\r\n",
      "\t\tMap output materialized bytes=3407\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2553806848\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2697\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000320_0\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000321_0\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:39 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00320-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+2687\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufend = 3327; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000321_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000321_0' done.\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000321_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1608479\r\n",
      "\t\tFILE: Number of bytes written=2986320\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1726033\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=650\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3327\r\n",
      "\t\tMap output materialized bytes=3397\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2553806848\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2687\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000321_0\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000322_0\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:39 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00322-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+2669\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:39 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: bufstart = 0; bufend = 3309; bufvoid = 104857600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000322_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000322_0' done.\r\n",
      "25/08/24 20:13:39 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000322_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1613031\r\n",
      "\t\tFILE: Number of bytes written=2989731\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1728702\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=652\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3309\r\n",
      "\t\tMap output materialized bytes=3379\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2553806848\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2669\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000322_0\r\n",
      "25/08/24 20:13:39 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000323_0\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:39 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:39 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:39 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00321-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+2666\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: bufstart = 0; bufend = 3306; bufvoid = 104857600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:40 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000323_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:40 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000323_0' done.\r\n",
      "25/08/24 20:13:40 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000323_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1617583\r\n",
      "\t\tFILE: Number of bytes written=2993139\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1731368\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=654\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3306\r\n",
      "\t\tMap output materialized bytes=3376\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2553806848\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2666\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000323_0\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000324_0\r\n",
      "25/08/24 20:13:40 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:40 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:40 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00323-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+2652\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: bufstart = 0; bufend = 3292; bufvoid = 104857600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:40 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000324_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:40 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000324_0' done.\r\n",
      "25/08/24 20:13:40 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000324_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1622135\r\n",
      "\t\tFILE: Number of bytes written=2996533\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1734020\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=656\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3292\r\n",
      "\t\tMap output materialized bytes=3362\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2553806848\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2652\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000324_0\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000325_0\r\n",
      "25/08/24 20:13:40 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:40 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:40 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00324-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+2639\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: bufstart = 0; bufend = 3279; bufvoid = 104857600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:40 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000325_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:40 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000325_0' done.\r\n",
      "25/08/24 20:13:40 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000325_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1626548\r\n",
      "\t\tFILE: Number of bytes written=2999914\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1736659\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=658\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3279\r\n",
      "\t\tMap output materialized bytes=3349\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2553806848\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2639\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000325_0\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000326_0\r\n",
      "25/08/24 20:13:40 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:40 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:40 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00325-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+2631\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: bufstart = 0; bufend = 3271; bufvoid = 104857600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:40 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000326_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:40 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000326_0' done.\r\n",
      "25/08/24 20:13:40 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000326_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1630961\r\n",
      "\t\tFILE: Number of bytes written=3003287\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1739290\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=660\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3271\r\n",
      "\t\tMap output materialized bytes=3341\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2553806848\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2631\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000326_0\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000327_0\r\n",
      "25/08/24 20:13:40 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:40 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:40 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00326-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+2613\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: bufstart = 0; bufend = 3253; bufvoid = 104857600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:40 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000327_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:40 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000327_0' done.\r\n",
      "25/08/24 20:13:40 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000327_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1635374\r\n",
      "\t\tFILE: Number of bytes written=3006642\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1741903\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=662\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3253\r\n",
      "\t\tMap output materialized bytes=3323\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2553806848\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2613\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000327_0\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000328_0\r\n",
      "25/08/24 20:13:40 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:40 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:40 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00327-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+2596\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: bufstart = 0; bufend = 3236; bufvoid = 104857600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:40 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000328_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:40 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000328_0' done.\r\n",
      "25/08/24 20:13:40 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000328_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1639275\r\n",
      "\t\tFILE: Number of bytes written=3009980\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1744499\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=664\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3236\r\n",
      "\t\tMap output materialized bytes=3306\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=2\r\n",
      "\t\tTotal committed heap usage (bytes)=2555379712\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2596\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000328_0\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000329_0\r\n",
      "25/08/24 20:13:40 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:40 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:40 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00328-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+2580\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: bufstart = 0; bufend = 3220; bufvoid = 104857600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:40 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000329_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:40 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000329_0' done.\r\n",
      "25/08/24 20:13:40 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000329_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1643176\r\n",
      "\t\tFILE: Number of bytes written=3013302\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1747079\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=666\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3220\r\n",
      "\t\tMap output materialized bytes=3290\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2555379712\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2580\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000329_0\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000330_0\r\n",
      "25/08/24 20:13:40 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:40 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:40 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00329-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+2571\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: bufstart = 0; bufend = 3211; bufvoid = 104857600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:40 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000330_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:40 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000330_0' done.\r\n",
      "25/08/24 20:13:40 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000330_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1647077\r\n",
      "\t\tFILE: Number of bytes written=3016615\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1749650\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=668\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3211\r\n",
      "\t\tMap output materialized bytes=3281\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2555379712\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2571\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000330_0\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000331_0\r\n",
      "25/08/24 20:13:40 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:40 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:40 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00330-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+2568\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: bufstart = 0; bufend = 3208; bufvoid = 104857600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:40 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000331_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:40 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000331_0' done.\r\n",
      "25/08/24 20:13:40 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000331_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1650978\r\n",
      "\t\tFILE: Number of bytes written=3019925\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1752218\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=670\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3208\r\n",
      "\t\tMap output materialized bytes=3278\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2555379712\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2568\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000331_0\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000332_0\r\n",
      "25/08/24 20:13:40 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:40 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:40 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00331-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+2566\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: bufstart = 0; bufend = 3206; bufvoid = 104857600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:40 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000332_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:40 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000332_0' done.\r\n",
      "25/08/24 20:13:40 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000332_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1654367\r\n",
      "\t\tFILE: Number of bytes written=3023233\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1754784\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=672\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3206\r\n",
      "\t\tMap output materialized bytes=3276\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2555379712\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2566\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000332_0\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000333_0\r\n",
      "25/08/24 20:13:40 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:40 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:40 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00333-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+2538\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: bufstart = 0; bufend = 3178; bufvoid = 104857600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:40 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000333_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:40 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000333_0' done.\r\n",
      "25/08/24 20:13:40 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000333_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1657756\r\n",
      "\t\tFILE: Number of bytes written=3026513\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1757322\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=674\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3178\r\n",
      "\t\tMap output materialized bytes=3248\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2555379712\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2538\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000333_0\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000334_0\r\n",
      "25/08/24 20:13:40 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:40 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:40 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00332-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+2531\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: bufstart = 0; bufend = 3171; bufvoid = 104857600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:40 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000334_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:40 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000334_0' done.\r\n",
      "25/08/24 20:13:40 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000334_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1661145\r\n",
      "\t\tFILE: Number of bytes written=3029786\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1759853\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=676\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3171\r\n",
      "\t\tMap output materialized bytes=3241\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2555379712\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2531\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000334_0\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000335_0\r\n",
      "25/08/24 20:13:40 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:40 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:40 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00334-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+2531\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: bufstart = 0; bufend = 3171; bufvoid = 104857600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:40 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000335_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:40 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000335_0' done.\r\n",
      "25/08/24 20:13:40 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000335_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1664022\r\n",
      "\t\tFILE: Number of bytes written=3033059\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1762384\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=678\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3171\r\n",
      "\t\tMap output materialized bytes=3241\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2555379712\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2531\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000335_0\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000336_0\r\n",
      "25/08/24 20:13:40 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:40 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:40 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00335-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+2517\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: bufstart = 0; bufend = 3157; bufvoid = 104857600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:40 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000336_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:40 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000336_0' done.\r\n",
      "25/08/24 20:13:40 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000336_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1666899\r\n",
      "\t\tFILE: Number of bytes written=3036318\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1764901\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=680\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3157\r\n",
      "\t\tMap output materialized bytes=3227\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2555379712\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2517\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000336_0\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000337_0\r\n",
      "25/08/24 20:13:40 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:40 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:40 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00336-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+2496\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: bufstart = 0; bufend = 3136; bufvoid = 104857600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:40 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000337_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:40 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000337_0' done.\r\n",
      "25/08/24 20:13:40 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000337_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1669776\r\n",
      "\t\tFILE: Number of bytes written=3039556\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1767397\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=682\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3136\r\n",
      "\t\tMap output materialized bytes=3206\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2555379712\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2496\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000337_0\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000338_0\r\n",
      "25/08/24 20:13:40 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:40 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:40 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00337-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+2479\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: bufstart = 0; bufend = 3119; bufvoid = 104857600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:40 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000338_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:40 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000338_0' done.\r\n",
      "25/08/24 20:13:40 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000338_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1672141\r\n",
      "\t\tFILE: Number of bytes written=3042777\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1769876\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=684\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3119\r\n",
      "\t\tMap output materialized bytes=3189\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2555379712\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2479\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000338_0\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000339_0\r\n",
      "25/08/24 20:13:40 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:40 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:40 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00338-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+2457\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: bufstart = 0; bufend = 3097; bufvoid = 104857600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:40 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000339_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:40 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000339_0' done.\r\n",
      "25/08/24 20:13:40 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000339_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1674506\r\n",
      "\t\tFILE: Number of bytes written=3045976\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1772333\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=686\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3097\r\n",
      "\t\tMap output materialized bytes=3167\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2555379712\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2457\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000339_0\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000340_0\r\n",
      "25/08/24 20:13:40 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:40 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:40 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00339-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+2429\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: bufstart = 0; bufend = 3069; bufvoid = 104857600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:40 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000340_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:40 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000340_0' done.\r\n",
      "25/08/24 20:13:40 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000340_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1676871\r\n",
      "\t\tFILE: Number of bytes written=3049147\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1774762\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=688\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3069\r\n",
      "\t\tMap output materialized bytes=3139\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2555379712\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2429\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000340_0\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000341_0\r\n",
      "25/08/24 20:13:40 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:40 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:40 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00340-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+2420\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: bufstart = 0; bufend = 3060; bufvoid = 104857600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:40 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000341_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:40 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000341_0' done.\r\n",
      "25/08/24 20:13:40 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000341_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1678724\r\n",
      "\t\tFILE: Number of bytes written=3052309\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1777182\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=690\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3060\r\n",
      "\t\tMap output materialized bytes=3130\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2555379712\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2420\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000341_0\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000342_0\r\n",
      "25/08/24 20:13:40 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:40 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:40 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00341-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+2396\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: bufstart = 0; bufend = 3036; bufvoid = 104857600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:40 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000342_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:40 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000342_0' done.\r\n",
      "25/08/24 20:13:40 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000342_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1680577\r\n",
      "\t\tFILE: Number of bytes written=3055447\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1779578\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=692\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3036\r\n",
      "\t\tMap output materialized bytes=3106\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2555379712\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2396\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000342_0\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000343_0\r\n",
      "25/08/24 20:13:40 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:40 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:40 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00342-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+2386\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: bufstart = 0; bufend = 3026; bufvoid = 104857600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:40 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000343_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:40 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000343_0' done.\r\n",
      "25/08/24 20:13:40 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000343_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1682430\r\n",
      "\t\tFILE: Number of bytes written=3058575\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1781964\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=694\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=3026\r\n",
      "\t\tMap output materialized bytes=3096\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=2\r\n",
      "\t\tTotal committed heap usage (bytes)=2634022912\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2386\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000343_0\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000344_0\r\n",
      "25/08/24 20:13:40 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:40 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:40 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00343-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+2343\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: bufstart = 0; bufend = 2983; bufvoid = 104857600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:40 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000344_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:40 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000344_0' done.\r\n",
      "25/08/24 20:13:40 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000344_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1683771\r\n",
      "\t\tFILE: Number of bytes written=3061660\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1784307\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=696\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=2983\r\n",
      "\t\tMap output materialized bytes=3053\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2634022912\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2343\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000344_0\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000345_0\r\n",
      "25/08/24 20:13:40 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:40 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:40 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00344-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+2316\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: bufstart = 0; bufend = 2956; bufvoid = 104857600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:40 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000345_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:40 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000345_0' done.\r\n",
      "25/08/24 20:13:40 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000345_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1685112\r\n",
      "\t\tFILE: Number of bytes written=3064718\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1786623\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=698\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=2956\r\n",
      "\t\tMap output materialized bytes=3026\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2634022912\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2316\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000345_0\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000346_0\r\n",
      "25/08/24 20:13:40 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:40 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:40 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00345-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+2276\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: bufstart = 0; bufend = 2916; bufvoid = 104857600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:40 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000346_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:40 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000346_0' done.\r\n",
      "25/08/24 20:13:40 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000346_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1686453\r\n",
      "\t\tFILE: Number of bytes written=3067736\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1788899\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=700\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=2916\r\n",
      "\t\tMap output materialized bytes=2986\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2634022912\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2276\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000346_0\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000347_0\r\n",
      "25/08/24 20:13:40 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:40 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:40 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00346-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+2222\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: Records R/W=32/1\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: bufstart = 0; bufend = 2862; bufvoid = 104857600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:40 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000347_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: Records R/W=32/1\r\n",
      "25/08/24 20:13:40 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000347_0' done.\r\n",
      "25/08/24 20:13:40 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000347_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1687282\r\n",
      "\t\tFILE: Number of bytes written=3070700\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1791121\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=702\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=32\r\n",
      "\t\tMap output records=32\r\n",
      "\t\tMap output bytes=2862\r\n",
      "\t\tMap output materialized bytes=2932\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=32\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2634022912\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=2222\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000347_0\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_m_000348_0\r\n",
      "25/08/24 20:13:40 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:40 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:40 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Processing split: hdfs://localhost:54310/user/ubuntu/dataset_preprocessed/part-00347-8d7047aa-8a5a-485a-b915-475bbd473e88-c000.csv:0+1543\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: numReduceTasks: 1\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: soft limit at 83886080\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/mapper_join.py]\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: Records R/W=23/1\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: \r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Starting flush of map output\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Spilling map output\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: bufstart = 0; bufend = 2003; bufvoid = 104857600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214308(104857232); length = 89/6553600\r\n",
      "25/08/24 20:13:40 INFO mapred.MapTask: Finished spill 0\r\n",
      "25/08/24 20:13:40 INFO mapred.Task: Task:attempt_local1384700255_0001_m_000348_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: Records R/W=23/1\r\n",
      "25/08/24 20:13:40 INFO mapred.Task: Task 'attempt_local1384700255_0001_m_000348_0' done.\r\n",
      "25/08/24 20:13:40 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_m_000348_0: Counters: 22\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=1688111\r\n",
      "\t\tFILE: Number of bytes written=3072787\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1792664\r\n",
      "\t\tHDFS: Number of bytes written=0\r\n",
      "\t\tHDFS: Number of read operations=704\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=1\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=23\r\n",
      "\t\tMap output records=23\r\n",
      "\t\tMap output bytes=2003\r\n",
      "\t\tMap output materialized bytes=2055\r\n",
      "\t\tInput split bytes=164\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=23\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2634022912\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=1543\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_m_000348_0\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: map task executor complete.\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: Waiting for reduce tasks\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: Starting task: attempt_local1384700255_0001_r_000000_0\r\n",
      "25/08/24 20:13:40 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\r\n",
      "25/08/24 20:13:40 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "25/08/24 20:13:40 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "25/08/24 20:13:40 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@763e3f04\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: The max number of bytes for a single in-memory shuffle cannot be larger than Integer.MAX_VALUE. Setting it to Integer.MAX_VALUE\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=10690022400, maxSingleShuffleLimit=2147483647, mergeThreshold=7055415296, ioSortFactor=10, memToMemMergeOutputsThreshold=10\r\n",
      "25/08/24 20:13:40 INFO reduce.EventFetcher: attempt_local1384700255_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000052_0 decomp: 5308 len: 5312 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 5308 bytes from map-output for attempt_local1384700255_0001_m_000052_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5308, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->5308\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000257_0 decomp: 3910 len: 3914 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3910 bytes from map-output for attempt_local1384700255_0001_m_000257_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3910, inMemoryMapOutputs.size() -> 2, commitMemory -> 5308, usedMemory ->9218\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000155_0 decomp: 4576 len: 4580 to MEMORY\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4576 bytes from map-output for attempt_local1384700255_0001_m_000155_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4576, inMemoryMapOutputs.size() -> 3, commitMemory -> 9218, usedMemory ->13794\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000053_0 decomp: 5290 len: 5294 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 5290 bytes from map-output for attempt_local1384700255_0001_m_000053_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5290, inMemoryMapOutputs.size() -> 4, commitMemory -> 13794, usedMemory ->19084\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000258_0 decomp: 3885 len: 3889 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3885 bytes from map-output for attempt_local1384700255_0001_m_000258_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3885, inMemoryMapOutputs.size() -> 5, commitMemory -> 19084, usedMemory ->22969\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000156_0 decomp: 4566 len: 4570 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4566 bytes from map-output for attempt_local1384700255_0001_m_000156_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4566, inMemoryMapOutputs.size() -> 6, commitMemory -> 22969, usedMemory ->27535\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000054_0 decomp: 5303 len: 5307 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 5303 bytes from map-output for attempt_local1384700255_0001_m_000054_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5303, inMemoryMapOutputs.size() -> 7, commitMemory -> 27535, usedMemory ->32838\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000259_0 decomp: 3883 len: 3887 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3883 bytes from map-output for attempt_local1384700255_0001_m_000259_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3883, inMemoryMapOutputs.size() -> 8, commitMemory -> 32838, usedMemory ->36721\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000157_0 decomp: 4570 len: 4574 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4570 bytes from map-output for attempt_local1384700255_0001_m_000157_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4570, inMemoryMapOutputs.size() -> 9, commitMemory -> 36721, usedMemory ->41291\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000055_0 decomp: 5274 len: 5278 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 5274 bytes from map-output for attempt_local1384700255_0001_m_000055_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5274, inMemoryMapOutputs.size() -> 10, commitMemory -> 41291, usedMemory ->46565\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000049_0 decomp: 5348 len: 5352 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 5348 bytes from map-output for attempt_local1384700255_0001_m_000049_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5348, inMemoryMapOutputs.size() -> 11, commitMemory -> 46565, usedMemory ->51913\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000254_0 decomp: 3914 len: 3918 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3914 bytes from map-output for attempt_local1384700255_0001_m_000254_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3914, inMemoryMapOutputs.size() -> 12, commitMemory -> 51913, usedMemory ->55827\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000152_0 decomp: 4583 len: 4587 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4583 bytes from map-output for attempt_local1384700255_0001_m_000152_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4583, inMemoryMapOutputs.size() -> 13, commitMemory -> 55827, usedMemory ->60410\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000050_0 decomp: 5315 len: 5319 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 5315 bytes from map-output for attempt_local1384700255_0001_m_000050_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5315, inMemoryMapOutputs.size() -> 14, commitMemory -> 60410, usedMemory ->65725\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000255_0 decomp: 3912 len: 3916 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3912 bytes from map-output for attempt_local1384700255_0001_m_000255_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3912, inMemoryMapOutputs.size() -> 15, commitMemory -> 65725, usedMemory ->69637\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000153_0 decomp: 4586 len: 4590 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4586 bytes from map-output for attempt_local1384700255_0001_m_000153_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4586, inMemoryMapOutputs.size() -> 16, commitMemory -> 69637, usedMemory ->74223\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000051_0 decomp: 5314 len: 5318 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 5314 bytes from map-output for attempt_local1384700255_0001_m_000051_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5314, inMemoryMapOutputs.size() -> 17, commitMemory -> 74223, usedMemory ->79537\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000256_0 decomp: 3912 len: 3916 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3912 bytes from map-output for attempt_local1384700255_0001_m_000256_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3912, inMemoryMapOutputs.size() -> 18, commitMemory -> 79537, usedMemory ->83449\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000154_0 decomp: 4579 len: 4583 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4579 bytes from map-output for attempt_local1384700255_0001_m_000154_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4579, inMemoryMapOutputs.size() -> 19, commitMemory -> 83449, usedMemory ->88028\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000161_0 decomp: 4553 len: 4557 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4553 bytes from map-output for attempt_local1384700255_0001_m_000161_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4553, inMemoryMapOutputs.size() -> 20, commitMemory -> 88028, usedMemory ->92581\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000059_0 decomp: 5228 len: 5232 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 5228 bytes from map-output for attempt_local1384700255_0001_m_000059_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5228, inMemoryMapOutputs.size() -> 21, commitMemory -> 92581, usedMemory ->97809\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000264_0 decomp: 3849 len: 3853 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3849 bytes from map-output for attempt_local1384700255_0001_m_000264_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3849, inMemoryMapOutputs.size() -> 22, commitMemory -> 97809, usedMemory ->101658\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000162_0 decomp: 4548 len: 4552 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4548 bytes from map-output for attempt_local1384700255_0001_m_000162_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4548, inMemoryMapOutputs.size() -> 23, commitMemory -> 101658, usedMemory ->106206\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000060_0 decomp: 5215 len: 5219 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 5215 bytes from map-output for attempt_local1384700255_0001_m_000060_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5215, inMemoryMapOutputs.size() -> 24, commitMemory -> 106206, usedMemory ->111421\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000265_0 decomp: 3848 len: 3852 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3848 bytes from map-output for attempt_local1384700255_0001_m_000265_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3848, inMemoryMapOutputs.size() -> 25, commitMemory -> 111421, usedMemory ->115269\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000163_0 decomp: 4529 len: 4533 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4529 bytes from map-output for attempt_local1384700255_0001_m_000163_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4529, inMemoryMapOutputs.size() -> 26, commitMemory -> 115269, usedMemory ->119798\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000061_0 decomp: 5200 len: 5204 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 5200 bytes from map-output for attempt_local1384700255_0001_m_000061_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5200, inMemoryMapOutputs.size() -> 27, commitMemory -> 119798, usedMemory ->124998\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000266_0 decomp: 3838 len: 3842 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3838 bytes from map-output for attempt_local1384700255_0001_m_000266_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3838, inMemoryMapOutputs.size() -> 28, commitMemory -> 124998, usedMemory ->128836\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000260_0 decomp: 3881 len: 3885 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3881 bytes from map-output for attempt_local1384700255_0001_m_000260_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3881, inMemoryMapOutputs.size() -> 29, commitMemory -> 128836, usedMemory ->132717\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000158_0 decomp: 4562 len: 4566 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4562 bytes from map-output for attempt_local1384700255_0001_m_000158_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4562, inMemoryMapOutputs.size() -> 30, commitMemory -> 132717, usedMemory ->137279\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000056_0 decomp: 5265 len: 5269 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 5265 bytes from map-output for attempt_local1384700255_0001_m_000056_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5265, inMemoryMapOutputs.size() -> 31, commitMemory -> 137279, usedMemory ->142544\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000261_0 decomp: 3876 len: 3880 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3876 bytes from map-output for attempt_local1384700255_0001_m_000261_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3876, inMemoryMapOutputs.size() -> 32, commitMemory -> 142544, usedMemory ->146420\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000159_0 decomp: 4558 len: 4562 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4558 bytes from map-output for attempt_local1384700255_0001_m_000159_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4558, inMemoryMapOutputs.size() -> 33, commitMemory -> 146420, usedMemory ->150978\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000057_0 decomp: 5271 len: 5275 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 5271 bytes from map-output for attempt_local1384700255_0001_m_000057_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5271, inMemoryMapOutputs.size() -> 34, commitMemory -> 150978, usedMemory ->156249\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000262_0 decomp: 3858 len: 3862 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3858 bytes from map-output for attempt_local1384700255_0001_m_000262_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3858, inMemoryMapOutputs.size() -> 35, commitMemory -> 156249, usedMemory ->160107\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000160_0 decomp: 4559 len: 4563 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4559 bytes from map-output for attempt_local1384700255_0001_m_000160_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4559, inMemoryMapOutputs.size() -> 36, commitMemory -> 160107, usedMemory ->164666\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000058_0 decomp: 5240 len: 5244 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 5240 bytes from map-output for attempt_local1384700255_0001_m_000058_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5240, inMemoryMapOutputs.size() -> 37, commitMemory -> 164666, usedMemory ->169906\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000263_0 decomp: 3852 len: 3856 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3852 bytes from map-output for attempt_local1384700255_0001_m_000263_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3852, inMemoryMapOutputs.size() -> 38, commitMemory -> 169906, usedMemory ->173758\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000244_0 decomp: 4001 len: 4005 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4001 bytes from map-output for attempt_local1384700255_0001_m_000244_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4001, inMemoryMapOutputs.size() -> 39, commitMemory -> 173758, usedMemory ->177759\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000142_0 decomp: 4639 len: 4643 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4639 bytes from map-output for attempt_local1384700255_0001_m_000142_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4639, inMemoryMapOutputs.size() -> 40, commitMemory -> 177759, usedMemory ->182398\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000347_0 decomp: 2928 len: 2932 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 2928 bytes from map-output for attempt_local1384700255_0001_m_000347_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2928, inMemoryMapOutputs.size() -> 41, commitMemory -> 182398, usedMemory ->185326\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000040_0 decomp: 5482 len: 5486 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 5482 bytes from map-output for attempt_local1384700255_0001_m_000040_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5482, inMemoryMapOutputs.size() -> 42, commitMemory -> 185326, usedMemory ->190808\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000245_0 decomp: 3981 len: 3985 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3981 bytes from map-output for attempt_local1384700255_0001_m_000245_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3981, inMemoryMapOutputs.size() -> 43, commitMemory -> 190808, usedMemory ->194789\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000143_0 decomp: 4639 len: 4643 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4639 bytes from map-output for attempt_local1384700255_0001_m_000143_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4639, inMemoryMapOutputs.size() -> 44, commitMemory -> 194789, usedMemory ->199428\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000348_0 decomp: 2051 len: 2055 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 2051 bytes from map-output for attempt_local1384700255_0001_m_000348_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2051, inMemoryMapOutputs.size() -> 45, commitMemory -> 199428, usedMemory ->201479\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000041_0 decomp: 5478 len: 5482 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 5478 bytes from map-output for attempt_local1384700255_0001_m_000041_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5478, inMemoryMapOutputs.size() -> 46, commitMemory -> 201479, usedMemory ->206957\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000246_0 decomp: 3977 len: 3981 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3977 bytes from map-output for attempt_local1384700255_0001_m_000246_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3977, inMemoryMapOutputs.size() -> 47, commitMemory -> 206957, usedMemory ->210934\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000144_0 decomp: 4622 len: 4626 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4622 bytes from map-output for attempt_local1384700255_0001_m_000144_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4622, inMemoryMapOutputs.size() -> 48, commitMemory -> 210934, usedMemory ->215556\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000042_0 decomp: 5460 len: 5464 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 5460 bytes from map-output for attempt_local1384700255_0001_m_000042_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5460, inMemoryMapOutputs.size() -> 49, commitMemory -> 215556, usedMemory ->221016\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000247_0 decomp: 3975 len: 3979 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3975 bytes from map-output for attempt_local1384700255_0001_m_000247_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3975, inMemoryMapOutputs.size() -> 50, commitMemory -> 221016, usedMemory ->224991\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000036_0 decomp: 5550 len: 5554 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 5550 bytes from map-output for attempt_local1384700255_0001_m_000036_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5550, inMemoryMapOutputs.size() -> 51, commitMemory -> 224991, usedMemory ->230541\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000241_0 decomp: 4004 len: 4008 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4004 bytes from map-output for attempt_local1384700255_0001_m_000241_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4004, inMemoryMapOutputs.size() -> 52, commitMemory -> 230541, usedMemory ->234545\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000139_0 decomp: 4656 len: 4660 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4656 bytes from map-output for attempt_local1384700255_0001_m_000139_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4656, inMemoryMapOutputs.size() -> 53, commitMemory -> 234545, usedMemory ->239201\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000344_0 decomp: 3049 len: 3053 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3049 bytes from map-output for attempt_local1384700255_0001_m_000344_0\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3049, inMemoryMapOutputs.size() -> 54, commitMemory -> 239201, usedMemory ->242250\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000037_0 decomp: 5558 len: 5562 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 5558 bytes from map-output for attempt_local1384700255_0001_m_000037_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5558, inMemoryMapOutputs.size() -> 55, commitMemory -> 242250, usedMemory ->247808\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000242_0 decomp: 4003 len: 4007 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4003 bytes from map-output for attempt_local1384700255_0001_m_000242_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4003, inMemoryMapOutputs.size() -> 56, commitMemory -> 247808, usedMemory ->251811\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000140_0 decomp: 4656 len: 4660 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4656 bytes from map-output for attempt_local1384700255_0001_m_000140_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4656, inMemoryMapOutputs.size() -> 57, commitMemory -> 251811, usedMemory ->256467\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000345_0 decomp: 3022 len: 3026 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3022 bytes from map-output for attempt_local1384700255_0001_m_000345_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3022, inMemoryMapOutputs.size() -> 58, commitMemory -> 256467, usedMemory ->259489\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000038_0 decomp: 5521 len: 5525 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 5521 bytes from map-output for attempt_local1384700255_0001_m_000038_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5521, inMemoryMapOutputs.size() -> 59, commitMemory -> 259489, usedMemory ->265010\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000243_0 decomp: 4003 len: 4007 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4003 bytes from map-output for attempt_local1384700255_0001_m_000243_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4003, inMemoryMapOutputs.size() -> 60, commitMemory -> 265010, usedMemory ->269013\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000141_0 decomp: 4645 len: 4649 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4645 bytes from map-output for attempt_local1384700255_0001_m_000141_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4645, inMemoryMapOutputs.size() -> 61, commitMemory -> 269013, usedMemory ->273658\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000346_0 decomp: 2982 len: 2986 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 2982 bytes from map-output for attempt_local1384700255_0001_m_000346_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2982, inMemoryMapOutputs.size() -> 62, commitMemory -> 273658, usedMemory ->276640\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000039_0 decomp: 5494 len: 5498 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 5494 bytes from map-output for attempt_local1384700255_0001_m_000039_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5494, inMemoryMapOutputs.size() -> 63, commitMemory -> 276640, usedMemory ->282134\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000148_0 decomp: 4606 len: 4610 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4606 bytes from map-output for attempt_local1384700255_0001_m_000148_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4606, inMemoryMapOutputs.size() -> 64, commitMemory -> 282134, usedMemory ->286740\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000046_0 decomp: 5364 len: 5368 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 5364 bytes from map-output for attempt_local1384700255_0001_m_000046_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5364, inMemoryMapOutputs.size() -> 65, commitMemory -> 286740, usedMemory ->292104\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000251_0 decomp: 3951 len: 3955 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3951 bytes from map-output for attempt_local1384700255_0001_m_000251_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3951, inMemoryMapOutputs.size() -> 66, commitMemory -> 292104, usedMemory ->296055\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000149_0 decomp: 4592 len: 4596 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4592 bytes from map-output for attempt_local1384700255_0001_m_000149_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4592, inMemoryMapOutputs.size() -> 67, commitMemory -> 296055, usedMemory ->300647\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000047_0 decomp: 5343 len: 5347 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 5343 bytes from map-output for attempt_local1384700255_0001_m_000047_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5343, inMemoryMapOutputs.size() -> 68, commitMemory -> 300647, usedMemory ->305990\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000252_0 decomp: 3945 len: 3949 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3945 bytes from map-output for attempt_local1384700255_0001_m_000252_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3945, inMemoryMapOutputs.size() -> 69, commitMemory -> 305990, usedMemory ->309935\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000150_0 decomp: 4589 len: 4593 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4589 bytes from map-output for attempt_local1384700255_0001_m_000150_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4589, inMemoryMapOutputs.size() -> 70, commitMemory -> 309935, usedMemory ->314524\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000048_0 decomp: 5348 len: 5352 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 5348 bytes from map-output for attempt_local1384700255_0001_m_000048_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5348, inMemoryMapOutputs.size() -> 71, commitMemory -> 314524, usedMemory ->319872\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000253_0 decomp: 3937 len: 3941 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3937 bytes from map-output for attempt_local1384700255_0001_m_000253_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3937, inMemoryMapOutputs.size() -> 72, commitMemory -> 319872, usedMemory ->323809\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000151_0 decomp: 4589 len: 4593 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4589 bytes from map-output for attempt_local1384700255_0001_m_000151_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4589, inMemoryMapOutputs.size() -> 73, commitMemory -> 323809, usedMemory ->328398\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000145_0 decomp: 4622 len: 4626 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4622 bytes from map-output for attempt_local1384700255_0001_m_000145_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4622, inMemoryMapOutputs.size() -> 74, commitMemory -> 328398, usedMemory ->333020\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000043_0 decomp: 5444 len: 5448 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 5444 bytes from map-output for attempt_local1384700255_0001_m_000043_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5444, inMemoryMapOutputs.size() -> 75, commitMemory -> 333020, usedMemory ->338464\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000248_0 decomp: 3965 len: 3969 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3965 bytes from map-output for attempt_local1384700255_0001_m_000248_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3965, inMemoryMapOutputs.size() -> 76, commitMemory -> 338464, usedMemory ->342429\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000146_0 decomp: 4612 len: 4616 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4612 bytes from map-output for attempt_local1384700255_0001_m_000146_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4612, inMemoryMapOutputs.size() -> 77, commitMemory -> 342429, usedMemory ->347041\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000044_0 decomp: 5424 len: 5428 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 5424 bytes from map-output for attempt_local1384700255_0001_m_000044_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5424, inMemoryMapOutputs.size() -> 78, commitMemory -> 347041, usedMemory ->352465\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000249_0 decomp: 3962 len: 3966 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3962 bytes from map-output for attempt_local1384700255_0001_m_000249_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3962, inMemoryMapOutputs.size() -> 79, commitMemory -> 352465, usedMemory ->356427\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000147_0 decomp: 4606 len: 4610 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4606 bytes from map-output for attempt_local1384700255_0001_m_000147_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4606, inMemoryMapOutputs.size() -> 80, commitMemory -> 356427, usedMemory ->361033\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000045_0 decomp: 5413 len: 5417 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 5413 bytes from map-output for attempt_local1384700255_0001_m_000045_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5413, inMemoryMapOutputs.size() -> 81, commitMemory -> 361033, usedMemory ->366446\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000250_0 decomp: 3954 len: 3958 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3954 bytes from map-output for attempt_local1384700255_0001_m_000250_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3954, inMemoryMapOutputs.size() -> 82, commitMemory -> 366446, usedMemory ->370400\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000180_0 decomp: 4404 len: 4408 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4404 bytes from map-output for attempt_local1384700255_0001_m_000180_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4404, inMemoryMapOutputs.size() -> 83, commitMemory -> 370400, usedMemory ->374804\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000078_0 decomp: 5106 len: 5110 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 5106 bytes from map-output for attempt_local1384700255_0001_m_000078_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5106, inMemoryMapOutputs.size() -> 84, commitMemory -> 374804, usedMemory ->379910\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000283_0 decomp: 3719 len: 3723 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3719 bytes from map-output for attempt_local1384700255_0001_m_000283_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3719, inMemoryMapOutputs.size() -> 85, commitMemory -> 379910, usedMemory ->383629\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000181_0 decomp: 4396 len: 4400 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4396 bytes from map-output for attempt_local1384700255_0001_m_000181_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4396, inMemoryMapOutputs.size() -> 86, commitMemory -> 383629, usedMemory ->388025\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000079_0 decomp: 5092 len: 5096 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 5092 bytes from map-output for attempt_local1384700255_0001_m_000079_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5092, inMemoryMapOutputs.size() -> 87, commitMemory -> 388025, usedMemory ->393117\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000284_0 decomp: 3709 len: 3713 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3709 bytes from map-output for attempt_local1384700255_0001_m_000284_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3709, inMemoryMapOutputs.size() -> 88, commitMemory -> 393117, usedMemory ->396826\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000182_0 decomp: 4394 len: 4398 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4394 bytes from map-output for attempt_local1384700255_0001_m_000182_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4394, inMemoryMapOutputs.size() -> 89, commitMemory -> 396826, usedMemory ->401220\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000080_0 decomp: 5085 len: 5089 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 5085 bytes from map-output for attempt_local1384700255_0001_m_000080_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5085, inMemoryMapOutputs.size() -> 90, commitMemory -> 401220, usedMemory ->406305\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000285_0 decomp: 3691 len: 3695 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3691 bytes from map-output for attempt_local1384700255_0001_m_000285_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3691, inMemoryMapOutputs.size() -> 91, commitMemory -> 406305, usedMemory ->409996\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000183_0 decomp: 4393 len: 4397 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4393 bytes from map-output for attempt_local1384700255_0001_m_000183_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4393, inMemoryMapOutputs.size() -> 92, commitMemory -> 409996, usedMemory ->414389\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000177_0 decomp: 4426 len: 4430 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4426 bytes from map-output for attempt_local1384700255_0001_m_000177_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4426, inMemoryMapOutputs.size() -> 93, commitMemory -> 414389, usedMemory ->418815\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000075_0 decomp: 5112 len: 5116 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 5112 bytes from map-output for attempt_local1384700255_0001_m_000075_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5112, inMemoryMapOutputs.size() -> 94, commitMemory -> 418815, usedMemory ->423927\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000280_0 decomp: 3728 len: 3732 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3728 bytes from map-output for attempt_local1384700255_0001_m_000280_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3728, inMemoryMapOutputs.size() -> 95, commitMemory -> 423927, usedMemory ->427655\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000178_0 decomp: 4421 len: 4425 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4421 bytes from map-output for attempt_local1384700255_0001_m_000178_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4421, inMemoryMapOutputs.size() -> 96, commitMemory -> 427655, usedMemory ->432076\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000076_0 decomp: 5120 len: 5124 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 5120 bytes from map-output for attempt_local1384700255_0001_m_000076_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5120, inMemoryMapOutputs.size() -> 97, commitMemory -> 432076, usedMemory ->437196\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000281_0 decomp: 3726 len: 3730 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3726 bytes from map-output for attempt_local1384700255_0001_m_000281_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3726, inMemoryMapOutputs.size() -> 98, commitMemory -> 437196, usedMemory ->440922\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000179_0 decomp: 4417 len: 4421 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4417 bytes from map-output for attempt_local1384700255_0001_m_000179_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4417, inMemoryMapOutputs.size() -> 99, commitMemory -> 440922, usedMemory ->445339\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000077_0 decomp: 5104 len: 5108 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 5104 bytes from map-output for attempt_local1384700255_0001_m_000077_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5104, inMemoryMapOutputs.size() -> 100, commitMemory -> 445339, usedMemory ->450443\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000282_0 decomp: 3725 len: 3729 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3725 bytes from map-output for attempt_local1384700255_0001_m_000282_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3725, inMemoryMapOutputs.size() -> 101, commitMemory -> 450443, usedMemory ->454168\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000084_0 decomp: 5074 len: 5078 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 5074 bytes from map-output for attempt_local1384700255_0001_m_000084_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5074, inMemoryMapOutputs.size() -> 102, commitMemory -> 454168, usedMemory ->459242\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000289_0 decomp: 3651 len: 3655 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3651 bytes from map-output for attempt_local1384700255_0001_m_000289_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3651, inMemoryMapOutputs.size() -> 103, commitMemory -> 459242, usedMemory ->462893\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000187_0 decomp: 4366 len: 4370 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4366 bytes from map-output for attempt_local1384700255_0001_m_000187_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4366, inMemoryMapOutputs.size() -> 104, commitMemory -> 462893, usedMemory ->467259\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000085_0 decomp: 5063 len: 5067 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 5063 bytes from map-output for attempt_local1384700255_0001_m_000085_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5063, inMemoryMapOutputs.size() -> 105, commitMemory -> 467259, usedMemory ->472322\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000290_0 decomp: 3648 len: 3652 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3648 bytes from map-output for attempt_local1384700255_0001_m_000290_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3648, inMemoryMapOutputs.size() -> 106, commitMemory -> 472322, usedMemory ->475970\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000188_0 decomp: 4362 len: 4366 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4362 bytes from map-output for attempt_local1384700255_0001_m_000188_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4362, inMemoryMapOutputs.size() -> 107, commitMemory -> 475970, usedMemory ->480332\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000086_0 decomp: 5058 len: 5062 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 5058 bytes from map-output for attempt_local1384700255_0001_m_000086_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5058, inMemoryMapOutputs.size() -> 108, commitMemory -> 480332, usedMemory ->485390\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000291_0 decomp: 3644 len: 3648 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3644 bytes from map-output for attempt_local1384700255_0001_m_000291_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3644, inMemoryMapOutputs.size() -> 109, commitMemory -> 485390, usedMemory ->489034\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000189_0 decomp: 4359 len: 4363 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4359 bytes from map-output for attempt_local1384700255_0001_m_000189_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4359, inMemoryMapOutputs.size() -> 110, commitMemory -> 489034, usedMemory ->493393\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000087_0 decomp: 5038 len: 5042 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 5038 bytes from map-output for attempt_local1384700255_0001_m_000087_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5038, inMemoryMapOutputs.size() -> 111, commitMemory -> 493393, usedMemory ->498431\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000081_0 decomp: 5083 len: 5087 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 5083 bytes from map-output for attempt_local1384700255_0001_m_000081_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5083, inMemoryMapOutputs.size() -> 112, commitMemory -> 498431, usedMemory ->503514\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000286_0 decomp: 3691 len: 3695 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3691 bytes from map-output for attempt_local1384700255_0001_m_000286_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3691, inMemoryMapOutputs.size() -> 113, commitMemory -> 503514, usedMemory ->507205\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000184_0 decomp: 4389 len: 4393 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4389 bytes from map-output for attempt_local1384700255_0001_m_000184_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4389, inMemoryMapOutputs.size() -> 114, commitMemory -> 507205, usedMemory ->511594\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000082_0 decomp: 5074 len: 5078 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 5074 bytes from map-output for attempt_local1384700255_0001_m_000082_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5074, inMemoryMapOutputs.size() -> 115, commitMemory -> 511594, usedMemory ->516668\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000287_0 decomp: 3686 len: 3690 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3686 bytes from map-output for attempt_local1384700255_0001_m_000287_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3686, inMemoryMapOutputs.size() -> 116, commitMemory -> 516668, usedMemory ->520354\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000185_0 decomp: 4379 len: 4383 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4379 bytes from map-output for attempt_local1384700255_0001_m_000185_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4379, inMemoryMapOutputs.size() -> 117, commitMemory -> 520354, usedMemory ->524733\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000083_0 decomp: 5077 len: 5081 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 5077 bytes from map-output for attempt_local1384700255_0001_m_000083_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5077, inMemoryMapOutputs.size() -> 118, commitMemory -> 524733, usedMemory ->529810\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000288_0 decomp: 3680 len: 3684 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3680 bytes from map-output for attempt_local1384700255_0001_m_000288_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3680, inMemoryMapOutputs.size() -> 119, commitMemory -> 529810, usedMemory ->533490\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000186_0 decomp: 4380 len: 4384 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4380 bytes from map-output for attempt_local1384700255_0001_m_000186_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4380, inMemoryMapOutputs.size() -> 120, commitMemory -> 533490, usedMemory ->537870\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000065_0 decomp: 5172 len: 5176 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 5172 bytes from map-output for attempt_local1384700255_0001_m_000065_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5172, inMemoryMapOutputs.size() -> 121, commitMemory -> 537870, usedMemory ->543042\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000270_0 decomp: 3805 len: 3809 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3805 bytes from map-output for attempt_local1384700255_0001_m_000270_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3805, inMemoryMapOutputs.size() -> 122, commitMemory -> 543042, usedMemory ->546847\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000168_0 decomp: 4497 len: 4501 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4497 bytes from map-output for attempt_local1384700255_0001_m_000168_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4497, inMemoryMapOutputs.size() -> 123, commitMemory -> 546847, usedMemory ->551344\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000066_0 decomp: 5170 len: 5174 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 5170 bytes from map-output for attempt_local1384700255_0001_m_000066_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5170, inMemoryMapOutputs.size() -> 124, commitMemory -> 551344, usedMemory ->556514\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000271_0 decomp: 3801 len: 3805 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3801 bytes from map-output for attempt_local1384700255_0001_m_000271_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3801, inMemoryMapOutputs.size() -> 125, commitMemory -> 556514, usedMemory ->560315\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000169_0 decomp: 4487 len: 4491 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4487 bytes from map-output for attempt_local1384700255_0001_m_000169_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4487, inMemoryMapOutputs.size() -> 126, commitMemory -> 560315, usedMemory ->564802\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000067_0 decomp: 5163 len: 5167 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 5163 bytes from map-output for attempt_local1384700255_0001_m_000067_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5163, inMemoryMapOutputs.size() -> 127, commitMemory -> 564802, usedMemory ->569965\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000272_0 decomp: 3792 len: 3796 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3792 bytes from map-output for attempt_local1384700255_0001_m_000272_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3792, inMemoryMapOutputs.size() -> 128, commitMemory -> 569965, usedMemory ->573757\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000170_0 decomp: 4467 len: 4471 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4467 bytes from map-output for attempt_local1384700255_0001_m_000170_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4467, inMemoryMapOutputs.size() -> 129, commitMemory -> 573757, usedMemory ->578224\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000164_0 decomp: 4520 len: 4524 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4520 bytes from map-output for attempt_local1384700255_0001_m_000164_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4520, inMemoryMapOutputs.size() -> 130, commitMemory -> 578224, usedMemory ->582744\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000062_0 decomp: 5185 len: 5189 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 5185 bytes from map-output for attempt_local1384700255_0001_m_000062_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5185, inMemoryMapOutputs.size() -> 131, commitMemory -> 582744, usedMemory ->587929\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000267_0 decomp: 3822 len: 3826 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3822 bytes from map-output for attempt_local1384700255_0001_m_000267_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3822, inMemoryMapOutputs.size() -> 132, commitMemory -> 587929, usedMemory ->591751\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000165_0 decomp: 4515 len: 4519 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4515 bytes from map-output for attempt_local1384700255_0001_m_000165_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4515, inMemoryMapOutputs.size() -> 133, commitMemory -> 591751, usedMemory ->596266\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000063_0 decomp: 5176 len: 5180 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 5176 bytes from map-output for attempt_local1384700255_0001_m_000063_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5176, inMemoryMapOutputs.size() -> 134, commitMemory -> 596266, usedMemory ->601442\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000268_0 decomp: 3820 len: 3824 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3820 bytes from map-output for attempt_local1384700255_0001_m_000268_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3820, inMemoryMapOutputs.size() -> 135, commitMemory -> 601442, usedMemory ->605262\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000166_0 decomp: 4503 len: 4507 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4503 bytes from map-output for attempt_local1384700255_0001_m_000166_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4503, inMemoryMapOutputs.size() -> 136, commitMemory -> 605262, usedMemory ->609765\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000064_0 decomp: 5164 len: 5168 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 5164 bytes from map-output for attempt_local1384700255_0001_m_000064_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5164, inMemoryMapOutputs.size() -> 137, commitMemory -> 609765, usedMemory ->614929\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000269_0 decomp: 3819 len: 3823 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3819 bytes from map-output for attempt_local1384700255_0001_m_000269_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3819, inMemoryMapOutputs.size() -> 138, commitMemory -> 614929, usedMemory ->618748\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000167_0 decomp: 4495 len: 4499 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4495 bytes from map-output for attempt_local1384700255_0001_m_000167_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4495, inMemoryMapOutputs.size() -> 139, commitMemory -> 618748, usedMemory ->623243\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000276_0 decomp: 3760 len: 3764 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3760 bytes from map-output for attempt_local1384700255_0001_m_000276_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3760, inMemoryMapOutputs.size() -> 140, commitMemory -> 623243, usedMemory ->627003\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000174_0 decomp: 4449 len: 4453 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4449 bytes from map-output for attempt_local1384700255_0001_m_000174_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4449, inMemoryMapOutputs.size() -> 141, commitMemory -> 627003, usedMemory ->631452\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000072_0 decomp: 5131 len: 5135 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 5131 bytes from map-output for attempt_local1384700255_0001_m_000072_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5131, inMemoryMapOutputs.size() -> 142, commitMemory -> 631452, usedMemory ->636583\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000277_0 decomp: 3753 len: 3757 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3753 bytes from map-output for attempt_local1384700255_0001_m_000277_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3753, inMemoryMapOutputs.size() -> 143, commitMemory -> 636583, usedMemory ->640336\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000175_0 decomp: 4449 len: 4453 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4449 bytes from map-output for attempt_local1384700255_0001_m_000175_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4449, inMemoryMapOutputs.size() -> 144, commitMemory -> 640336, usedMemory ->644785\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000073_0 decomp: 5123 len: 5127 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 5123 bytes from map-output for attempt_local1384700255_0001_m_000073_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5123, inMemoryMapOutputs.size() -> 145, commitMemory -> 644785, usedMemory ->649908\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000278_0 decomp: 3752 len: 3756 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3752 bytes from map-output for attempt_local1384700255_0001_m_000278_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3752, inMemoryMapOutputs.size() -> 146, commitMemory -> 649908, usedMemory ->653660\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000176_0 decomp: 4435 len: 4439 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4435 bytes from map-output for attempt_local1384700255_0001_m_000176_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4435, inMemoryMapOutputs.size() -> 147, commitMemory -> 653660, usedMemory ->658095\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000074_0 decomp: 5117 len: 5121 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 5117 bytes from map-output for attempt_local1384700255_0001_m_000074_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5117, inMemoryMapOutputs.size() -> 148, commitMemory -> 658095, usedMemory ->663212\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000279_0 decomp: 3751 len: 3755 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3751 bytes from map-output for attempt_local1384700255_0001_m_000279_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3751, inMemoryMapOutputs.size() -> 149, commitMemory -> 663212, usedMemory ->666963\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000068_0 decomp: 5159 len: 5163 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 5159 bytes from map-output for attempt_local1384700255_0001_m_000068_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5159, inMemoryMapOutputs.size() -> 150, commitMemory -> 666963, usedMemory ->672122\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000273_0 decomp: 3789 len: 3793 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3789 bytes from map-output for attempt_local1384700255_0001_m_000273_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3789, inMemoryMapOutputs.size() -> 151, commitMemory -> 672122, usedMemory ->675911\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000171_0 decomp: 4461 len: 4465 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4461 bytes from map-output for attempt_local1384700255_0001_m_000171_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4461, inMemoryMapOutputs.size() -> 152, commitMemory -> 675911, usedMemory ->680372\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000069_0 decomp: 5155 len: 5159 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 5155 bytes from map-output for attempt_local1384700255_0001_m_000069_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5155, inMemoryMapOutputs.size() -> 153, commitMemory -> 680372, usedMemory ->685527\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000274_0 decomp: 3783 len: 3787 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3783 bytes from map-output for attempt_local1384700255_0001_m_000274_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3783, inMemoryMapOutputs.size() -> 154, commitMemory -> 685527, usedMemory ->689310\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000172_0 decomp: 4459 len: 4463 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4459 bytes from map-output for attempt_local1384700255_0001_m_000172_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4459, inMemoryMapOutputs.size() -> 155, commitMemory -> 689310, usedMemory ->693769\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000070_0 decomp: 5150 len: 5154 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 5150 bytes from map-output for attempt_local1384700255_0001_m_000070_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5150, inMemoryMapOutputs.size() -> 156, commitMemory -> 693769, usedMemory ->698919\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000275_0 decomp: 3766 len: 3770 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3766 bytes from map-output for attempt_local1384700255_0001_m_000275_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3766, inMemoryMapOutputs.size() -> 157, commitMemory -> 698919, usedMemory ->702685\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000173_0 decomp: 4459 len: 4463 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4459 bytes from map-output for attempt_local1384700255_0001_m_000173_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4459, inMemoryMapOutputs.size() -> 158, commitMemory -> 702685, usedMemory ->707144\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000071_0 decomp: 5139 len: 5143 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 5139 bytes from map-output for attempt_local1384700255_0001_m_000071_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5139, inMemoryMapOutputs.size() -> 159, commitMemory -> 707144, usedMemory ->712283\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000308_0 decomp: 3503 len: 3507 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3503 bytes from map-output for attempt_local1384700255_0001_m_000308_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3503, inMemoryMapOutputs.size() -> 160, commitMemory -> 712283, usedMemory ->715786\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000001_0 decomp: 15743 len: 15747 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 15743 bytes from map-output for attempt_local1384700255_0001_m_000001_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 15743, inMemoryMapOutputs.size() -> 161, commitMemory -> 715786, usedMemory ->731529\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000206_0 decomp: 4238 len: 4242 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4238 bytes from map-output for attempt_local1384700255_0001_m_000206_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4238, inMemoryMapOutputs.size() -> 162, commitMemory -> 731529, usedMemory ->735767\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000104_0 decomp: 4928 len: 4932 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4928 bytes from map-output for attempt_local1384700255_0001_m_000104_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4928, inMemoryMapOutputs.size() -> 163, commitMemory -> 735767, usedMemory ->740695\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000309_0 decomp: 3502 len: 3506 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3502 bytes from map-output for attempt_local1384700255_0001_m_000309_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3502, inMemoryMapOutputs.size() -> 164, commitMemory -> 740695, usedMemory ->744197\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000002_0 decomp: 11467 len: 11471 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 11467 bytes from map-output for attempt_local1384700255_0001_m_000002_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 11467, inMemoryMapOutputs.size() -> 165, commitMemory -> 744197, usedMemory ->755664\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000207_0 decomp: 4234 len: 4238 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4234 bytes from map-output for attempt_local1384700255_0001_m_000207_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4234, inMemoryMapOutputs.size() -> 166, commitMemory -> 755664, usedMemory ->759898\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000105_0 decomp: 4927 len: 4931 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4927 bytes from map-output for attempt_local1384700255_0001_m_000105_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4927, inMemoryMapOutputs.size() -> 167, commitMemory -> 759898, usedMemory ->764825\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000310_0 decomp: 3499 len: 3503 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3499 bytes from map-output for attempt_local1384700255_0001_m_000310_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3499, inMemoryMapOutputs.size() -> 168, commitMemory -> 764825, usedMemory ->768324\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000003_0 decomp: 9404 len: 9408 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 9404 bytes from map-output for attempt_local1384700255_0001_m_000003_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 9404, inMemoryMapOutputs.size() -> 169, commitMemory -> 768324, usedMemory ->777728\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000208_0 decomp: 4234 len: 4238 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4234 bytes from map-output for attempt_local1384700255_0001_m_000208_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4234, inMemoryMapOutputs.size() -> 170, commitMemory -> 777728, usedMemory ->781962\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000106_0 decomp: 4876 len: 4880 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4876 bytes from map-output for attempt_local1384700255_0001_m_000106_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4876, inMemoryMapOutputs.size() -> 171, commitMemory -> 781962, usedMemory ->786838\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000311_0 decomp: 3489 len: 3493 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3489 bytes from map-output for attempt_local1384700255_0001_m_000311_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3489, inMemoryMapOutputs.size() -> 172, commitMemory -> 786838, usedMemory ->790327\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000100_0 decomp: 4941 len: 4945 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4941 bytes from map-output for attempt_local1384700255_0001_m_000100_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4941, inMemoryMapOutputs.size() -> 173, commitMemory -> 790327, usedMemory ->795268\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000305_0 decomp: 3529 len: 3533 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3529 bytes from map-output for attempt_local1384700255_0001_m_000305_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3529, inMemoryMapOutputs.size() -> 174, commitMemory -> 795268, usedMemory ->798797\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000203_0 decomp: 4262 len: 4266 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4262 bytes from map-output for attempt_local1384700255_0001_m_000203_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4262, inMemoryMapOutputs.size() -> 175, commitMemory -> 798797, usedMemory ->803059\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000101_0 decomp: 4932 len: 4936 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4932 bytes from map-output for attempt_local1384700255_0001_m_000101_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4932, inMemoryMapOutputs.size() -> 176, commitMemory -> 803059, usedMemory ->807991\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000306_0 decomp: 3526 len: 3530 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3526 bytes from map-output for attempt_local1384700255_0001_m_000306_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3526, inMemoryMapOutputs.size() -> 177, commitMemory -> 807991, usedMemory ->811517\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000204_0 decomp: 4260 len: 4264 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4260 bytes from map-output for attempt_local1384700255_0001_m_000204_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4260, inMemoryMapOutputs.size() -> 178, commitMemory -> 811517, usedMemory ->815777\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000102_0 decomp: 4930 len: 4934 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4930 bytes from map-output for attempt_local1384700255_0001_m_000102_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4930, inMemoryMapOutputs.size() -> 179, commitMemory -> 815777, usedMemory ->820707\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000307_0 decomp: 3524 len: 3528 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3524 bytes from map-output for attempt_local1384700255_0001_m_000307_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3524, inMemoryMapOutputs.size() -> 180, commitMemory -> 820707, usedMemory ->824231\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000000_0 decomp: 783241 len: 783245 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 783241 bytes from map-output for attempt_local1384700255_0001_m_000000_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 783241, inMemoryMapOutputs.size() -> 181, commitMemory -> 824231, usedMemory ->1607472\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000205_0 decomp: 4256 len: 4260 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4256 bytes from map-output for attempt_local1384700255_0001_m_000205_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4256, inMemoryMapOutputs.size() -> 182, commitMemory -> 1607472, usedMemory ->1611728\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000103_0 decomp: 4930 len: 4934 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4930 bytes from map-output for attempt_local1384700255_0001_m_000103_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4930, inMemoryMapOutputs.size() -> 183, commitMemory -> 1611728, usedMemory ->1616658\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000212_0 decomp: 4202 len: 4206 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4202 bytes from map-output for attempt_local1384700255_0001_m_000212_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4202, inMemoryMapOutputs.size() -> 184, commitMemory -> 1616658, usedMemory ->1620860\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000110_0 decomp: 4833 len: 4837 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4833 bytes from map-output for attempt_local1384700255_0001_m_000110_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4833, inMemoryMapOutputs.size() -> 185, commitMemory -> 1620860, usedMemory ->1625693\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000315_0 decomp: 3447 len: 3451 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3447 bytes from map-output for attempt_local1384700255_0001_m_000315_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3447, inMemoryMapOutputs.size() -> 186, commitMemory -> 1625693, usedMemory ->1629140\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000008_0 decomp: 7265 len: 7269 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 7265 bytes from map-output for attempt_local1384700255_0001_m_000008_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 7265, inMemoryMapOutputs.size() -> 187, commitMemory -> 1629140, usedMemory ->1636405\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000213_0 decomp: 4202 len: 4206 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4202 bytes from map-output for attempt_local1384700255_0001_m_000213_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4202, inMemoryMapOutputs.size() -> 188, commitMemory -> 1636405, usedMemory ->1640607\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000111_0 decomp: 4828 len: 4832 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4828 bytes from map-output for attempt_local1384700255_0001_m_000111_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4828, inMemoryMapOutputs.size() -> 189, commitMemory -> 1640607, usedMemory ->1645435\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000316_0 decomp: 3433 len: 3437 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3433 bytes from map-output for attempt_local1384700255_0001_m_000316_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3433, inMemoryMapOutputs.size() -> 190, commitMemory -> 1645435, usedMemory ->1648868\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000009_0 decomp: 6941 len: 6945 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 6941 bytes from map-output for attempt_local1384700255_0001_m_000009_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 6941, inMemoryMapOutputs.size() -> 191, commitMemory -> 1648868, usedMemory ->1655809\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000214_0 decomp: 4201 len: 4205 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4201 bytes from map-output for attempt_local1384700255_0001_m_000214_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4201, inMemoryMapOutputs.size() -> 192, commitMemory -> 1655809, usedMemory ->1660010\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000112_0 decomp: 4813 len: 4817 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4813 bytes from map-output for attempt_local1384700255_0001_m_000112_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4813, inMemoryMapOutputs.size() -> 193, commitMemory -> 1660010, usedMemory ->1664823\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000317_0 decomp: 3429 len: 3433 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3429 bytes from map-output for attempt_local1384700255_0001_m_000317_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3429, inMemoryMapOutputs.size() -> 194, commitMemory -> 1664823, usedMemory ->1668252\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000010_0 decomp: 6866 len: 6870 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 6866 bytes from map-output for attempt_local1384700255_0001_m_000010_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 6866, inMemoryMapOutputs.size() -> 195, commitMemory -> 1668252, usedMemory ->1675118\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000215_0 decomp: 4194 len: 4198 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4194 bytes from map-output for attempt_local1384700255_0001_m_000215_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4194, inMemoryMapOutputs.size() -> 196, commitMemory -> 1675118, usedMemory ->1679312\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000004_0 decomp: 8304 len: 8308 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 8304 bytes from map-output for attempt_local1384700255_0001_m_000004_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 8304, inMemoryMapOutputs.size() -> 197, commitMemory -> 1679312, usedMemory ->1687616\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000209_0 decomp: 4228 len: 4232 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4228 bytes from map-output for attempt_local1384700255_0001_m_000209_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4228, inMemoryMapOutputs.size() -> 198, commitMemory -> 1687616, usedMemory ->1691844\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000107_0 decomp: 4859 len: 4863 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4859 bytes from map-output for attempt_local1384700255_0001_m_000107_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4859, inMemoryMapOutputs.size() -> 199, commitMemory -> 1691844, usedMemory ->1696703\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000312_0 decomp: 3472 len: 3476 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3472 bytes from map-output for attempt_local1384700255_0001_m_000312_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3472, inMemoryMapOutputs.size() -> 200, commitMemory -> 1696703, usedMemory ->1700175\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000005_0 decomp: 7670 len: 7674 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 7670 bytes from map-output for attempt_local1384700255_0001_m_000005_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 7670, inMemoryMapOutputs.size() -> 201, commitMemory -> 1700175, usedMemory ->1707845\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000210_0 decomp: 4219 len: 4223 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4219 bytes from map-output for attempt_local1384700255_0001_m_000210_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4219, inMemoryMapOutputs.size() -> 202, commitMemory -> 1707845, usedMemory ->1712064\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000108_0 decomp: 4839 len: 4843 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4839 bytes from map-output for attempt_local1384700255_0001_m_000108_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4839, inMemoryMapOutputs.size() -> 203, commitMemory -> 1712064, usedMemory ->1716903\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000313_0 decomp: 3466 len: 3470 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3466 bytes from map-output for attempt_local1384700255_0001_m_000313_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3466, inMemoryMapOutputs.size() -> 204, commitMemory -> 1716903, usedMemory ->1720369\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000006_0 decomp: 7380 len: 7384 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 7380 bytes from map-output for attempt_local1384700255_0001_m_000006_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 7380, inMemoryMapOutputs.size() -> 205, commitMemory -> 1720369, usedMemory ->1727749\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000211_0 decomp: 4213 len: 4217 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4213 bytes from map-output for attempt_local1384700255_0001_m_000211_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4213, inMemoryMapOutputs.size() -> 206, commitMemory -> 1727749, usedMemory ->1731962\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000109_0 decomp: 4833 len: 4837 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4833 bytes from map-output for attempt_local1384700255_0001_m_000109_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4833, inMemoryMapOutputs.size() -> 207, commitMemory -> 1731962, usedMemory ->1736795\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000314_0 decomp: 3455 len: 3459 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3455 bytes from map-output for attempt_local1384700255_0001_m_000314_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3455, inMemoryMapOutputs.size() -> 208, commitMemory -> 1736795, usedMemory ->1740250\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000007_0 decomp: 7289 len: 7293 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 7289 bytes from map-output for attempt_local1384700255_0001_m_000007_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 7289, inMemoryMapOutputs.size() -> 209, commitMemory -> 1740250, usedMemory ->1747539\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000193_0 decomp: 4330 len: 4334 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4330 bytes from map-output for attempt_local1384700255_0001_m_000193_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4330, inMemoryMapOutputs.size() -> 210, commitMemory -> 1747539, usedMemory ->1751869\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000091_0 decomp: 5014 len: 5018 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 5014 bytes from map-output for attempt_local1384700255_0001_m_000091_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5014, inMemoryMapOutputs.size() -> 211, commitMemory -> 1751869, usedMemory ->1756883\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000296_0 decomp: 3604 len: 3608 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3604 bytes from map-output for attempt_local1384700255_0001_m_000296_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3604, inMemoryMapOutputs.size() -> 212, commitMemory -> 1756883, usedMemory ->1760487\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000194_0 decomp: 4329 len: 4333 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4329 bytes from map-output for attempt_local1384700255_0001_m_000194_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4329, inMemoryMapOutputs.size() -> 213, commitMemory -> 1760487, usedMemory ->1764816\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000092_0 decomp: 5013 len: 5017 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 5013 bytes from map-output for attempt_local1384700255_0001_m_000092_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5013, inMemoryMapOutputs.size() -> 214, commitMemory -> 1764816, usedMemory ->1769829\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000297_0 decomp: 3596 len: 3600 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3596 bytes from map-output for attempt_local1384700255_0001_m_000297_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3596, inMemoryMapOutputs.size() -> 215, commitMemory -> 1769829, usedMemory ->1773425\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000195_0 decomp: 4311 len: 4315 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4311 bytes from map-output for attempt_local1384700255_0001_m_000195_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4311, inMemoryMapOutputs.size() -> 216, commitMemory -> 1773425, usedMemory ->1777736\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000093_0 decomp: 4996 len: 5000 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4996 bytes from map-output for attempt_local1384700255_0001_m_000093_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4996, inMemoryMapOutputs.size() -> 217, commitMemory -> 1777736, usedMemory ->1782732\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000298_0 decomp: 3589 len: 3593 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3589 bytes from map-output for attempt_local1384700255_0001_m_000298_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3589, inMemoryMapOutputs.size() -> 218, commitMemory -> 1782732, usedMemory ->1786321\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000292_0 decomp: 3640 len: 3644 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3640 bytes from map-output for attempt_local1384700255_0001_m_000292_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3640, inMemoryMapOutputs.size() -> 219, commitMemory -> 1786321, usedMemory ->1789961\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000190_0 decomp: 4354 len: 4358 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4354 bytes from map-output for attempt_local1384700255_0001_m_000190_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4354, inMemoryMapOutputs.size() -> 220, commitMemory -> 1789961, usedMemory ->1794315\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000088_0 decomp: 5034 len: 5038 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 5034 bytes from map-output for attempt_local1384700255_0001_m_000088_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5034, inMemoryMapOutputs.size() -> 221, commitMemory -> 1794315, usedMemory ->1799349\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000293_0 decomp: 3630 len: 3634 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3630 bytes from map-output for attempt_local1384700255_0001_m_000293_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3630, inMemoryMapOutputs.size() -> 222, commitMemory -> 1799349, usedMemory ->1802979\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000191_0 decomp: 4336 len: 4340 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4336 bytes from map-output for attempt_local1384700255_0001_m_000191_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4336, inMemoryMapOutputs.size() -> 223, commitMemory -> 1802979, usedMemory ->1807315\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000089_0 decomp: 5033 len: 5037 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 5033 bytes from map-output for attempt_local1384700255_0001_m_000089_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5033, inMemoryMapOutputs.size() -> 224, commitMemory -> 1807315, usedMemory ->1812348\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000294_0 decomp: 3629 len: 3633 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3629 bytes from map-output for attempt_local1384700255_0001_m_000294_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3629, inMemoryMapOutputs.size() -> 225, commitMemory -> 1812348, usedMemory ->1815977\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000192_0 decomp: 4336 len: 4340 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4336 bytes from map-output for attempt_local1384700255_0001_m_000192_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4336, inMemoryMapOutputs.size() -> 226, commitMemory -> 1815977, usedMemory ->1820313\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000090_0 decomp: 5028 len: 5032 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 5028 bytes from map-output for attempt_local1384700255_0001_m_000090_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5028, inMemoryMapOutputs.size() -> 227, commitMemory -> 1820313, usedMemory ->1825341\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000295_0 decomp: 3616 len: 3620 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3616 bytes from map-output for attempt_local1384700255_0001_m_000295_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3616, inMemoryMapOutputs.size() -> 228, commitMemory -> 1825341, usedMemory ->1828957\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000097_0 decomp: 4961 len: 4965 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4961 bytes from map-output for attempt_local1384700255_0001_m_000097_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4961, inMemoryMapOutputs.size() -> 229, commitMemory -> 1828957, usedMemory ->1833918\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000302_0 decomp: 3561 len: 3565 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3561 bytes from map-output for attempt_local1384700255_0001_m_000302_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3561, inMemoryMapOutputs.size() -> 230, commitMemory -> 1833918, usedMemory ->1837479\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000200_0 decomp: 4281 len: 4285 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4281 bytes from map-output for attempt_local1384700255_0001_m_000200_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4281, inMemoryMapOutputs.size() -> 231, commitMemory -> 1837479, usedMemory ->1841760\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000098_0 decomp: 4951 len: 4955 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4951 bytes from map-output for attempt_local1384700255_0001_m_000098_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4951, inMemoryMapOutputs.size() -> 232, commitMemory -> 1841760, usedMemory ->1846711\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000303_0 decomp: 3556 len: 3560 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3556 bytes from map-output for attempt_local1384700255_0001_m_000303_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3556, inMemoryMapOutputs.size() -> 233, commitMemory -> 1846711, usedMemory ->1850267\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000201_0 decomp: 4269 len: 4273 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4269 bytes from map-output for attempt_local1384700255_0001_m_000201_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4269, inMemoryMapOutputs.size() -> 234, commitMemory -> 1850267, usedMemory ->1854536\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000099_0 decomp: 4948 len: 4952 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4948 bytes from map-output for attempt_local1384700255_0001_m_000099_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4948, inMemoryMapOutputs.size() -> 235, commitMemory -> 1854536, usedMemory ->1859484\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000304_0 decomp: 3543 len: 3547 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3543 bytes from map-output for attempt_local1384700255_0001_m_000304_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3543, inMemoryMapOutputs.size() -> 236, commitMemory -> 1859484, usedMemory ->1863027\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000202_0 decomp: 4265 len: 4269 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4265 bytes from map-output for attempt_local1384700255_0001_m_000202_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4265, inMemoryMapOutputs.size() -> 237, commitMemory -> 1863027, usedMemory ->1867292\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000196_0 decomp: 4301 len: 4305 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4301 bytes from map-output for attempt_local1384700255_0001_m_000196_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4301, inMemoryMapOutputs.size() -> 238, commitMemory -> 1867292, usedMemory ->1871593\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000094_0 decomp: 4980 len: 4984 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4980 bytes from map-output for attempt_local1384700255_0001_m_000094_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4980, inMemoryMapOutputs.size() -> 239, commitMemory -> 1871593, usedMemory ->1876573\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000299_0 decomp: 3583 len: 3587 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3583 bytes from map-output for attempt_local1384700255_0001_m_000299_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3583, inMemoryMapOutputs.size() -> 240, commitMemory -> 1876573, usedMemory ->1880156\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000197_0 decomp: 4297 len: 4301 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4297 bytes from map-output for attempt_local1384700255_0001_m_000197_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4297, inMemoryMapOutputs.size() -> 241, commitMemory -> 1880156, usedMemory ->1884453\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000095_0 decomp: 4977 len: 4981 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4977 bytes from map-output for attempt_local1384700255_0001_m_000095_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4977, inMemoryMapOutputs.size() -> 242, commitMemory -> 1884453, usedMemory ->1889430\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000300_0 decomp: 3567 len: 3571 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3567 bytes from map-output for attempt_local1384700255_0001_m_000300_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3567, inMemoryMapOutputs.size() -> 243, commitMemory -> 1889430, usedMemory ->1892997\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000198_0 decomp: 4296 len: 4300 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4296 bytes from map-output for attempt_local1384700255_0001_m_000198_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4296, inMemoryMapOutputs.size() -> 244, commitMemory -> 1892997, usedMemory ->1897293\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000096_0 decomp: 4975 len: 4979 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4975 bytes from map-output for attempt_local1384700255_0001_m_000096_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4975, inMemoryMapOutputs.size() -> 245, commitMemory -> 1897293, usedMemory ->1902268\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000301_0 decomp: 3563 len: 3567 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3563 bytes from map-output for attempt_local1384700255_0001_m_000301_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3563, inMemoryMapOutputs.size() -> 246, commitMemory -> 1902268, usedMemory ->1905831\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000199_0 decomp: 4295 len: 4299 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4295 bytes from map-output for attempt_local1384700255_0001_m_000199_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4295, inMemoryMapOutputs.size() -> 247, commitMemory -> 1905831, usedMemory ->1910126\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000129_0 decomp: 4700 len: 4704 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4700 bytes from map-output for attempt_local1384700255_0001_m_000129_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4700, inMemoryMapOutputs.size() -> 248, commitMemory -> 1910126, usedMemory ->1914826\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000334_0 decomp: 3237 len: 3241 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3237 bytes from map-output for attempt_local1384700255_0001_m_000334_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3237, inMemoryMapOutputs.size() -> 249, commitMemory -> 1914826, usedMemory ->1918063\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000027_0 decomp: 5803 len: 5807 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 5803 bytes from map-output for attempt_local1384700255_0001_m_000027_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5803, inMemoryMapOutputs.size() -> 250, commitMemory -> 1918063, usedMemory ->1923866\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000232_0 decomp: 4072 len: 4076 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4072 bytes from map-output for attempt_local1384700255_0001_m_000232_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4072, inMemoryMapOutputs.size() -> 251, commitMemory -> 1923866, usedMemory ->1927938\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000130_0 decomp: 4696 len: 4700 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4696 bytes from map-output for attempt_local1384700255_0001_m_000130_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4696, inMemoryMapOutputs.size() -> 252, commitMemory -> 1927938, usedMemory ->1932634\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000335_0 decomp: 3237 len: 3241 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3237 bytes from map-output for attempt_local1384700255_0001_m_000335_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3237, inMemoryMapOutputs.size() -> 253, commitMemory -> 1932634, usedMemory ->1935871\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000028_0 decomp: 5704 len: 5708 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 5704 bytes from map-output for attempt_local1384700255_0001_m_000028_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5704, inMemoryMapOutputs.size() -> 254, commitMemory -> 1935871, usedMemory ->1941575\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000233_0 decomp: 4072 len: 4076 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4072 bytes from map-output for attempt_local1384700255_0001_m_000233_0\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4072, inMemoryMapOutputs.size() -> 255, commitMemory -> 1941575, usedMemory ->1945647\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000131_0 decomp: 4698 len: 4702 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4698 bytes from map-output for attempt_local1384700255_0001_m_000131_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4698, inMemoryMapOutputs.size() -> 256, commitMemory -> 1945647, usedMemory ->1950345\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000336_0 decomp: 3223 len: 3227 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3223 bytes from map-output for attempt_local1384700255_0001_m_000336_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3223, inMemoryMapOutputs.size() -> 257, commitMemory -> 1950345, usedMemory ->1953568\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000029_0 decomp: 5699 len: 5703 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 5699 bytes from map-output for attempt_local1384700255_0001_m_000029_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5699, inMemoryMapOutputs.size() -> 258, commitMemory -> 1953568, usedMemory ->1959267\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000234_0 decomp: 4068 len: 4072 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4068 bytes from map-output for attempt_local1384700255_0001_m_000234_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4068, inMemoryMapOutputs.size() -> 259, commitMemory -> 1959267, usedMemory ->1963335\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000228_0 decomp: 4100 len: 4104 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4100 bytes from map-output for attempt_local1384700255_0001_m_000228_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4100, inMemoryMapOutputs.size() -> 260, commitMemory -> 1963335, usedMemory ->1967435\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000126_0 decomp: 4707 len: 4711 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4707 bytes from map-output for attempt_local1384700255_0001_m_000126_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4707, inMemoryMapOutputs.size() -> 261, commitMemory -> 1967435, usedMemory ->1972142\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000331_0 decomp: 3274 len: 3278 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3274 bytes from map-output for attempt_local1384700255_0001_m_000331_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3274, inMemoryMapOutputs.size() -> 262, commitMemory -> 1972142, usedMemory ->1975416\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000024_0 decomp: 5945 len: 5949 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 5945 bytes from map-output for attempt_local1384700255_0001_m_000024_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5945, inMemoryMapOutputs.size() -> 263, commitMemory -> 1975416, usedMemory ->1981361\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000229_0 decomp: 4088 len: 4092 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4088 bytes from map-output for attempt_local1384700255_0001_m_000229_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4088, inMemoryMapOutputs.size() -> 264, commitMemory -> 1981361, usedMemory ->1985449\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000127_0 decomp: 4715 len: 4719 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4715 bytes from map-output for attempt_local1384700255_0001_m_000127_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4715, inMemoryMapOutputs.size() -> 265, commitMemory -> 1985449, usedMemory ->1990164\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000332_0 decomp: 3272 len: 3276 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3272 bytes from map-output for attempt_local1384700255_0001_m_000332_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3272, inMemoryMapOutputs.size() -> 266, commitMemory -> 1990164, usedMemory ->1993436\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000025_0 decomp: 5918 len: 5922 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 5918 bytes from map-output for attempt_local1384700255_0001_m_000025_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5918, inMemoryMapOutputs.size() -> 267, commitMemory -> 1993436, usedMemory ->1999354\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000230_0 decomp: 4086 len: 4090 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4086 bytes from map-output for attempt_local1384700255_0001_m_000230_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4086, inMemoryMapOutputs.size() -> 268, commitMemory -> 1999354, usedMemory ->2003440\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000128_0 decomp: 4711 len: 4715 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4711 bytes from map-output for attempt_local1384700255_0001_m_000128_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4711, inMemoryMapOutputs.size() -> 269, commitMemory -> 2003440, usedMemory ->2008151\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000333_0 decomp: 3244 len: 3248 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3244 bytes from map-output for attempt_local1384700255_0001_m_000333_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3244, inMemoryMapOutputs.size() -> 270, commitMemory -> 2008151, usedMemory ->2011395\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000026_0 decomp: 5841 len: 5845 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 5841 bytes from map-output for attempt_local1384700255_0001_m_000026_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5841, inMemoryMapOutputs.size() -> 271, commitMemory -> 2011395, usedMemory ->2017236\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000231_0 decomp: 4084 len: 4088 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4084 bytes from map-output for attempt_local1384700255_0001_m_000231_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4084, inMemoryMapOutputs.size() -> 272, commitMemory -> 2017236, usedMemory ->2021320\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000340_0 decomp: 3135 len: 3139 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3135 bytes from map-output for attempt_local1384700255_0001_m_000340_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3135, inMemoryMapOutputs.size() -> 273, commitMemory -> 2021320, usedMemory ->2024455\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000033_0 decomp: 5587 len: 5591 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 5587 bytes from map-output for attempt_local1384700255_0001_m_000033_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5587, inMemoryMapOutputs.size() -> 274, commitMemory -> 2024455, usedMemory ->2030042\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000238_0 decomp: 4037 len: 4041 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4037 bytes from map-output for attempt_local1384700255_0001_m_000238_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4037, inMemoryMapOutputs.size() -> 275, commitMemory -> 2030042, usedMemory ->2034079\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000136_0 decomp: 4666 len: 4670 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4666 bytes from map-output for attempt_local1384700255_0001_m_000136_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4666, inMemoryMapOutputs.size() -> 276, commitMemory -> 2034079, usedMemory ->2038745\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000341_0 decomp: 3126 len: 3130 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3126 bytes from map-output for attempt_local1384700255_0001_m_000341_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3126, inMemoryMapOutputs.size() -> 277, commitMemory -> 2038745, usedMemory ->2041871\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000034_0 decomp: 5571 len: 5575 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 5571 bytes from map-output for attempt_local1384700255_0001_m_000034_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5571, inMemoryMapOutputs.size() -> 278, commitMemory -> 2041871, usedMemory ->2047442\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000239_0 decomp: 4033 len: 4037 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4033 bytes from map-output for attempt_local1384700255_0001_m_000239_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4033, inMemoryMapOutputs.size() -> 279, commitMemory -> 2047442, usedMemory ->2051475\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000137_0 decomp: 4662 len: 4666 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4662 bytes from map-output for attempt_local1384700255_0001_m_000137_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4662, inMemoryMapOutputs.size() -> 280, commitMemory -> 2051475, usedMemory ->2056137\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000342_0 decomp: 3102 len: 3106 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3102 bytes from map-output for attempt_local1384700255_0001_m_000342_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3102, inMemoryMapOutputs.size() -> 281, commitMemory -> 2056137, usedMemory ->2059239\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000035_0 decomp: 5563 len: 5567 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 5563 bytes from map-output for attempt_local1384700255_0001_m_000035_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5563, inMemoryMapOutputs.size() -> 282, commitMemory -> 2059239, usedMemory ->2064802\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000240_0 decomp: 4021 len: 4025 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4021 bytes from map-output for attempt_local1384700255_0001_m_000240_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4021, inMemoryMapOutputs.size() -> 283, commitMemory -> 2064802, usedMemory ->2068823\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000138_0 decomp: 4658 len: 4662 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4658 bytes from map-output for attempt_local1384700255_0001_m_000138_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4658, inMemoryMapOutputs.size() -> 284, commitMemory -> 2068823, usedMemory ->2073481\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000343_0 decomp: 3092 len: 3096 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3092 bytes from map-output for attempt_local1384700255_0001_m_000343_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3092, inMemoryMapOutputs.size() -> 285, commitMemory -> 2073481, usedMemory ->2076573\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000132_0 decomp: 4674 len: 4678 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4674 bytes from map-output for attempt_local1384700255_0001_m_000132_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4674, inMemoryMapOutputs.size() -> 286, commitMemory -> 2076573, usedMemory ->2081247\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000337_0 decomp: 3202 len: 3206 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3202 bytes from map-output for attempt_local1384700255_0001_m_000337_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3202, inMemoryMapOutputs.size() -> 287, commitMemory -> 2081247, usedMemory ->2084449\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000030_0 decomp: 5685 len: 5689 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 5685 bytes from map-output for attempt_local1384700255_0001_m_000030_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5685, inMemoryMapOutputs.size() -> 288, commitMemory -> 2084449, usedMemory ->2090134\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000235_0 decomp: 4063 len: 4067 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4063 bytes from map-output for attempt_local1384700255_0001_m_000235_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4063, inMemoryMapOutputs.size() -> 289, commitMemory -> 2090134, usedMemory ->2094197\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000133_0 decomp: 4682 len: 4686 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4682 bytes from map-output for attempt_local1384700255_0001_m_000133_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4682, inMemoryMapOutputs.size() -> 290, commitMemory -> 2094197, usedMemory ->2098879\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000338_0 decomp: 3185 len: 3189 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3185 bytes from map-output for attempt_local1384700255_0001_m_000338_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3185, inMemoryMapOutputs.size() -> 291, commitMemory -> 2098879, usedMemory ->2102064\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000031_0 decomp: 5625 len: 5629 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 5625 bytes from map-output for attempt_local1384700255_0001_m_000031_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5625, inMemoryMapOutputs.size() -> 292, commitMemory -> 2102064, usedMemory ->2107689\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000236_0 decomp: 4047 len: 4051 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4047 bytes from map-output for attempt_local1384700255_0001_m_000236_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4047, inMemoryMapOutputs.size() -> 293, commitMemory -> 2107689, usedMemory ->2111736\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000134_0 decomp: 4679 len: 4683 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4679 bytes from map-output for attempt_local1384700255_0001_m_000134_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4679, inMemoryMapOutputs.size() -> 294, commitMemory -> 2111736, usedMemory ->2116415\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000339_0 decomp: 3163 len: 3167 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3163 bytes from map-output for attempt_local1384700255_0001_m_000339_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3163, inMemoryMapOutputs.size() -> 295, commitMemory -> 2116415, usedMemory ->2119578\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000032_0 decomp: 5585 len: 5589 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 5585 bytes from map-output for attempt_local1384700255_0001_m_000032_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5585, inMemoryMapOutputs.size() -> 296, commitMemory -> 2119578, usedMemory ->2125163\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000237_0 decomp: 4043 len: 4047 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4043 bytes from map-output for attempt_local1384700255_0001_m_000237_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4043, inMemoryMapOutputs.size() -> 297, commitMemory -> 2125163, usedMemory ->2129206\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000135_0 decomp: 4673 len: 4677 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4673 bytes from map-output for attempt_local1384700255_0001_m_000135_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4673, inMemoryMapOutputs.size() -> 298, commitMemory -> 2129206, usedMemory ->2133879\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000116_0 decomp: 4786 len: 4790 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4786 bytes from map-output for attempt_local1384700255_0001_m_000116_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4786, inMemoryMapOutputs.size() -> 299, commitMemory -> 2133879, usedMemory ->2138665\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000321_0 decomp: 3393 len: 3397 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3393 bytes from map-output for attempt_local1384700255_0001_m_000321_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3393, inMemoryMapOutputs.size() -> 300, commitMemory -> 2138665, usedMemory ->2142058\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000014_0 decomp: 6343 len: 6347 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 6343 bytes from map-output for attempt_local1384700255_0001_m_000014_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 6343, inMemoryMapOutputs.size() -> 301, commitMemory -> 2142058, usedMemory ->2148401\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000219_0 decomp: 4167 len: 4171 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4167 bytes from map-output for attempt_local1384700255_0001_m_000219_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4167, inMemoryMapOutputs.size() -> 302, commitMemory -> 2148401, usedMemory ->2152568\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000117_0 decomp: 4782 len: 4786 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4782 bytes from map-output for attempt_local1384700255_0001_m_000117_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4782, inMemoryMapOutputs.size() -> 303, commitMemory -> 2152568, usedMemory ->2157350\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000322_0 decomp: 3375 len: 3379 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3375 bytes from map-output for attempt_local1384700255_0001_m_000322_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3375, inMemoryMapOutputs.size() -> 304, commitMemory -> 2157350, usedMemory ->2160725\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000015_0 decomp: 6314 len: 6318 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 6314 bytes from map-output for attempt_local1384700255_0001_m_000015_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 6314, inMemoryMapOutputs.size() -> 305, commitMemory -> 2160725, usedMemory ->2167039\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000220_0 decomp: 4166 len: 4170 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4166 bytes from map-output for attempt_local1384700255_0001_m_000220_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4166, inMemoryMapOutputs.size() -> 306, commitMemory -> 2167039, usedMemory ->2171205\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000118_0 decomp: 4776 len: 4780 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4776 bytes from map-output for attempt_local1384700255_0001_m_000118_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4776, inMemoryMapOutputs.size() -> 307, commitMemory -> 2171205, usedMemory ->2175981\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000323_0 decomp: 3372 len: 3376 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3372 bytes from map-output for attempt_local1384700255_0001_m_000323_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3372, inMemoryMapOutputs.size() -> 308, commitMemory -> 2175981, usedMemory ->2179353\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000016_0 decomp: 6297 len: 6301 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 6297 bytes from map-output for attempt_local1384700255_0001_m_000016_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 6297, inMemoryMapOutputs.size() -> 309, commitMemory -> 2179353, usedMemory ->2185650\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000221_0 decomp: 4141 len: 4145 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4141 bytes from map-output for attempt_local1384700255_0001_m_000221_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4141, inMemoryMapOutputs.size() -> 310, commitMemory -> 2185650, usedMemory ->2189791\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000119_0 decomp: 4775 len: 4779 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4775 bytes from map-output for attempt_local1384700255_0001_m_000119_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4775, inMemoryMapOutputs.size() -> 311, commitMemory -> 2189791, usedMemory ->2194566\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000113_0 decomp: 4797 len: 4801 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4797 bytes from map-output for attempt_local1384700255_0001_m_000113_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4797, inMemoryMapOutputs.size() -> 312, commitMemory -> 2194566, usedMemory ->2199363\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000318_0 decomp: 3427 len: 3431 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3427 bytes from map-output for attempt_local1384700255_0001_m_000318_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3427, inMemoryMapOutputs.size() -> 313, commitMemory -> 2199363, usedMemory ->2202790\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000011_0 decomp: 6642 len: 6646 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 6642 bytes from map-output for attempt_local1384700255_0001_m_000011_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 6642, inMemoryMapOutputs.size() -> 314, commitMemory -> 2202790, usedMemory ->2209432\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000216_0 decomp: 4183 len: 4187 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4183 bytes from map-output for attempt_local1384700255_0001_m_000216_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4183, inMemoryMapOutputs.size() -> 315, commitMemory -> 2209432, usedMemory ->2213615\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000114_0 decomp: 4795 len: 4799 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4795 bytes from map-output for attempt_local1384700255_0001_m_000114_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4795, inMemoryMapOutputs.size() -> 316, commitMemory -> 2213615, usedMemory ->2218410\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000319_0 decomp: 3403 len: 3407 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3403 bytes from map-output for attempt_local1384700255_0001_m_000319_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3403, inMemoryMapOutputs.size() -> 317, commitMemory -> 2218410, usedMemory ->2221813\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000012_0 decomp: 6513 len: 6517 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 6513 bytes from map-output for attempt_local1384700255_0001_m_000012_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 6513, inMemoryMapOutputs.size() -> 318, commitMemory -> 2221813, usedMemory ->2228326\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000217_0 decomp: 4172 len: 4176 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4172 bytes from map-output for attempt_local1384700255_0001_m_000217_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4172, inMemoryMapOutputs.size() -> 319, commitMemory -> 2228326, usedMemory ->2232498\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000115_0 decomp: 4793 len: 4797 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4793 bytes from map-output for attempt_local1384700255_0001_m_000115_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4793, inMemoryMapOutputs.size() -> 320, commitMemory -> 2232498, usedMemory ->2237291\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000320_0 decomp: 3403 len: 3407 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3403 bytes from map-output for attempt_local1384700255_0001_m_000320_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3403, inMemoryMapOutputs.size() -> 321, commitMemory -> 2237291, usedMemory ->2240694\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000013_0 decomp: 6393 len: 6397 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 6393 bytes from map-output for attempt_local1384700255_0001_m_000013_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 6393, inMemoryMapOutputs.size() -> 322, commitMemory -> 2240694, usedMemory ->2247087\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000218_0 decomp: 4168 len: 4172 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4168 bytes from map-output for attempt_local1384700255_0001_m_000218_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4168, inMemoryMapOutputs.size() -> 323, commitMemory -> 2247087, usedMemory ->2251255\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000020_0 decomp: 6105 len: 6109 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 6105 bytes from map-output for attempt_local1384700255_0001_m_000020_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 6105, inMemoryMapOutputs.size() -> 324, commitMemory -> 2251255, usedMemory ->2257360\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000225_0 decomp: 4117 len: 4121 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4117 bytes from map-output for attempt_local1384700255_0001_m_000225_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4117, inMemoryMapOutputs.size() -> 325, commitMemory -> 2257360, usedMemory ->2261477\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000123_0 decomp: 4728 len: 4732 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4728 bytes from map-output for attempt_local1384700255_0001_m_000123_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4728, inMemoryMapOutputs.size() -> 326, commitMemory -> 2261477, usedMemory ->2266205\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000328_0 decomp: 3302 len: 3306 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3302 bytes from map-output for attempt_local1384700255_0001_m_000328_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3302, inMemoryMapOutputs.size() -> 327, commitMemory -> 2266205, usedMemory ->2269507\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000021_0 decomp: 6048 len: 6052 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 6048 bytes from map-output for attempt_local1384700255_0001_m_000021_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 6048, inMemoryMapOutputs.size() -> 328, commitMemory -> 2269507, usedMemory ->2275555\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000226_0 decomp: 4111 len: 4115 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4111 bytes from map-output for attempt_local1384700255_0001_m_000226_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4111, inMemoryMapOutputs.size() -> 329, commitMemory -> 2275555, usedMemory ->2279666\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000124_0 decomp: 4724 len: 4728 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4724 bytes from map-output for attempt_local1384700255_0001_m_000124_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4724, inMemoryMapOutputs.size() -> 330, commitMemory -> 2279666, usedMemory ->2284390\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000329_0 decomp: 3286 len: 3290 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3286 bytes from map-output for attempt_local1384700255_0001_m_000329_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3286, inMemoryMapOutputs.size() -> 331, commitMemory -> 2284390, usedMemory ->2287676\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000022_0 decomp: 6008 len: 6012 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 6008 bytes from map-output for attempt_local1384700255_0001_m_000022_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 6008, inMemoryMapOutputs.size() -> 332, commitMemory -> 2287676, usedMemory ->2293684\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000227_0 decomp: 4107 len: 4111 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4107 bytes from map-output for attempt_local1384700255_0001_m_000227_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4107, inMemoryMapOutputs.size() -> 333, commitMemory -> 2293684, usedMemory ->2297791\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000125_0 decomp: 4723 len: 4727 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4723 bytes from map-output for attempt_local1384700255_0001_m_000125_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4723, inMemoryMapOutputs.size() -> 334, commitMemory -> 2297791, usedMemory ->2302514\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000330_0 decomp: 3277 len: 3281 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3277 bytes from map-output for attempt_local1384700255_0001_m_000330_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3277, inMemoryMapOutputs.size() -> 335, commitMemory -> 2302514, usedMemory ->2305791\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000023_0 decomp: 5947 len: 5951 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 5947 bytes from map-output for attempt_local1384700255_0001_m_000023_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 5947, inMemoryMapOutputs.size() -> 336, commitMemory -> 2305791, usedMemory ->2311738\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000324_0 decomp: 3358 len: 3362 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3358 bytes from map-output for attempt_local1384700255_0001_m_000324_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3358, inMemoryMapOutputs.size() -> 337, commitMemory -> 2311738, usedMemory ->2315096\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000017_0 decomp: 6231 len: 6235 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 6231 bytes from map-output for attempt_local1384700255_0001_m_000017_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 6231, inMemoryMapOutputs.size() -> 338, commitMemory -> 2315096, usedMemory ->2321327\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000222_0 decomp: 4140 len: 4144 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4140 bytes from map-output for attempt_local1384700255_0001_m_000222_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4140, inMemoryMapOutputs.size() -> 339, commitMemory -> 2321327, usedMemory ->2325467\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000120_0 decomp: 4752 len: 4756 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4752 bytes from map-output for attempt_local1384700255_0001_m_000120_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4752, inMemoryMapOutputs.size() -> 340, commitMemory -> 2325467, usedMemory ->2330219\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000325_0 decomp: 3345 len: 3349 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3345 bytes from map-output for attempt_local1384700255_0001_m_000325_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3345, inMemoryMapOutputs.size() -> 341, commitMemory -> 2330219, usedMemory ->2333564\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000018_0 decomp: 6149 len: 6153 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 6149 bytes from map-output for attempt_local1384700255_0001_m_000018_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 6149, inMemoryMapOutputs.size() -> 342, commitMemory -> 2333564, usedMemory ->2339713\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000223_0 decomp: 4138 len: 4142 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4138 bytes from map-output for attempt_local1384700255_0001_m_000223_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4138, inMemoryMapOutputs.size() -> 343, commitMemory -> 2339713, usedMemory ->2343851\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000121_0 decomp: 4756 len: 4760 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4756 bytes from map-output for attempt_local1384700255_0001_m_000121_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4756, inMemoryMapOutputs.size() -> 344, commitMemory -> 2343851, usedMemory ->2348607\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000326_0 decomp: 3337 len: 3341 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3337 bytes from map-output for attempt_local1384700255_0001_m_000326_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3337, inMemoryMapOutputs.size() -> 345, commitMemory -> 2348607, usedMemory ->2351944\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000019_0 decomp: 6111 len: 6115 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 6111 bytes from map-output for attempt_local1384700255_0001_m_000019_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 6111, inMemoryMapOutputs.size() -> 346, commitMemory -> 2351944, usedMemory ->2358055\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000224_0 decomp: 4121 len: 4125 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4121 bytes from map-output for attempt_local1384700255_0001_m_000224_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4121, inMemoryMapOutputs.size() -> 347, commitMemory -> 2358055, usedMemory ->2362176\r\n",
      "25/08/24 20:13:40 WARN io.ReadaheadPool: Failed readahead on ifile\r\n",
      "EBADF: Bad file descriptor\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\r\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\r\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:750)\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000122_0 decomp: 4738 len: 4742 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 4738 bytes from map-output for attempt_local1384700255_0001_m_000122_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4738, inMemoryMapOutputs.size() -> 348, commitMemory -> 2362176, usedMemory ->2366914\r\n",
      "25/08/24 20:13:40 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1384700255_0001_m_000327_0 decomp: 3319 len: 3323 to MEMORY\r\n",
      "25/08/24 20:13:40 INFO reduce.InMemoryMapOutput: Read 3319 bytes from map-output for attempt_local1384700255_0001_m_000327_0\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3319, inMemoryMapOutputs.size() -> 349, commitMemory -> 2366914, usedMemory ->2370233\r\n",
      "25/08/24 20:13:40 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: 349 / 349 copied.\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: finalMerge called with 349 in-memory map-outputs and 0 on-disk map-outputs\r\n",
      "25/08/24 20:13:40 INFO mapred.Merger: Merging 349 sorted segments\r\n",
      "25/08/24 20:13:40 INFO mapred.Merger: Down to the last merge-pass, with 349 segments left of total size: 2356354 bytes\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: Merged 349 segments, 2370233 bytes to disk to satisfy reduce memory limit\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: Merging 1 files, 2369541 bytes from disk\r\n",
      "25/08/24 20:13:40 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce\r\n",
      "25/08/24 20:13:40 INFO mapred.Merger: Merging 1 sorted segments\r\n",
      "25/08/24 20:13:40 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 2369408 bytes\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: 349 / 349 copied.\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: PipeMapRed exec [/home/ubuntu/jupyter/MapReduce/reducer_join.py]\r\n",
      "25/08/24 20:13:40 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\r\n",
      "25/08/24 20:13:40 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: Records R/W=1199/1\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: R/W/S=10000/4755/0 in:NA [rec/s] out:NA [rec/s]\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: MRErrorThread done\r\n",
      "25/08/24 20:13:40 INFO streaming.PipeMapRed: mapRedFinished\r\n",
      "25/08/24 20:13:40 INFO mapred.Task: Task:attempt_local1384700255_0001_r_000000_0 is done. And is in the process of committing\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: 349 / 349 copied.\r\n",
      "25/08/24 20:13:40 INFO mapred.Task: Task attempt_local1384700255_0001_r_000000_0 is allowed to commit now\r\n",
      "25/08/24 20:13:40 INFO output.FileOutputCommitter: Saved output of task 'attempt_local1384700255_0001_r_000000_0' to hdfs://localhost:54310/user/ubuntu/map_reduce/joint_dataset/_temporary/0/task_local1384700255_0001_r_000000\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: Records R/W=1199/1 > reduce\r\n",
      "25/08/24 20:13:40 INFO mapred.Task: Task 'attempt_local1384700255_0001_r_000000_0' done.\r\n",
      "25/08/24 20:13:40 INFO mapred.Task: Final Counters for attempt_local1384700255_0001_r_000000_0: Counters: 29\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=6440449\r\n",
      "\t\tFILE: Number of bytes written=5442328\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=1792664\r\n",
      "\t\tHDFS: Number of bytes written=1393873\r\n",
      "\t\tHDFS: Number of read operations=707\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=3\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tCombine output records=0\r\n",
      "\t\tReduce input groups=10315\r\n",
      "\t\tReduce shuffle bytes=2371629\r\n",
      "\t\tReduce input records=21442\r\n",
      "\t\tReduce output records=11127\r\n",
      "\t\tSpilled Records=21442\r\n",
      "\t\tShuffled Maps =349\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=349\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=2634022912\r\n",
      "\tShuffle Errors\r\n",
      "\t\tBAD_ID=0\r\n",
      "\t\tCONNECTION=0\r\n",
      "\t\tIO_ERROR=0\r\n",
      "\t\tWRONG_LENGTH=0\r\n",
      "\t\tWRONG_MAP=0\r\n",
      "\t\tWRONG_REDUCE=0\r\n",
      "\tFile Output Format Counters \r\n",
      "\t\tBytes Written=1393873\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: Finishing task: attempt_local1384700255_0001_r_000000_0\r\n",
      "25/08/24 20:13:40 INFO mapred.LocalJobRunner: reduce task executor complete.\r\n",
      "25/08/24 20:13:41 INFO mapreduce.Job:  map 100% reduce 100%\r\n",
      "25/08/24 20:13:41 INFO mapreduce.Job: Job job_local1384700255_0001 completed successfully\r\n",
      "25/08/24 20:13:41 INFO mapreduce.Job: Counters: 35\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=333914856\r\n",
      "\t\tFILE: Number of bytes written=831075790\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\t\tHDFS: Number of bytes read=425740913\r\n",
      "\t\tHDFS: Number of bytes written=1393873\r\n",
      "\t\tHDFS: Number of read operations=124951\r\n",
      "\t\tHDFS: Number of large read operations=0\r\n",
      "\t\tHDFS: Number of write operations=352\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=21442\r\n",
      "\t\tMap output records=21442\r\n",
      "\t\tMap output bytes=2325622\r\n",
      "\t\tMap output materialized bytes=2371629\r\n",
      "\t\tInput split bytes=57198\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tCombine output records=0\r\n",
      "\t\tReduce input groups=10315\r\n",
      "\t\tReduce shuffle bytes=2371629\r\n",
      "\t\tReduce input records=21442\r\n",
      "\t\tReduce output records=11127\r\n",
      "\t\tSpilled Records=42884\r\n",
      "\t\tShuffled Maps =349\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=349\r\n",
      "\t\tGC time elapsed (ms)=591\r\n",
      "\t\tTotal committed heap usage (bytes)=1443009921024\r\n",
      "\tShuffle Errors\r\n",
      "\t\tBAD_ID=0\r\n",
      "\t\tCONNECTION=0\r\n",
      "\t\tIO_ERROR=0\r\n",
      "\t\tWRONG_LENGTH=0\r\n",
      "\t\tWRONG_MAP=0\r\n",
      "\t\tWRONG_REDUCE=0\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=1792664\r\n",
      "\tFile Output Format Counters \r\n",
      "\t\tBytes Written=1393873\r\n",
      "25/08/24 20:13:41 INFO streaming.StreamJob: Output directory: /user/ubuntu/map_reduce/joint_dataset/\r\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "43ad25dc842defdc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
